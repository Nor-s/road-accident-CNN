{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Flatten, Reshape, Conv2D, Conv1D\n",
    "from tensorflow.keras import models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D\n",
    "import math\n",
    "import numpy as np\n",
    " \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'three_image(3_label)'\n",
    "\n",
    "TRAIN_SAMPLES = 15926\n",
    "VALIDATION_SAMPLES = 1990\n",
    "IMG_WIDTH, IMG_HEIGHT = 128, 128\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/keras-team/keras/issues/9969#issuecomment-420371428\n",
    "# https://stackoverflow.com/questions/59492866/keras-imagedatagenerator-for-multiple-inputs-and-image-based-target-output\n",
    "class JoinedGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, input_gen1, input_gen2, input_gen3):\n",
    "        self.gen1 = input_gen1\n",
    "        self.gen2 = input_gen2\n",
    "        self.gen3 = input_gen2\n",
    "\n",
    "        assert len(input_gen1) == len(input_gen2)  == len(input_gen3)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gen1)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x1, y1 = self.gen1[i]\n",
    "        x2, y2 = self.gen2[i]\n",
    "        x3, y3 = self.gen3[i]\n",
    "        return [x1, x2, x3], y1\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.gen1.on_epoch_end()\n",
    "        self.gen2.on_epoch_end()\n",
    "        self.gen3.on_epoch_end()\n",
    "        self.gen2.index_array = self.gen1.index_array\n",
    "        self.gen3.index_array = self.gen1.index_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15926 images belonging to 3 classes.\n",
      "Found 15926 images belonging to 3 classes.\n",
      "Found 15926 images belonging to 3 classes.\n",
      "Found 1990 images belonging to 3 classes.\n",
      "Found 1990 images belonging to 3 classes.\n",
      "Found 1990 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "                                   rotation_range=45,\n",
    "                                   width_shift_range=0.3,\n",
    "                                   height_shift_range=0.3,\n",
    "                                   zoom_range=0.3,\n",
    "                                   vertical_flip =True,\n",
    "                                   horizontal_flip =True)\n",
    " \n",
    "val_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "\n",
    "train_generator1 = train_datagen.flow_from_directory(f'../data/{NAME}/sat/train',\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "train_generator2 = train_datagen.flow_from_directory(f'../data/{NAME}/dem/train',\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "train_generator3 = train_datagen.flow_from_directory(f'../data/{NAME}/road/train',\n",
    "                                                    target_size=(IMG_WIDTH,\n",
    "                                                                 IMG_HEIGHT),\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=12345,\n",
    "                                                    class_mode='categorical')\n",
    "validation_generator1 = val_datagen.flow_from_directory(\n",
    "    f'../data/{NAME}/sat/val',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "validation_generator2 = val_datagen.flow_from_directory(\n",
    "    f'../data/{NAME}/dem/val',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')\n",
    "validation_generator3 = val_datagen.flow_from_directory(\n",
    "    f'../data/{NAME}/road/val',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = JoinedGen(train_generator1, train_generator2, train_generator3)\n",
    "validation_generator = JoinedGen(validation_generator1, validation_generator2, validation_generator3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 9)  0           ['input_4[0][0]',                \n",
      "                                                                  'input_6[0][0]',                \n",
      "                                                                  'input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 126, 126, 32  2624        ['concatenate[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 124, 124, 64  18496       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 62, 62, 64)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 60, 60, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 128)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " mobilenetv2_1 (Functional)     (None, 4, 4, 1280)   2257984     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " mobilenetv2_2 (Functional)     (None, 4, 4, 1280)   2257984     ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " mobilenetv2_3 (Functional)     (None, 4, 4, 1280)   2257984     ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 28, 28, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['mobilenetv2_1[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 1280)        0           ['mobilenetv2_2[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 1280)        0           ['mobilenetv2_3[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 256)         0           ['conv2d_3[0][0]']               \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1280)         0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1280)         0           ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 1280)         0           ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 256)          0           ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          327936      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          327936      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          327936      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          65792       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1024)         0           ['dense[0][0]',                  \n",
      "                                                                  'dense_1[0][0]',                \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           65600       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           2080        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 3)            99          ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,281,475\n",
      "Trainable params: 5,587,523\n",
      "Non-trainable params: 2,693,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_maker(num_class, input_shape=(224, 224, 3)):\n",
    "    base_model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=input_shape , weights='imagenet')\n",
    "    base_model2 = tf.keras.applications.MobileNetV2( include_top=False, input_shape=input_shape , weights='imagenet')\n",
    "    base_model3 = tf.keras.applications.MobileNetV2( include_top=False, input_shape=input_shape , weights='imagenet')\n",
    "    # print(len(base_model.layers))\n",
    "    base_model._name = 'mobilenetv2_1'\n",
    "    base_model2._name = 'mobilenetv2_2'\n",
    "    base_model3._name = 'mobilenetv2_3'\n",
    " \n",
    "\n",
    "    # base_model.trainable = True\n",
    "    for layer in base_model.layers[:130]:\n",
    "        layer.trainable = False \n",
    "    for layer in base_model2.layers[:130]:\n",
    "        layer.trainable = False \n",
    "    for layer in base_model3.layers[:130]:\n",
    "        layer.trainable = False \n",
    "            \n",
    "    sat_input = tf.keras.Input(shape=input_shape)\n",
    "    sat_custom_model = base_model(sat_input)\n",
    "    sat_custom_model = tf.keras.layers.GlobalAveragePooling2D()(sat_custom_model)\n",
    "    sat_custom_model = tf.keras.layers.Dropout(0.2)(sat_custom_model)\n",
    "    sat_custom_model = tf.keras.layers.Dense(256, activation='relu')(sat_custom_model)\n",
    "\n",
    "    dem_input = tf.keras.Input(shape=input_shape)\n",
    "    dem_custom_model = base_model2(dem_input)\n",
    "    dem_custom_model = tf.keras.layers.GlobalAveragePooling2D()(dem_custom_model)\n",
    "    dem_custom_model = tf.keras.layers.Dropout(0.2)(dem_custom_model)\n",
    "    dem_custom_model = tf.keras.layers.Dense(256, activation='relu')(dem_custom_model)  \n",
    "\n",
    "    road_input = tf.keras.Input(shape=input_shape)\n",
    "    road_custom_model = base_model3(road_input)\n",
    "    road_custom_model = tf.keras.layers.GlobalAveragePooling2D()(road_custom_model)\n",
    "    road_custom_model = tf.keras.layers.Dropout(0.2)(road_custom_model)\n",
    "    road_custom_model = tf.keras.layers.Dense(256, activation='relu')(road_custom_model)\n",
    "\n",
    "    sum_custom_model = tf.keras.layers.concatenate([sat_input, road_input, dem_input])\n",
    "    sum_custom_model = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(sum_custom_model)\n",
    "    sum_custom_model = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(sum_custom_model)\n",
    "    sum_custom_model =  tf.keras.layers.MaxPool2D(pool_size=(2, 2))(sum_custom_model)\n",
    "    sum_custom_model = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(sum_custom_model)\n",
    "    sum_custom_model =  tf.keras.layers.MaxPool2D(pool_size=(2, 2))(sum_custom_model)\n",
    "    sum_custom_model = tf.keras.layers.Conv2D(256, (3, 3), activation='relu')(sum_custom_model)\n",
    "    sum_custom_model = tf.keras.layers.GlobalAveragePooling2D()(sum_custom_model)\n",
    "    sum_custom_model = tf.keras.layers.Dropout(0.2)(sum_custom_model)\n",
    "    sum_custom_model = tf.keras.layers.Dense(256, activation='relu')(sum_custom_model)\n",
    "\n",
    "\n",
    "    custom_model = tf.keras.layers.concatenate([sat_custom_model, dem_custom_model, road_custom_model, sum_custom_model])\n",
    "    custom_model = tf.keras.layers.Dense(64, activation='relu')(custom_model)\n",
    "\n",
    "    custom_model = tf.keras.layers.Dense(32, activation='relu')(custom_model)\n",
    "    predictions = tf.keras.layers.Dense(num_class, activation='softmax')(custom_model)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[sat_input, dem_input, road_input], outputs=predictions)\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "      tf.keras.metrics.CategoricalAccuracy(name='accuracy')\n",
    "]\n",
    "\n",
    "model_final = model_maker(3, input_shape=(IMG_HEIGHT, IMG_HEIGHT, 3))\n",
    "model_final.summary()\n",
    "model_final.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1ca3fd44e20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = f\"../{NAME}_mob3i_RESULT/cp-{EPOCH:04d}.ckpt\"   # 3\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 monitor='val_accuracy',\n",
    "                                                 mode='max',\n",
    "                                                 save_best_only=True)\n",
    "# latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "# model_final.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import model_to_dot\n",
    "\n",
    "dot_res = model_to_dot(model_final,show_shapes=True, dpi=50).create(prog='dot', format='svg')\n",
    "fi = open(\"dotres.svg\", 'wb')\n",
    "fi.write(dot_res)\n",
    "fi.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.9099 - tp: 5680.0000 - fp: 2454.0000 - tn: 29270.0000 - fn: 10182.0000 - precision: 0.6983 - recall: 0.3581 - auc: 0.7633 - prc: 0.6569 - accuracy: 0.5577\n",
      "Epoch 1: val_accuracy improved from -inf to 0.57359, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 75s 243ms/step - loss: 0.9099 - tp: 5680.0000 - fp: 2454.0000 - tn: 29270.0000 - fn: 10182.0000 - precision: 0.6983 - recall: 0.3581 - auc: 0.7633 - prc: 0.6569 - accuracy: 0.5577 - val_loss: 1.1008 - val_tp: 955.0000 - val_fp: 538.0000 - val_tn: 3430.0000 - val_fn: 1029.0000 - val_precision: 0.6397 - val_recall: 0.4814 - val_auc: 0.7160 - val_prc: 0.6288 - val_accuracy: 0.5736\n",
      "Epoch 2/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.8422 - tp: 6930.0000 - fp: 2973.0000 - tn: 28751.0000 - fn: 8932.0000 - precision: 0.6998 - recall: 0.4369 - auc: 0.8064 - prc: 0.7080 - accuracy: 0.5923\n",
      "Epoch 2: val_accuracy improved from 0.57359 to 0.62298, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.8422 - tp: 6930.0000 - fp: 2973.0000 - tn: 28751.0000 - fn: 8932.0000 - precision: 0.6998 - recall: 0.4369 - auc: 0.8064 - prc: 0.7080 - accuracy: 0.5923 - val_loss: 0.8936 - val_tp: 1057.0000 - val_fp: 526.0000 - val_tn: 3442.0000 - val_fn: 927.0000 - val_precision: 0.6677 - val_recall: 0.5328 - val_auc: 0.7869 - val_prc: 0.6947 - val_accuracy: 0.6230\n",
      "Epoch 3/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.8135 - tp: 7298.0000 - fp: 2990.0000 - tn: 28734.0000 - fn: 8564.0000 - precision: 0.7094 - recall: 0.4601 - auc: 0.8207 - prc: 0.7251 - accuracy: 0.6121\n",
      "Epoch 3: val_accuracy improved from 0.62298 to 0.64214, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.8135 - tp: 7298.0000 - fp: 2990.0000 - tn: 28734.0000 - fn: 8564.0000 - precision: 0.7094 - recall: 0.4601 - auc: 0.8207 - prc: 0.7251 - accuracy: 0.6121 - val_loss: 0.8269 - val_tp: 1174.0000 - val_fp: 590.0000 - val_tn: 3378.0000 - val_fn: 810.0000 - val_precision: 0.6655 - val_recall: 0.5917 - val_auc: 0.8215 - val_prc: 0.7330 - val_accuracy: 0.6421\n",
      "Epoch 4/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7987 - tp: 7742.0000 - fp: 3305.0000 - tn: 28419.0000 - fn: 8120.0000 - precision: 0.7008 - recall: 0.4881 - auc: 0.8282 - prc: 0.7346 - accuracy: 0.6205\n",
      "Epoch 4: val_accuracy did not improve from 0.64214\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.7987 - tp: 7742.0000 - fp: 3305.0000 - tn: 28419.0000 - fn: 8120.0000 - precision: 0.7008 - recall: 0.4881 - auc: 0.8282 - prc: 0.7346 - accuracy: 0.6205 - val_loss: 0.9839 - val_tp: 1116.0000 - val_fp: 682.0000 - val_tn: 3286.0000 - val_fn: 868.0000 - val_precision: 0.6207 - val_recall: 0.5625 - val_auc: 0.7756 - val_prc: 0.6770 - val_accuracy: 0.5948\n",
      "Epoch 5/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7819 - tp: 8062.0000 - fp: 3298.0000 - tn: 28426.0000 - fn: 7800.0000 - precision: 0.7097 - recall: 0.5083 - auc: 0.8368 - prc: 0.7456 - accuracy: 0.6287\n",
      "Epoch 5: val_accuracy did not improve from 0.64214\n",
      "248/248 [==============================] - 58s 229ms/step - loss: 0.7819 - tp: 8062.0000 - fp: 3298.0000 - tn: 28426.0000 - fn: 7800.0000 - precision: 0.7097 - recall: 0.5083 - auc: 0.8368 - prc: 0.7456 - accuracy: 0.6287 - val_loss: 0.8911 - val_tp: 1125.0000 - val_fp: 632.0000 - val_tn: 3336.0000 - val_fn: 859.0000 - val_precision: 0.6403 - val_recall: 0.5670 - val_auc: 0.8088 - val_prc: 0.7154 - val_accuracy: 0.6109\n",
      "Epoch 6/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7691 - tp: 8196.0000 - fp: 3399.0000 - tn: 28325.0000 - fn: 7666.0000 - precision: 0.7069 - recall: 0.5167 - auc: 0.8402 - prc: 0.7492 - accuracy: 0.6326\n",
      "Epoch 6: val_accuracy improved from 0.64214 to 0.70161, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.7691 - tp: 8196.0000 - fp: 3399.0000 - tn: 28325.0000 - fn: 7666.0000 - precision: 0.7069 - recall: 0.5167 - auc: 0.8402 - prc: 0.7492 - accuracy: 0.6326 - val_loss: 0.7084 - val_tp: 1328.0000 - val_fp: 498.0000 - val_tn: 3470.0000 - val_fn: 656.0000 - val_precision: 0.7273 - val_recall: 0.6694 - val_auc: 0.8684 - val_prc: 0.7937 - val_accuracy: 0.7016\n",
      "Epoch 7/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7613 - tp: 8387.0000 - fp: 3414.0000 - tn: 28310.0000 - fn: 7475.0000 - precision: 0.7107 - recall: 0.5287 - auc: 0.8447 - prc: 0.7564 - accuracy: 0.6323\n",
      "Epoch 7: val_accuracy improved from 0.70161 to 0.70665, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 240ms/step - loss: 0.7613 - tp: 8387.0000 - fp: 3414.0000 - tn: 28310.0000 - fn: 7475.0000 - precision: 0.7107 - recall: 0.5287 - auc: 0.8447 - prc: 0.7564 - accuracy: 0.6323 - val_loss: 0.6857 - val_tp: 1348.0000 - val_fp: 494.0000 - val_tn: 3474.0000 - val_fn: 636.0000 - val_precision: 0.7318 - val_recall: 0.6794 - val_auc: 0.8717 - val_prc: 0.7912 - val_accuracy: 0.7067\n",
      "Epoch 8/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7493 - tp: 8620.0000 - fp: 3316.0000 - tn: 28408.0000 - fn: 7242.0000 - precision: 0.7222 - recall: 0.5434 - auc: 0.8513 - prc: 0.7650 - accuracy: 0.6524\n",
      "Epoch 8: val_accuracy did not improve from 0.70665\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.7493 - tp: 8620.0000 - fp: 3316.0000 - tn: 28408.0000 - fn: 7242.0000 - precision: 0.7222 - recall: 0.5434 - auc: 0.8513 - prc: 0.7650 - accuracy: 0.6524 - val_loss: 0.6975 - val_tp: 1223.0000 - val_fp: 490.0000 - val_tn: 3478.0000 - val_fn: 761.0000 - val_precision: 0.7140 - val_recall: 0.6164 - val_auc: 0.8629 - val_prc: 0.7813 - val_accuracy: 0.6845\n",
      "Epoch 9/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7290 - tp: 8933.0000 - fp: 3399.0000 - tn: 28325.0000 - fn: 6929.0000 - precision: 0.7244 - recall: 0.5632 - auc: 0.8603 - prc: 0.7764 - accuracy: 0.6662\n",
      "Epoch 9: val_accuracy improved from 0.70665 to 0.71270, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.7290 - tp: 8933.0000 - fp: 3399.0000 - tn: 28325.0000 - fn: 6929.0000 - precision: 0.7244 - recall: 0.5632 - auc: 0.8603 - prc: 0.7764 - accuracy: 0.6662 - val_loss: 0.6399 - val_tp: 1294.0000 - val_fp: 442.0000 - val_tn: 3526.0000 - val_fn: 690.0000 - val_precision: 0.7454 - val_recall: 0.6522 - val_auc: 0.8863 - val_prc: 0.8127 - val_accuracy: 0.7127\n",
      "Epoch 10/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7272 - tp: 9099.0000 - fp: 3468.0000 - tn: 28256.0000 - fn: 6763.0000 - precision: 0.7240 - recall: 0.5736 - auc: 0.8604 - prc: 0.7773 - accuracy: 0.6649\n",
      "Epoch 10: val_accuracy improved from 0.71270 to 0.72933, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.7272 - tp: 9099.0000 - fp: 3468.0000 - tn: 28256.0000 - fn: 6763.0000 - precision: 0.7240 - recall: 0.5736 - auc: 0.8604 - prc: 0.7773 - accuracy: 0.6649 - val_loss: 0.6397 - val_tp: 1367.0000 - val_fp: 455.0000 - val_tn: 3513.0000 - val_fn: 617.0000 - val_precision: 0.7503 - val_recall: 0.6890 - val_auc: 0.8926 - val_prc: 0.8204 - val_accuracy: 0.7293\n",
      "Epoch 11/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7153 - tp: 9270.0000 - fp: 3518.0000 - tn: 28206.0000 - fn: 6592.0000 - precision: 0.7249 - recall: 0.5844 - auc: 0.8639 - prc: 0.7825 - accuracy: 0.6726\n",
      "Epoch 11: val_accuracy improved from 0.72933 to 0.73488, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.7153 - tp: 9270.0000 - fp: 3518.0000 - tn: 28206.0000 - fn: 6592.0000 - precision: 0.7249 - recall: 0.5844 - auc: 0.8639 - prc: 0.7825 - accuracy: 0.6726 - val_loss: 0.6333 - val_tp: 1352.0000 - val_fp: 425.0000 - val_tn: 3543.0000 - val_fn: 632.0000 - val_precision: 0.7608 - val_recall: 0.6815 - val_auc: 0.8938 - val_prc: 0.8236 - val_accuracy: 0.7349\n",
      "Epoch 12/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.7069 - tp: 9387.0000 - fp: 3445.0000 - tn: 28279.0000 - fn: 6475.0000 - precision: 0.7315 - recall: 0.5918 - auc: 0.8688 - prc: 0.7897 - accuracy: 0.6774\n",
      "Epoch 12: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 58s 229ms/step - loss: 0.7069 - tp: 9387.0000 - fp: 3445.0000 - tn: 28279.0000 - fn: 6475.0000 - precision: 0.7315 - recall: 0.5918 - auc: 0.8688 - prc: 0.7897 - accuracy: 0.6774 - val_loss: 0.7424 - val_tp: 1194.0000 - val_fp: 557.0000 - val_tn: 3411.0000 - val_fn: 790.0000 - val_precision: 0.6819 - val_recall: 0.6018 - val_auc: 0.8544 - val_prc: 0.7714 - val_accuracy: 0.6512\n",
      "Epoch 13/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6910 - tp: 9595.0000 - fp: 3450.0000 - tn: 28274.0000 - fn: 6267.0000 - precision: 0.7355 - recall: 0.6049 - auc: 0.8740 - prc: 0.7970 - accuracy: 0.6855\n",
      "Epoch 13: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 62s 242ms/step - loss: 0.6910 - tp: 9595.0000 - fp: 3450.0000 - tn: 28274.0000 - fn: 6267.0000 - precision: 0.7355 - recall: 0.6049 - auc: 0.8740 - prc: 0.7970 - accuracy: 0.6855 - val_loss: 0.6812 - val_tp: 1285.0000 - val_fp: 500.0000 - val_tn: 3468.0000 - val_fn: 699.0000 - val_precision: 0.7199 - val_recall: 0.6477 - val_auc: 0.8737 - val_prc: 0.7946 - val_accuracy: 0.6870\n",
      "Epoch 14/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6981 - tp: 9495.0000 - fp: 3492.0000 - tn: 28232.0000 - fn: 6367.0000 - precision: 0.7311 - recall: 0.5986 - auc: 0.8709 - prc: 0.7932 - accuracy: 0.6751\n",
      "Epoch 14: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.6981 - tp: 9495.0000 - fp: 3492.0000 - tn: 28232.0000 - fn: 6367.0000 - precision: 0.7311 - recall: 0.5986 - auc: 0.8709 - prc: 0.7932 - accuracy: 0.6751 - val_loss: 0.6618 - val_tp: 1278.0000 - val_fp: 478.0000 - val_tn: 3490.0000 - val_fn: 706.0000 - val_precision: 0.7278 - val_recall: 0.6442 - val_auc: 0.8809 - val_prc: 0.8032 - val_accuracy: 0.6920\n",
      "Epoch 15/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6743 - tp: 9831.0000 - fp: 3348.0000 - tn: 28376.0000 - fn: 6031.0000 - precision: 0.7460 - recall: 0.6198 - auc: 0.8819 - prc: 0.8079 - accuracy: 0.6991\n",
      "Epoch 15: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.6743 - tp: 9831.0000 - fp: 3348.0000 - tn: 28376.0000 - fn: 6031.0000 - precision: 0.7460 - recall: 0.6198 - auc: 0.8819 - prc: 0.8079 - accuracy: 0.6991 - val_loss: 0.8149 - val_tp: 1174.0000 - val_fp: 633.0000 - val_tn: 3335.0000 - val_fn: 810.0000 - val_precision: 0.6497 - val_recall: 0.5917 - val_auc: 0.8346 - val_prc: 0.7402 - val_accuracy: 0.6300\n",
      "Epoch 16/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6715 - tp: 9967.0000 - fp: 3470.0000 - tn: 28254.0000 - fn: 5895.0000 - precision: 0.7418 - recall: 0.6284 - auc: 0.8815 - prc: 0.8074 - accuracy: 0.6985\n",
      "Epoch 16: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 61s 239ms/step - loss: 0.6715 - tp: 9967.0000 - fp: 3470.0000 - tn: 28254.0000 - fn: 5895.0000 - precision: 0.7418 - recall: 0.6284 - auc: 0.8815 - prc: 0.8074 - accuracy: 0.6985 - val_loss: 0.6458 - val_tp: 1290.0000 - val_fp: 461.0000 - val_tn: 3507.0000 - val_fn: 694.0000 - val_precision: 0.7367 - val_recall: 0.6502 - val_auc: 0.8847 - val_prc: 0.8112 - val_accuracy: 0.7051\n",
      "Epoch 17/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6624 - tp: 10071.0000 - fp: 3413.0000 - tn: 28311.0000 - fn: 5791.0000 - precision: 0.7469 - recall: 0.6349 - auc: 0.8856 - prc: 0.8137 - accuracy: 0.7023\n",
      "Epoch 17: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.6624 - tp: 10071.0000 - fp: 3413.0000 - tn: 28311.0000 - fn: 5791.0000 - precision: 0.7469 - recall: 0.6349 - auc: 0.8856 - prc: 0.8137 - accuracy: 0.7023 - val_loss: 0.6470 - val_tp: 1374.0000 - val_fp: 488.0000 - val_tn: 3480.0000 - val_fn: 610.0000 - val_precision: 0.7379 - val_recall: 0.6925 - val_auc: 0.8931 - val_prc: 0.8277 - val_accuracy: 0.7193\n",
      "Epoch 18/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6570 - tp: 10158.0000 - fp: 3406.0000 - tn: 28318.0000 - fn: 5704.0000 - precision: 0.7489 - recall: 0.6404 - auc: 0.8875 - prc: 0.8171 - accuracy: 0.7070\n",
      "Epoch 18: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.6570 - tp: 10158.0000 - fp: 3406.0000 - tn: 28318.0000 - fn: 5704.0000 - precision: 0.7489 - recall: 0.6404 - auc: 0.8875 - prc: 0.8171 - accuracy: 0.7070 - val_loss: 0.6587 - val_tp: 1405.0000 - val_fp: 482.0000 - val_tn: 3486.0000 - val_fn: 579.0000 - val_precision: 0.7446 - val_recall: 0.7082 - val_auc: 0.8915 - val_prc: 0.8248 - val_accuracy: 0.7283\n",
      "Epoch 19/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6495 - tp: 10395.0000 - fp: 3311.0000 - tn: 28413.0000 - fn: 5467.0000 - precision: 0.7584 - recall: 0.6553 - auc: 0.8911 - prc: 0.8219 - accuracy: 0.7130\n",
      "Epoch 19: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 62s 245ms/step - loss: 0.6495 - tp: 10395.0000 - fp: 3311.0000 - tn: 28413.0000 - fn: 5467.0000 - precision: 0.7584 - recall: 0.6553 - auc: 0.8911 - prc: 0.8219 - accuracy: 0.7130 - val_loss: 0.7750 - val_tp: 1313.0000 - val_fp: 563.0000 - val_tn: 3405.0000 - val_fn: 671.0000 - val_precision: 0.6999 - val_recall: 0.6618 - val_auc: 0.8561 - val_prc: 0.7789 - val_accuracy: 0.6794\n",
      "Epoch 20/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6445 - tp: 10301.0000 - fp: 3380.0000 - tn: 28344.0000 - fn: 5561.0000 - precision: 0.7529 - recall: 0.6494 - auc: 0.8914 - prc: 0.8222 - accuracy: 0.7114\n",
      "Epoch 20: val_accuracy did not improve from 0.73488\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.6445 - tp: 10301.0000 - fp: 3380.0000 - tn: 28344.0000 - fn: 5561.0000 - precision: 0.7529 - recall: 0.6494 - auc: 0.8914 - prc: 0.8222 - accuracy: 0.7114 - val_loss: 0.6465 - val_tp: 1375.0000 - val_fp: 468.0000 - val_tn: 3500.0000 - val_fn: 609.0000 - val_precision: 0.7461 - val_recall: 0.6930 - val_auc: 0.8928 - val_prc: 0.8304 - val_accuracy: 0.7218\n",
      "Epoch 21/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6354 - tp: 10434.0000 - fp: 3361.0000 - tn: 28363.0000 - fn: 5428.0000 - precision: 0.7564 - recall: 0.6578 - auc: 0.8940 - prc: 0.8269 - accuracy: 0.7161\n",
      "Epoch 21: val_accuracy improved from 0.73488 to 0.73942, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.6354 - tp: 10434.0000 - fp: 3361.0000 - tn: 28363.0000 - fn: 5428.0000 - precision: 0.7564 - recall: 0.6578 - auc: 0.8940 - prc: 0.8269 - accuracy: 0.7161 - val_loss: 0.5790 - val_tp: 1372.0000 - val_fp: 419.0000 - val_tn: 3549.0000 - val_fn: 612.0000 - val_precision: 0.7661 - val_recall: 0.6915 - val_auc: 0.9072 - val_prc: 0.8443 - val_accuracy: 0.7394\n",
      "Epoch 22/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6254 - tp: 10611.0000 - fp: 3273.0000 - tn: 28451.0000 - fn: 5251.0000 - precision: 0.7643 - recall: 0.6690 - auc: 0.8988 - prc: 0.8340 - accuracy: 0.7237\n",
      "Epoch 22: val_accuracy did not improve from 0.73942\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.6254 - tp: 10611.0000 - fp: 3273.0000 - tn: 28451.0000 - fn: 5251.0000 - precision: 0.7643 - recall: 0.6690 - auc: 0.8988 - prc: 0.8340 - accuracy: 0.7237 - val_loss: 0.6198 - val_tp: 1365.0000 - val_fp: 424.0000 - val_tn: 3544.0000 - val_fn: 619.0000 - val_precision: 0.7630 - val_recall: 0.6880 - val_auc: 0.8997 - val_prc: 0.8331 - val_accuracy: 0.7329\n",
      "Epoch 23/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6144 - tp: 10727.0000 - fp: 3230.0000 - tn: 28494.0000 - fn: 5135.0000 - precision: 0.7686 - recall: 0.6763 - auc: 0.9028 - prc: 0.8401 - accuracy: 0.7295\n",
      "Epoch 23: val_accuracy improved from 0.73942 to 0.75000, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.6144 - tp: 10727.0000 - fp: 3230.0000 - tn: 28494.0000 - fn: 5135.0000 - precision: 0.7686 - recall: 0.6763 - auc: 0.9028 - prc: 0.8401 - accuracy: 0.7295 - val_loss: 0.5915 - val_tp: 1433.0000 - val_fp: 417.0000 - val_tn: 3551.0000 - val_fn: 551.0000 - val_precision: 0.7746 - val_recall: 0.7223 - val_auc: 0.9095 - val_prc: 0.8490 - val_accuracy: 0.7500\n",
      "Epoch 24/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6134 - tp: 10827.0000 - fp: 3206.0000 - tn: 28518.0000 - fn: 5035.0000 - precision: 0.7715 - recall: 0.6826 - auc: 0.9032 - prc: 0.8406 - accuracy: 0.7341\n",
      "Epoch 24: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.6134 - tp: 10827.0000 - fp: 3206.0000 - tn: 28518.0000 - fn: 5035.0000 - precision: 0.7715 - recall: 0.6826 - auc: 0.9032 - prc: 0.8406 - accuracy: 0.7341 - val_loss: 0.6099 - val_tp: 1436.0000 - val_fp: 447.0000 - val_tn: 3521.0000 - val_fn: 548.0000 - val_precision: 0.7626 - val_recall: 0.7238 - val_auc: 0.9076 - val_prc: 0.8441 - val_accuracy: 0.7455\n",
      "Epoch 25/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.6049 - tp: 10859.0000 - fp: 3221.0000 - tn: 28503.0000 - fn: 5003.0000 - precision: 0.7712 - recall: 0.6846 - auc: 0.9050 - prc: 0.8429 - accuracy: 0.7333\n",
      "Epoch 25: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 59s 229ms/step - loss: 0.6049 - tp: 10859.0000 - fp: 3221.0000 - tn: 28503.0000 - fn: 5003.0000 - precision: 0.7712 - recall: 0.6846 - auc: 0.9050 - prc: 0.8429 - accuracy: 0.7333 - val_loss: 0.6717 - val_tp: 1372.0000 - val_fp: 503.0000 - val_tn: 3465.0000 - val_fn: 612.0000 - val_precision: 0.7317 - val_recall: 0.6915 - val_auc: 0.8849 - val_prc: 0.8146 - val_accuracy: 0.7112\n",
      "Epoch 26/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5934 - tp: 11034.0000 - fp: 3115.0000 - tn: 28609.0000 - fn: 4828.0000 - precision: 0.7798 - recall: 0.6956 - auc: 0.9090 - prc: 0.8490 - accuracy: 0.7449\n",
      "Epoch 26: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.5934 - tp: 11034.0000 - fp: 3115.0000 - tn: 28609.0000 - fn: 4828.0000 - precision: 0.7798 - recall: 0.6956 - auc: 0.9090 - prc: 0.8490 - accuracy: 0.7449 - val_loss: 0.6349 - val_tp: 1376.0000 - val_fp: 483.0000 - val_tn: 3485.0000 - val_fn: 608.0000 - val_precision: 0.7402 - val_recall: 0.6935 - val_auc: 0.8959 - val_prc: 0.8320 - val_accuracy: 0.7193\n",
      "Epoch 27/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5851 - tp: 11168.0000 - fp: 3158.0000 - tn: 28566.0000 - fn: 4694.0000 - precision: 0.7796 - recall: 0.7041 - auc: 0.9108 - prc: 0.8511 - accuracy: 0.7469\n",
      "Epoch 27: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.5851 - tp: 11168.0000 - fp: 3158.0000 - tn: 28566.0000 - fn: 4694.0000 - precision: 0.7796 - recall: 0.7041 - auc: 0.9108 - prc: 0.8511 - accuracy: 0.7469 - val_loss: 0.6660 - val_tp: 1424.0000 - val_fp: 474.0000 - val_tn: 3494.0000 - val_fn: 560.0000 - val_precision: 0.7503 - val_recall: 0.7177 - val_auc: 0.8945 - val_prc: 0.8266 - val_accuracy: 0.7374\n",
      "Epoch 28/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5831 - tp: 11147.0000 - fp: 3113.0000 - tn: 28611.0000 - fn: 4715.0000 - precision: 0.7817 - recall: 0.7027 - auc: 0.9128 - prc: 0.8548 - accuracy: 0.7486\n",
      "Epoch 28: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.5831 - tp: 11147.0000 - fp: 3113.0000 - tn: 28611.0000 - fn: 4715.0000 - precision: 0.7817 - recall: 0.7027 - auc: 0.9128 - prc: 0.8548 - accuracy: 0.7486 - val_loss: 0.6398 - val_tp: 1385.0000 - val_fp: 472.0000 - val_tn: 3496.0000 - val_fn: 599.0000 - val_precision: 0.7458 - val_recall: 0.6981 - val_auc: 0.8929 - val_prc: 0.8233 - val_accuracy: 0.7248\n",
      "Epoch 29/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5747 - tp: 11227.0000 - fp: 3112.0000 - tn: 28612.0000 - fn: 4635.0000 - precision: 0.7830 - recall: 0.7078 - auc: 0.9141 - prc: 0.8572 - accuracy: 0.7514\n",
      "Epoch 29: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.5747 - tp: 11227.0000 - fp: 3112.0000 - tn: 28612.0000 - fn: 4635.0000 - precision: 0.7830 - recall: 0.7078 - auc: 0.9141 - prc: 0.8572 - accuracy: 0.7514 - val_loss: 0.6579 - val_tp: 1409.0000 - val_fp: 490.0000 - val_tn: 3478.0000 - val_fn: 575.0000 - val_precision: 0.7420 - val_recall: 0.7102 - val_auc: 0.8941 - val_prc: 0.8266 - val_accuracy: 0.7248\n",
      "Epoch 30/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5703 - tp: 11343.0000 - fp: 3093.0000 - tn: 28631.0000 - fn: 4519.0000 - precision: 0.7857 - recall: 0.7151 - auc: 0.9158 - prc: 0.8590 - accuracy: 0.7565\n",
      "Epoch 30: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 59s 229ms/step - loss: 0.5703 - tp: 11343.0000 - fp: 3093.0000 - tn: 28631.0000 - fn: 4519.0000 - precision: 0.7857 - recall: 0.7151 - auc: 0.9158 - prc: 0.8590 - accuracy: 0.7565 - val_loss: 0.6221 - val_tp: 1437.0000 - val_fp: 471.0000 - val_tn: 3497.0000 - val_fn: 547.0000 - val_precision: 0.7531 - val_recall: 0.7243 - val_auc: 0.9045 - val_prc: 0.8411 - val_accuracy: 0.7399\n",
      "Epoch 31/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5646 - tp: 11381.0000 - fp: 3033.0000 - tn: 28691.0000 - fn: 4481.0000 - precision: 0.7896 - recall: 0.7175 - auc: 0.9186 - prc: 0.8643 - accuracy: 0.7582\n",
      "Epoch 31: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.5646 - tp: 11381.0000 - fp: 3033.0000 - tn: 28691.0000 - fn: 4481.0000 - precision: 0.7896 - recall: 0.7175 - auc: 0.9186 - prc: 0.8643 - accuracy: 0.7582 - val_loss: 0.5976 - val_tp: 1448.0000 - val_fp: 429.0000 - val_tn: 3539.0000 - val_fn: 536.0000 - val_precision: 0.7714 - val_recall: 0.7298 - val_auc: 0.9107 - val_prc: 0.8485 - val_accuracy: 0.7485\n",
      "Epoch 32/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5600 - tp: 11413.0000 - fp: 2980.0000 - tn: 28744.0000 - fn: 4449.0000 - precision: 0.7930 - recall: 0.7195 - auc: 0.9200 - prc: 0.8653 - accuracy: 0.7611\n",
      "Epoch 32: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.5600 - tp: 11413.0000 - fp: 2980.0000 - tn: 28744.0000 - fn: 4449.0000 - precision: 0.7930 - recall: 0.7195 - auc: 0.9200 - prc: 0.8653 - accuracy: 0.7611 - val_loss: 0.6314 - val_tp: 1431.0000 - val_fp: 464.0000 - val_tn: 3504.0000 - val_fn: 553.0000 - val_precision: 0.7551 - val_recall: 0.7213 - val_auc: 0.9040 - val_prc: 0.8401 - val_accuracy: 0.7359\n",
      "Epoch 33/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5529 - tp: 11500.0000 - fp: 2968.0000 - tn: 28756.0000 - fn: 4362.0000 - precision: 0.7949 - recall: 0.7250 - auc: 0.9210 - prc: 0.8676 - accuracy: 0.7640\n",
      "Epoch 33: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.5529 - tp: 11500.0000 - fp: 2968.0000 - tn: 28756.0000 - fn: 4362.0000 - precision: 0.7949 - recall: 0.7250 - auc: 0.9210 - prc: 0.8676 - accuracy: 0.7640 - val_loss: 0.6098 - val_tp: 1434.0000 - val_fp: 460.0000 - val_tn: 3508.0000 - val_fn: 550.0000 - val_precision: 0.7571 - val_recall: 0.7228 - val_auc: 0.9089 - val_prc: 0.8482 - val_accuracy: 0.7404\n",
      "Epoch 34/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5441 - tp: 11609.0000 - fp: 2825.0000 - tn: 28899.0000 - fn: 4253.0000 - precision: 0.8043 - recall: 0.7319 - auc: 0.9238 - prc: 0.8724 - accuracy: 0.7717\n",
      "Epoch 34: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 229ms/step - loss: 0.5441 - tp: 11609.0000 - fp: 2825.0000 - tn: 28899.0000 - fn: 4253.0000 - precision: 0.8043 - recall: 0.7319 - auc: 0.9238 - prc: 0.8724 - accuracy: 0.7717 - val_loss: 0.6538 - val_tp: 1425.0000 - val_fp: 484.0000 - val_tn: 3484.0000 - val_fn: 559.0000 - val_precision: 0.7465 - val_recall: 0.7182 - val_auc: 0.9018 - val_prc: 0.8402 - val_accuracy: 0.7379\n",
      "Epoch 35/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5409 - tp: 11593.0000 - fp: 2950.0000 - tn: 28774.0000 - fn: 4269.0000 - precision: 0.7972 - recall: 0.7309 - auc: 0.9236 - prc: 0.8717 - accuracy: 0.7687\n",
      "Epoch 35: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.5409 - tp: 11593.0000 - fp: 2950.0000 - tn: 28774.0000 - fn: 4269.0000 - precision: 0.7972 - recall: 0.7309 - auc: 0.9236 - prc: 0.8717 - accuracy: 0.7687 - val_loss: 0.6406 - val_tp: 1393.0000 - val_fp: 489.0000 - val_tn: 3479.0000 - val_fn: 591.0000 - val_precision: 0.7402 - val_recall: 0.7021 - val_auc: 0.8983 - val_prc: 0.8329 - val_accuracy: 0.7248\n",
      "Epoch 36/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5250 - tp: 11758.0000 - fp: 2859.0000 - tn: 28865.0000 - fn: 4104.0000 - precision: 0.8044 - recall: 0.7413 - auc: 0.9287 - prc: 0.8794 - accuracy: 0.7760\n",
      "Epoch 36: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 229ms/step - loss: 0.5250 - tp: 11758.0000 - fp: 2859.0000 - tn: 28865.0000 - fn: 4104.0000 - precision: 0.8044 - recall: 0.7413 - auc: 0.9287 - prc: 0.8794 - accuracy: 0.7760 - val_loss: 0.6649 - val_tp: 1398.0000 - val_fp: 497.0000 - val_tn: 3471.0000 - val_fn: 586.0000 - val_precision: 0.7377 - val_recall: 0.7046 - val_auc: 0.8963 - val_prc: 0.8314 - val_accuracy: 0.7213\n",
      "Epoch 37/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5298 - tp: 11736.0000 - fp: 2907.0000 - tn: 28817.0000 - fn: 4126.0000 - precision: 0.8015 - recall: 0.7399 - auc: 0.9266 - prc: 0.8760 - accuracy: 0.7745\n",
      "Epoch 37: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.5298 - tp: 11736.0000 - fp: 2907.0000 - tn: 28817.0000 - fn: 4126.0000 - precision: 0.8015 - recall: 0.7399 - auc: 0.9266 - prc: 0.8760 - accuracy: 0.7745 - val_loss: 0.6091 - val_tp: 1429.0000 - val_fp: 461.0000 - val_tn: 3507.0000 - val_fn: 555.0000 - val_precision: 0.7561 - val_recall: 0.7203 - val_auc: 0.9060 - val_prc: 0.8455 - val_accuracy: 0.7424\n",
      "Epoch 38/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5248 - tp: 11858.0000 - fp: 2882.0000 - tn: 28842.0000 - fn: 4004.0000 - precision: 0.8045 - recall: 0.7476 - auc: 0.9295 - prc: 0.8805 - accuracy: 0.7794\n",
      "Epoch 38: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.5248 - tp: 11858.0000 - fp: 2882.0000 - tn: 28842.0000 - fn: 4004.0000 - precision: 0.8045 - recall: 0.7476 - auc: 0.9295 - prc: 0.8805 - accuracy: 0.7794 - val_loss: 0.7283 - val_tp: 1383.0000 - val_fp: 534.0000 - val_tn: 3434.0000 - val_fn: 601.0000 - val_precision: 0.7214 - val_recall: 0.6971 - val_auc: 0.8842 - val_prc: 0.8123 - val_accuracy: 0.7122\n",
      "Epoch 39/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5182 - tp: 11891.0000 - fp: 2835.0000 - tn: 28889.0000 - fn: 3971.0000 - precision: 0.8075 - recall: 0.7497 - auc: 0.9307 - prc: 0.8824 - accuracy: 0.7822\n",
      "Epoch 39: val_accuracy did not improve from 0.75000\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.5182 - tp: 11891.0000 - fp: 2835.0000 - tn: 28889.0000 - fn: 3971.0000 - precision: 0.8075 - recall: 0.7497 - auc: 0.9307 - prc: 0.8824 - accuracy: 0.7822 - val_loss: 0.6347 - val_tp: 1460.0000 - val_fp: 461.0000 - val_tn: 3507.0000 - val_fn: 524.0000 - val_precision: 0.7600 - val_recall: 0.7359 - val_auc: 0.9071 - val_prc: 0.8450 - val_accuracy: 0.7495\n",
      "Epoch 40/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5067 - tp: 11946.0000 - fp: 2781.0000 - tn: 28943.0000 - fn: 3916.0000 - precision: 0.8112 - recall: 0.7531 - auc: 0.9335 - prc: 0.8874 - accuracy: 0.7865\n",
      "Epoch 40: val_accuracy improved from 0.75000 to 0.75907, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 60s 237ms/step - loss: 0.5067 - tp: 11946.0000 - fp: 2781.0000 - tn: 28943.0000 - fn: 3916.0000 - precision: 0.8112 - recall: 0.7531 - auc: 0.9335 - prc: 0.8874 - accuracy: 0.7865 - val_loss: 0.5549 - val_tp: 1468.0000 - val_fp: 432.0000 - val_tn: 3536.0000 - val_fn: 516.0000 - val_precision: 0.7726 - val_recall: 0.7399 - val_auc: 0.9204 - val_prc: 0.8637 - val_accuracy: 0.7591\n",
      "Epoch 41/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5003 - tp: 12047.0000 - fp: 2774.0000 - tn: 28950.0000 - fn: 3815.0000 - precision: 0.8128 - recall: 0.7595 - auc: 0.9346 - prc: 0.8885 - accuracy: 0.7880\n",
      "Epoch 41: val_accuracy improved from 0.75907 to 0.76815, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 60s 237ms/step - loss: 0.5003 - tp: 12047.0000 - fp: 2774.0000 - tn: 28950.0000 - fn: 3815.0000 - precision: 0.8128 - recall: 0.7595 - auc: 0.9346 - prc: 0.8885 - accuracy: 0.7880 - val_loss: 0.5703 - val_tp: 1490.0000 - val_fp: 420.0000 - val_tn: 3548.0000 - val_fn: 494.0000 - val_precision: 0.7801 - val_recall: 0.7510 - val_auc: 0.9194 - val_prc: 0.8640 - val_accuracy: 0.7681\n",
      "Epoch 42/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.5006 - tp: 12053.0000 - fp: 2745.0000 - tn: 28979.0000 - fn: 3809.0000 - precision: 0.8145 - recall: 0.7599 - auc: 0.9350 - prc: 0.8896 - accuracy: 0.7897\n",
      "Epoch 42: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.5006 - tp: 12053.0000 - fp: 2745.0000 - tn: 28979.0000 - fn: 3809.0000 - precision: 0.8145 - recall: 0.7599 - auc: 0.9350 - prc: 0.8896 - accuracy: 0.7897 - val_loss: 0.5844 - val_tp: 1479.0000 - val_fp: 433.0000 - val_tn: 3535.0000 - val_fn: 505.0000 - val_precision: 0.7735 - val_recall: 0.7455 - val_auc: 0.9165 - val_prc: 0.8600 - val_accuracy: 0.7571\n",
      "Epoch 43/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4873 - tp: 12159.0000 - fp: 2647.0000 - tn: 29077.0000 - fn: 3703.0000 - precision: 0.8212 - recall: 0.7665 - auc: 0.9388 - prc: 0.8955 - accuracy: 0.7957\n",
      "Epoch 43: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.4873 - tp: 12159.0000 - fp: 2647.0000 - tn: 29077.0000 - fn: 3703.0000 - precision: 0.8212 - recall: 0.7665 - auc: 0.9388 - prc: 0.8955 - accuracy: 0.7957 - val_loss: 0.6243 - val_tp: 1460.0000 - val_fp: 461.0000 - val_tn: 3507.0000 - val_fn: 524.0000 - val_precision: 0.7600 - val_recall: 0.7359 - val_auc: 0.9092 - val_prc: 0.8476 - val_accuracy: 0.7495\n",
      "Epoch 44/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4871 - tp: 12171.0000 - fp: 2686.0000 - tn: 29038.0000 - fn: 3691.0000 - precision: 0.8192 - recall: 0.7673 - auc: 0.9384 - prc: 0.8949 - accuracy: 0.7942\n",
      "Epoch 44: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 59s 229ms/step - loss: 0.4871 - tp: 12171.0000 - fp: 2686.0000 - tn: 29038.0000 - fn: 3691.0000 - precision: 0.8192 - recall: 0.7673 - auc: 0.9384 - prc: 0.8949 - accuracy: 0.7942 - val_loss: 0.5650 - val_tp: 1494.0000 - val_fp: 437.0000 - val_tn: 3531.0000 - val_fn: 490.0000 - val_precision: 0.7737 - val_recall: 0.7530 - val_auc: 0.9225 - val_prc: 0.8681 - val_accuracy: 0.7631\n",
      "Epoch 45/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4918 - tp: 12109.0000 - fp: 2772.0000 - tn: 28952.0000 - fn: 3753.0000 - precision: 0.8137 - recall: 0.7634 - auc: 0.9373 - prc: 0.8931 - accuracy: 0.7909\n",
      "Epoch 45: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 58s 225ms/step - loss: 0.4918 - tp: 12109.0000 - fp: 2772.0000 - tn: 28952.0000 - fn: 3753.0000 - precision: 0.8137 - recall: 0.7634 - auc: 0.9373 - prc: 0.8931 - accuracy: 0.7909 - val_loss: 0.5810 - val_tp: 1491.0000 - val_fp: 432.0000 - val_tn: 3536.0000 - val_fn: 493.0000 - val_precision: 0.7754 - val_recall: 0.7515 - val_auc: 0.9174 - val_prc: 0.8605 - val_accuracy: 0.7671\n",
      "Epoch 46/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4827 - tp: 12219.0000 - fp: 2691.0000 - tn: 29033.0000 - fn: 3643.0000 - precision: 0.8195 - recall: 0.7703 - auc: 0.9397 - prc: 0.8968 - accuracy: 0.7971\n",
      "Epoch 46: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.4827 - tp: 12219.0000 - fp: 2691.0000 - tn: 29033.0000 - fn: 3643.0000 - precision: 0.8195 - recall: 0.7703 - auc: 0.9397 - prc: 0.8968 - accuracy: 0.7971 - val_loss: 0.5791 - val_tp: 1471.0000 - val_fp: 433.0000 - val_tn: 3535.0000 - val_fn: 513.0000 - val_precision: 0.7726 - val_recall: 0.7414 - val_auc: 0.9179 - val_prc: 0.8622 - val_accuracy: 0.7626\n",
      "Epoch 47/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4724 - tp: 12333.0000 - fp: 2566.0000 - tn: 29158.0000 - fn: 3529.0000 - precision: 0.8278 - recall: 0.7775 - auc: 0.9418 - prc: 0.8999 - accuracy: 0.8056\n",
      "Epoch 47: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.4724 - tp: 12333.0000 - fp: 2566.0000 - tn: 29158.0000 - fn: 3529.0000 - precision: 0.8278 - recall: 0.7775 - auc: 0.9418 - prc: 0.8999 - accuracy: 0.8056 - val_loss: 0.6311 - val_tp: 1465.0000 - val_fp: 458.0000 - val_tn: 3510.0000 - val_fn: 519.0000 - val_precision: 0.7618 - val_recall: 0.7384 - val_auc: 0.9092 - val_prc: 0.8502 - val_accuracy: 0.7515\n",
      "Epoch 48/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4701 - tp: 12323.0000 - fp: 2619.0000 - tn: 29105.0000 - fn: 3539.0000 - precision: 0.8247 - recall: 0.7769 - auc: 0.9421 - prc: 0.9006 - accuracy: 0.8029\n",
      "Epoch 48: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.4701 - tp: 12323.0000 - fp: 2619.0000 - tn: 29105.0000 - fn: 3539.0000 - precision: 0.8247 - recall: 0.7769 - auc: 0.9421 - prc: 0.9006 - accuracy: 0.8029 - val_loss: 0.7008 - val_tp: 1450.0000 - val_fp: 484.0000 - val_tn: 3484.0000 - val_fn: 534.0000 - val_precision: 0.7497 - val_recall: 0.7308 - val_auc: 0.8976 - val_prc: 0.8323 - val_accuracy: 0.7399\n",
      "Epoch 49/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4511 - tp: 12497.0000 - fp: 2492.0000 - tn: 29232.0000 - fn: 3365.0000 - precision: 0.8337 - recall: 0.7879 - auc: 0.9465 - prc: 0.9080 - accuracy: 0.8130\n",
      "Epoch 49: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.4511 - tp: 12497.0000 - fp: 2492.0000 - tn: 29232.0000 - fn: 3365.0000 - precision: 0.8337 - recall: 0.7879 - auc: 0.9465 - prc: 0.9080 - accuracy: 0.8130 - val_loss: 0.6147 - val_tp: 1466.0000 - val_fp: 456.0000 - val_tn: 3512.0000 - val_fn: 518.0000 - val_precision: 0.7627 - val_recall: 0.7389 - val_auc: 0.9131 - val_prc: 0.8548 - val_accuracy: 0.7555\n",
      "Epoch 50/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4541 - tp: 12452.0000 - fp: 2573.0000 - tn: 29151.0000 - fn: 3410.0000 - precision: 0.8288 - recall: 0.7850 - auc: 0.9456 - prc: 0.9065 - accuracy: 0.8070\n",
      "Epoch 50: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.4541 - tp: 12452.0000 - fp: 2573.0000 - tn: 29151.0000 - fn: 3410.0000 - precision: 0.8288 - recall: 0.7850 - auc: 0.9456 - prc: 0.9065 - accuracy: 0.8070 - val_loss: 0.6196 - val_tp: 1475.0000 - val_fp: 441.0000 - val_tn: 3527.0000 - val_fn: 509.0000 - val_precision: 0.7698 - val_recall: 0.7434 - val_auc: 0.9135 - val_prc: 0.8544 - val_accuracy: 0.7606\n",
      "Epoch 51/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4496 - tp: 12525.0000 - fp: 2500.0000 - tn: 29224.0000 - fn: 3337.0000 - precision: 0.8336 - recall: 0.7896 - auc: 0.9473 - prc: 0.9090 - accuracy: 0.8129\n",
      "Epoch 51: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 59s 229ms/step - loss: 0.4496 - tp: 12525.0000 - fp: 2500.0000 - tn: 29224.0000 - fn: 3337.0000 - precision: 0.8336 - recall: 0.7896 - auc: 0.9473 - prc: 0.9090 - accuracy: 0.8129 - val_loss: 0.6042 - val_tp: 1470.0000 - val_fp: 453.0000 - val_tn: 3515.0000 - val_fn: 514.0000 - val_precision: 0.7644 - val_recall: 0.7409 - val_auc: 0.9144 - val_prc: 0.8547 - val_accuracy: 0.7555\n",
      "Epoch 52/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4468 - tp: 12560.0000 - fp: 2449.0000 - tn: 29275.0000 - fn: 3302.0000 - precision: 0.8368 - recall: 0.7918 - auc: 0.9481 - prc: 0.9103 - accuracy: 0.8179\n",
      "Epoch 52: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.4468 - tp: 12560.0000 - fp: 2449.0000 - tn: 29275.0000 - fn: 3302.0000 - precision: 0.8368 - recall: 0.7918 - auc: 0.9481 - prc: 0.9103 - accuracy: 0.8179 - val_loss: 0.5872 - val_tp: 1487.0000 - val_fp: 430.0000 - val_tn: 3538.0000 - val_fn: 497.0000 - val_precision: 0.7757 - val_recall: 0.7495 - val_auc: 0.9193 - val_prc: 0.8648 - val_accuracy: 0.7616\n",
      "Epoch 53/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4392 - tp: 12553.0000 - fp: 2538.0000 - tn: 29186.0000 - fn: 3309.0000 - precision: 0.8318 - recall: 0.7914 - auc: 0.9490 - prc: 0.9115 - accuracy: 0.8126\n",
      "Epoch 53: val_accuracy did not improve from 0.76815\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.4392 - tp: 12553.0000 - fp: 2538.0000 - tn: 29186.0000 - fn: 3309.0000 - precision: 0.8318 - recall: 0.7914 - auc: 0.9490 - prc: 0.9115 - accuracy: 0.8126 - val_loss: 0.5905 - val_tp: 1499.0000 - val_fp: 442.0000 - val_tn: 3526.0000 - val_fn: 485.0000 - val_precision: 0.7723 - val_recall: 0.7555 - val_auc: 0.9188 - val_prc: 0.8619 - val_accuracy: 0.7656\n",
      "Epoch 54/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4390 - tp: 12644.0000 - fp: 2447.0000 - tn: 29277.0000 - fn: 3218.0000 - precision: 0.8379 - recall: 0.7971 - auc: 0.9490 - prc: 0.9117 - accuracy: 0.8187\n",
      "Epoch 54: val_accuracy improved from 0.76815 to 0.78629, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 60s 237ms/step - loss: 0.4390 - tp: 12644.0000 - fp: 2447.0000 - tn: 29277.0000 - fn: 3218.0000 - precision: 0.8379 - recall: 0.7971 - auc: 0.9490 - prc: 0.9117 - accuracy: 0.8187 - val_loss: 0.5416 - val_tp: 1532.0000 - val_fp: 394.0000 - val_tn: 3574.0000 - val_fn: 452.0000 - val_precision: 0.7954 - val_recall: 0.7722 - val_auc: 0.9299 - val_prc: 0.8799 - val_accuracy: 0.7863\n",
      "Epoch 55/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4368 - tp: 12606.0000 - fp: 2483.0000 - tn: 29241.0000 - fn: 3256.0000 - precision: 0.8354 - recall: 0.7947 - auc: 0.9497 - prc: 0.9125 - accuracy: 0.8162\n",
      "Epoch 55: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.4368 - tp: 12606.0000 - fp: 2483.0000 - tn: 29241.0000 - fn: 3256.0000 - precision: 0.8354 - recall: 0.7947 - auc: 0.9497 - prc: 0.9125 - accuracy: 0.8162 - val_loss: 0.5886 - val_tp: 1533.0000 - val_fp: 412.0000 - val_tn: 3556.0000 - val_fn: 451.0000 - val_precision: 0.7882 - val_recall: 0.7727 - val_auc: 0.9247 - val_prc: 0.8693 - val_accuracy: 0.7782\n",
      "Epoch 56/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4257 - tp: 12792.0000 - fp: 2335.0000 - tn: 29389.0000 - fn: 3070.0000 - precision: 0.8456 - recall: 0.8065 - auc: 0.9532 - prc: 0.9193 - accuracy: 0.8274\n",
      "Epoch 56: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.4257 - tp: 12792.0000 - fp: 2335.0000 - tn: 29389.0000 - fn: 3070.0000 - precision: 0.8456 - recall: 0.8065 - auc: 0.9532 - prc: 0.9193 - accuracy: 0.8274 - val_loss: 0.5865 - val_tp: 1511.0000 - val_fp: 432.0000 - val_tn: 3536.0000 - val_fn: 473.0000 - val_precision: 0.7777 - val_recall: 0.7616 - val_auc: 0.9213 - val_prc: 0.8630 - val_accuracy: 0.7717\n",
      "Epoch 57/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4221 - tp: 12758.0000 - fp: 2388.0000 - tn: 29336.0000 - fn: 3104.0000 - precision: 0.8423 - recall: 0.8043 - auc: 0.9528 - prc: 0.9182 - accuracy: 0.8253\n",
      "Epoch 57: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.4221 - tp: 12758.0000 - fp: 2388.0000 - tn: 29336.0000 - fn: 3104.0000 - precision: 0.8423 - recall: 0.8043 - auc: 0.9528 - prc: 0.9182 - accuracy: 0.8253 - val_loss: 0.6383 - val_tp: 1482.0000 - val_fp: 450.0000 - val_tn: 3518.0000 - val_fn: 502.0000 - val_precision: 0.7671 - val_recall: 0.7470 - val_auc: 0.9127 - val_prc: 0.8522 - val_accuracy: 0.7591\n",
      "Epoch 58/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4225 - tp: 12747.0000 - fp: 2391.0000 - tn: 29333.0000 - fn: 3115.0000 - precision: 0.8421 - recall: 0.8036 - auc: 0.9530 - prc: 0.9186 - accuracy: 0.8234\n",
      "Epoch 58: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.4225 - tp: 12747.0000 - fp: 2391.0000 - tn: 29333.0000 - fn: 3115.0000 - precision: 0.8421 - recall: 0.8036 - auc: 0.9530 - prc: 0.9186 - accuracy: 0.8234 - val_loss: 0.6665 - val_tp: 1485.0000 - val_fp: 456.0000 - val_tn: 3512.0000 - val_fn: 499.0000 - val_precision: 0.7651 - val_recall: 0.7485 - val_auc: 0.9092 - val_prc: 0.8458 - val_accuracy: 0.7596\n",
      "Epoch 59/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4132 - tp: 12839.0000 - fp: 2293.0000 - tn: 29431.0000 - fn: 3023.0000 - precision: 0.8485 - recall: 0.8094 - auc: 0.9548 - prc: 0.9215 - accuracy: 0.8315\n",
      "Epoch 59: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 232ms/step - loss: 0.4132 - tp: 12839.0000 - fp: 2293.0000 - tn: 29431.0000 - fn: 3023.0000 - precision: 0.8485 - recall: 0.8094 - auc: 0.9548 - prc: 0.9215 - accuracy: 0.8315 - val_loss: 0.6100 - val_tp: 1493.0000 - val_fp: 440.0000 - val_tn: 3528.0000 - val_fn: 491.0000 - val_precision: 0.7724 - val_recall: 0.7525 - val_auc: 0.9178 - val_prc: 0.8606 - val_accuracy: 0.7616\n",
      "Epoch 60/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4081 - tp: 12860.0000 - fp: 2310.0000 - tn: 29414.0000 - fn: 3002.0000 - precision: 0.8477 - recall: 0.8107 - auc: 0.9555 - prc: 0.9226 - accuracy: 0.8300\n",
      "Epoch 60: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.4081 - tp: 12860.0000 - fp: 2310.0000 - tn: 29414.0000 - fn: 3002.0000 - precision: 0.8477 - recall: 0.8107 - auc: 0.9555 - prc: 0.9226 - accuracy: 0.8300 - val_loss: 0.6024 - val_tp: 1482.0000 - val_fp: 433.0000 - val_tn: 3535.0000 - val_fn: 502.0000 - val_precision: 0.7739 - val_recall: 0.7470 - val_auc: 0.9184 - val_prc: 0.8604 - val_accuracy: 0.7601\n",
      "Epoch 61/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4185 - tp: 12792.0000 - fp: 2376.0000 - tn: 29348.0000 - fn: 3070.0000 - precision: 0.8434 - recall: 0.8065 - auc: 0.9533 - prc: 0.9190 - accuracy: 0.8254\n",
      "Epoch 61: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 62s 243ms/step - loss: 0.4185 - tp: 12792.0000 - fp: 2376.0000 - tn: 29348.0000 - fn: 3070.0000 - precision: 0.8434 - recall: 0.8065 - auc: 0.9533 - prc: 0.9190 - accuracy: 0.8254 - val_loss: 0.6322 - val_tp: 1496.0000 - val_fp: 442.0000 - val_tn: 3526.0000 - val_fn: 488.0000 - val_precision: 0.7719 - val_recall: 0.7540 - val_auc: 0.9184 - val_prc: 0.8622 - val_accuracy: 0.7651\n",
      "Epoch 62/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4088 - tp: 12878.0000 - fp: 2339.0000 - tn: 29385.0000 - fn: 2984.0000 - precision: 0.8463 - recall: 0.8119 - auc: 0.9553 - prc: 0.9217 - accuracy: 0.8310\n",
      "Epoch 62: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 61s 239ms/step - loss: 0.4088 - tp: 12878.0000 - fp: 2339.0000 - tn: 29385.0000 - fn: 2984.0000 - precision: 0.8463 - recall: 0.8119 - auc: 0.9553 - prc: 0.9217 - accuracy: 0.8310 - val_loss: 0.5503 - val_tp: 1533.0000 - val_fp: 402.0000 - val_tn: 3566.0000 - val_fn: 451.0000 - val_precision: 0.7922 - val_recall: 0.7727 - val_auc: 0.9287 - val_prc: 0.8772 - val_accuracy: 0.7848\n",
      "Epoch 63/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4127 - tp: 12874.0000 - fp: 2280.0000 - tn: 29444.0000 - fn: 2988.0000 - precision: 0.8495 - recall: 0.8116 - auc: 0.9551 - prc: 0.9213 - accuracy: 0.8312\n",
      "Epoch 63: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 61s 239ms/step - loss: 0.4127 - tp: 12874.0000 - fp: 2280.0000 - tn: 29444.0000 - fn: 2988.0000 - precision: 0.8495 - recall: 0.8116 - auc: 0.9551 - prc: 0.9213 - accuracy: 0.8312 - val_loss: 0.6216 - val_tp: 1510.0000 - val_fp: 430.0000 - val_tn: 3538.0000 - val_fn: 474.0000 - val_precision: 0.7784 - val_recall: 0.7611 - val_auc: 0.9199 - val_prc: 0.8645 - val_accuracy: 0.7707\n",
      "Epoch 64/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4086 - tp: 12887.0000 - fp: 2300.0000 - tn: 29424.0000 - fn: 2975.0000 - precision: 0.8486 - recall: 0.8124 - auc: 0.9561 - prc: 0.9235 - accuracy: 0.8317\n",
      "Epoch 64: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 73s 286ms/step - loss: 0.4086 - tp: 12887.0000 - fp: 2300.0000 - tn: 29424.0000 - fn: 2975.0000 - precision: 0.8486 - recall: 0.8124 - auc: 0.9561 - prc: 0.9235 - accuracy: 0.8317 - val_loss: 0.5697 - val_tp: 1497.0000 - val_fp: 415.0000 - val_tn: 3553.0000 - val_fn: 487.0000 - val_precision: 0.7829 - val_recall: 0.7545 - val_auc: 0.9250 - val_prc: 0.8716 - val_accuracy: 0.7697\n",
      "Epoch 65/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.4003 - tp: 12958.0000 - fp: 2285.0000 - tn: 29439.0000 - fn: 2904.0000 - precision: 0.8501 - recall: 0.8169 - auc: 0.9571 - prc: 0.9255 - accuracy: 0.8357\n",
      "Epoch 65: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 69s 263ms/step - loss: 0.4003 - tp: 12958.0000 - fp: 2285.0000 - tn: 29439.0000 - fn: 2904.0000 - precision: 0.8501 - recall: 0.8169 - auc: 0.9571 - prc: 0.9255 - accuracy: 0.8357 - val_loss: 0.6361 - val_tp: 1492.0000 - val_fp: 454.0000 - val_tn: 3514.0000 - val_fn: 492.0000 - val_precision: 0.7667 - val_recall: 0.7520 - val_auc: 0.9169 - val_prc: 0.8589 - val_accuracy: 0.7631\n",
      "Epoch 66/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3835 - tp: 13079.0000 - fp: 2169.0000 - tn: 29555.0000 - fn: 2783.0000 - precision: 0.8578 - recall: 0.8245 - auc: 0.9610 - prc: 0.9318 - accuracy: 0.8409\n",
      "Epoch 66: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 65s 253ms/step - loss: 0.3835 - tp: 13079.0000 - fp: 2169.0000 - tn: 29555.0000 - fn: 2783.0000 - precision: 0.8578 - recall: 0.8245 - auc: 0.9610 - prc: 0.9318 - accuracy: 0.8409 - val_loss: 0.6383 - val_tp: 1534.0000 - val_fp: 415.0000 - val_tn: 3553.0000 - val_fn: 450.0000 - val_precision: 0.7871 - val_recall: 0.7732 - val_auc: 0.9218 - val_prc: 0.8665 - val_accuracy: 0.7807\n",
      "Epoch 67/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3858 - tp: 13108.0000 - fp: 2193.0000 - tn: 29531.0000 - fn: 2754.0000 - precision: 0.8567 - recall: 0.8264 - auc: 0.9597 - prc: 0.9297 - accuracy: 0.8439\n",
      "Epoch 67: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 65s 254ms/step - loss: 0.3858 - tp: 13108.0000 - fp: 2193.0000 - tn: 29531.0000 - fn: 2754.0000 - precision: 0.8567 - recall: 0.8264 - auc: 0.9597 - prc: 0.9297 - accuracy: 0.8439 - val_loss: 0.6071 - val_tp: 1514.0000 - val_fp: 421.0000 - val_tn: 3547.0000 - val_fn: 470.0000 - val_precision: 0.7824 - val_recall: 0.7631 - val_auc: 0.9240 - val_prc: 0.8685 - val_accuracy: 0.7752\n",
      "Epoch 68/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3854 - tp: 13093.0000 - fp: 2154.0000 - tn: 29570.0000 - fn: 2769.0000 - precision: 0.8587 - recall: 0.8254 - auc: 0.9606 - prc: 0.9308 - accuracy: 0.8445\n",
      "Epoch 68: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 62s 243ms/step - loss: 0.3854 - tp: 13093.0000 - fp: 2154.0000 - tn: 29570.0000 - fn: 2769.0000 - precision: 0.8587 - recall: 0.8254 - auc: 0.9606 - prc: 0.9308 - accuracy: 0.8445 - val_loss: 0.6242 - val_tp: 1512.0000 - val_fp: 429.0000 - val_tn: 3539.0000 - val_fn: 472.0000 - val_precision: 0.7790 - val_recall: 0.7621 - val_auc: 0.9206 - val_prc: 0.8606 - val_accuracy: 0.7742\n",
      "Epoch 69/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3883 - tp: 13083.0000 - fp: 2198.0000 - tn: 29526.0000 - fn: 2779.0000 - precision: 0.8562 - recall: 0.8248 - auc: 0.9595 - prc: 0.9289 - accuracy: 0.8404\n",
      "Epoch 69: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.3883 - tp: 13083.0000 - fp: 2198.0000 - tn: 29526.0000 - fn: 2779.0000 - precision: 0.8562 - recall: 0.8248 - auc: 0.9595 - prc: 0.9289 - accuracy: 0.8404 - val_loss: 0.6569 - val_tp: 1505.0000 - val_fp: 446.0000 - val_tn: 3522.0000 - val_fn: 479.0000 - val_precision: 0.7714 - val_recall: 0.7586 - val_auc: 0.9198 - val_prc: 0.8608 - val_accuracy: 0.7661\n",
      "Epoch 70/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3831 - tp: 13143.0000 - fp: 2186.0000 - tn: 29538.0000 - fn: 2719.0000 - precision: 0.8574 - recall: 0.8286 - auc: 0.9607 - prc: 0.9313 - accuracy: 0.8440\n",
      "Epoch 70: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 232ms/step - loss: 0.3831 - tp: 13143.0000 - fp: 2186.0000 - tn: 29538.0000 - fn: 2719.0000 - precision: 0.8574 - recall: 0.8286 - auc: 0.9607 - prc: 0.9313 - accuracy: 0.8440 - val_loss: 0.5818 - val_tp: 1521.0000 - val_fp: 417.0000 - val_tn: 3551.0000 - val_fn: 463.0000 - val_precision: 0.7848 - val_recall: 0.7666 - val_auc: 0.9280 - val_prc: 0.8754 - val_accuracy: 0.7752\n",
      "Epoch 71/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3792 - tp: 13126.0000 - fp: 2195.0000 - tn: 29529.0000 - fn: 2736.0000 - precision: 0.8567 - recall: 0.8275 - auc: 0.9608 - prc: 0.9316 - accuracy: 0.8417\n",
      "Epoch 71: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 232ms/step - loss: 0.3792 - tp: 13126.0000 - fp: 2195.0000 - tn: 29529.0000 - fn: 2736.0000 - precision: 0.8567 - recall: 0.8275 - auc: 0.9608 - prc: 0.9316 - accuracy: 0.8417 - val_loss: 0.6050 - val_tp: 1512.0000 - val_fp: 420.0000 - val_tn: 3548.0000 - val_fn: 472.0000 - val_precision: 0.7826 - val_recall: 0.7621 - val_auc: 0.9253 - val_prc: 0.8711 - val_accuracy: 0.7737\n",
      "Epoch 72/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3697 - tp: 13247.0000 - fp: 2079.0000 - tn: 29645.0000 - fn: 2615.0000 - precision: 0.8643 - recall: 0.8351 - auc: 0.9628 - prc: 0.9346 - accuracy: 0.8500\n",
      "Epoch 72: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.3697 - tp: 13247.0000 - fp: 2079.0000 - tn: 29645.0000 - fn: 2615.0000 - precision: 0.8643 - recall: 0.8351 - auc: 0.9628 - prc: 0.9346 - accuracy: 0.8500 - val_loss: 0.5786 - val_tp: 1517.0000 - val_fp: 414.0000 - val_tn: 3554.0000 - val_fn: 467.0000 - val_precision: 0.7856 - val_recall: 0.7646 - val_auc: 0.9272 - val_prc: 0.8746 - val_accuracy: 0.7757\n",
      "Epoch 73/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3713 - tp: 13201.0000 - fp: 2081.0000 - tn: 29643.0000 - fn: 2661.0000 - precision: 0.8638 - recall: 0.8322 - auc: 0.9627 - prc: 0.9341 - accuracy: 0.8493\n",
      "Epoch 73: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.3713 - tp: 13201.0000 - fp: 2081.0000 - tn: 29643.0000 - fn: 2661.0000 - precision: 0.8638 - recall: 0.8322 - auc: 0.9627 - prc: 0.9341 - accuracy: 0.8493 - val_loss: 0.6359 - val_tp: 1484.0000 - val_fp: 461.0000 - val_tn: 3507.0000 - val_fn: 500.0000 - val_precision: 0.7630 - val_recall: 0.7480 - val_auc: 0.9171 - val_prc: 0.8593 - val_accuracy: 0.7576\n",
      "Epoch 74/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3599 - tp: 13306.0000 - fp: 2032.0000 - tn: 29692.0000 - fn: 2556.0000 - precision: 0.8675 - recall: 0.8389 - auc: 0.9648 - prc: 0.9381 - accuracy: 0.8532\n",
      "Epoch 74: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.3599 - tp: 13306.0000 - fp: 2032.0000 - tn: 29692.0000 - fn: 2556.0000 - precision: 0.8675 - recall: 0.8389 - auc: 0.9648 - prc: 0.9381 - accuracy: 0.8532 - val_loss: 0.5987 - val_tp: 1514.0000 - val_fp: 427.0000 - val_tn: 3541.0000 - val_fn: 470.0000 - val_precision: 0.7800 - val_recall: 0.7631 - val_auc: 0.9260 - val_prc: 0.8721 - val_accuracy: 0.7732\n",
      "Epoch 75/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3693 - tp: 13200.0000 - fp: 2141.0000 - tn: 29583.0000 - fn: 2662.0000 - precision: 0.8604 - recall: 0.8322 - auc: 0.9631 - prc: 0.9347 - accuracy: 0.8473\n",
      "Epoch 75: val_accuracy did not improve from 0.78629\n",
      "248/248 [==============================] - 61s 239ms/step - loss: 0.3693 - tp: 13200.0000 - fp: 2141.0000 - tn: 29583.0000 - fn: 2662.0000 - precision: 0.8604 - recall: 0.8322 - auc: 0.9631 - prc: 0.9347 - accuracy: 0.8473 - val_loss: 0.6204 - val_tp: 1524.0000 - val_fp: 425.0000 - val_tn: 3543.0000 - val_fn: 460.0000 - val_precision: 0.7819 - val_recall: 0.7681 - val_auc: 0.9258 - val_prc: 0.8715 - val_accuracy: 0.7752\n",
      "Epoch 76/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3626 - tp: 13303.0000 - fp: 2101.0000 - tn: 29623.0000 - fn: 2559.0000 - precision: 0.8636 - recall: 0.8387 - auc: 0.9648 - prc: 0.9380 - accuracy: 0.8515\n",
      "Epoch 76: val_accuracy improved from 0.78629 to 0.78679, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 237ms/step - loss: 0.3626 - tp: 13303.0000 - fp: 2101.0000 - tn: 29623.0000 - fn: 2559.0000 - precision: 0.8636 - recall: 0.8387 - auc: 0.9648 - prc: 0.9380 - accuracy: 0.8515 - val_loss: 0.5479 - val_tp: 1546.0000 - val_fp: 395.0000 - val_tn: 3573.0000 - val_fn: 438.0000 - val_precision: 0.7965 - val_recall: 0.7792 - val_auc: 0.9327 - val_prc: 0.8836 - val_accuracy: 0.7868\n",
      "Epoch 77/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3639 - tp: 13258.0000 - fp: 2094.0000 - tn: 29630.0000 - fn: 2604.0000 - precision: 0.8636 - recall: 0.8358 - auc: 0.9637 - prc: 0.9361 - accuracy: 0.8505\n",
      "Epoch 77: val_accuracy did not improve from 0.78679\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.3639 - tp: 13258.0000 - fp: 2094.0000 - tn: 29630.0000 - fn: 2604.0000 - precision: 0.8636 - recall: 0.8358 - auc: 0.9637 - prc: 0.9361 - accuracy: 0.8505 - val_loss: 0.5833 - val_tp: 1506.0000 - val_fp: 416.0000 - val_tn: 3552.0000 - val_fn: 478.0000 - val_precision: 0.7836 - val_recall: 0.7591 - val_auc: 0.9262 - val_prc: 0.8720 - val_accuracy: 0.7717\n",
      "Epoch 78/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3592 - tp: 13313.0000 - fp: 2050.0000 - tn: 29674.0000 - fn: 2549.0000 - precision: 0.8666 - recall: 0.8393 - auc: 0.9649 - prc: 0.9381 - accuracy: 0.8544\n",
      "Epoch 78: val_accuracy improved from 0.78679 to 0.78931, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 237ms/step - loss: 0.3592 - tp: 13313.0000 - fp: 2050.0000 - tn: 29674.0000 - fn: 2549.0000 - precision: 0.8666 - recall: 0.8393 - auc: 0.9649 - prc: 0.9381 - accuracy: 0.8544 - val_loss: 0.5187 - val_tp: 1550.0000 - val_fp: 373.0000 - val_tn: 3595.0000 - val_fn: 434.0000 - val_precision: 0.8060 - val_recall: 0.7812 - val_auc: 0.9378 - val_prc: 0.8912 - val_accuracy: 0.7893\n",
      "Epoch 79/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3609 - tp: 13330.0000 - fp: 2046.0000 - tn: 29678.0000 - fn: 2532.0000 - precision: 0.8669 - recall: 0.8404 - auc: 0.9643 - prc: 0.9373 - accuracy: 0.8555\n",
      "Epoch 79: val_accuracy improved from 0.78931 to 0.79133, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 60s 237ms/step - loss: 0.3609 - tp: 13330.0000 - fp: 2046.0000 - tn: 29678.0000 - fn: 2532.0000 - precision: 0.8669 - recall: 0.8404 - auc: 0.9643 - prc: 0.9373 - accuracy: 0.8555 - val_loss: 0.5230 - val_tp: 1550.0000 - val_fp: 383.0000 - val_tn: 3585.0000 - val_fn: 434.0000 - val_precision: 0.8019 - val_recall: 0.7812 - val_auc: 0.9360 - val_prc: 0.8890 - val_accuracy: 0.7913\n",
      "Epoch 80/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3449 - tp: 13427.0000 - fp: 1926.0000 - tn: 29798.0000 - fn: 2435.0000 - precision: 0.8746 - recall: 0.8465 - auc: 0.9681 - prc: 0.9432 - accuracy: 0.8621\n",
      "Epoch 80: val_accuracy did not improve from 0.79133\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.3449 - tp: 13427.0000 - fp: 1926.0000 - tn: 29798.0000 - fn: 2435.0000 - precision: 0.8746 - recall: 0.8465 - auc: 0.9681 - prc: 0.9432 - accuracy: 0.8621 - val_loss: 0.5836 - val_tp: 1538.0000 - val_fp: 405.0000 - val_tn: 3563.0000 - val_fn: 446.0000 - val_precision: 0.7916 - val_recall: 0.7752 - val_auc: 0.9279 - val_prc: 0.8754 - val_accuracy: 0.7833\n",
      "Epoch 81/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3494 - tp: 13397.0000 - fp: 1978.0000 - tn: 29746.0000 - fn: 2465.0000 - precision: 0.8713 - recall: 0.8446 - auc: 0.9669 - prc: 0.9416 - accuracy: 0.8589\n",
      "Epoch 81: val_accuracy improved from 0.79133 to 0.79486, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 237ms/step - loss: 0.3494 - tp: 13397.0000 - fp: 1978.0000 - tn: 29746.0000 - fn: 2465.0000 - precision: 0.8713 - recall: 0.8446 - auc: 0.9669 - prc: 0.9416 - accuracy: 0.8589 - val_loss: 0.6205 - val_tp: 1570.0000 - val_fp: 389.0000 - val_tn: 3579.0000 - val_fn: 414.0000 - val_precision: 0.8014 - val_recall: 0.7913 - val_auc: 0.9291 - val_prc: 0.8780 - val_accuracy: 0.7949\n",
      "Epoch 82/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3433 - tp: 13409.0000 - fp: 2010.0000 - tn: 29714.0000 - fn: 2453.0000 - precision: 0.8696 - recall: 0.8454 - auc: 0.9673 - prc: 0.9420 - accuracy: 0.8579\n",
      "Epoch 82: val_accuracy did not improve from 0.79486\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.3433 - tp: 13409.0000 - fp: 2010.0000 - tn: 29714.0000 - fn: 2453.0000 - precision: 0.8696 - recall: 0.8454 - auc: 0.9673 - prc: 0.9420 - accuracy: 0.8579 - val_loss: 0.5749 - val_tp: 1562.0000 - val_fp: 395.0000 - val_tn: 3573.0000 - val_fn: 422.0000 - val_precision: 0.7982 - val_recall: 0.7873 - val_auc: 0.9335 - val_prc: 0.8839 - val_accuracy: 0.7918\n",
      "Epoch 83/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3406 - tp: 13475.0000 - fp: 1940.0000 - tn: 29784.0000 - fn: 2387.0000 - precision: 0.8741 - recall: 0.8495 - auc: 0.9686 - prc: 0.9442 - accuracy: 0.8622\n",
      "Epoch 83: val_accuracy improved from 0.79486 to 0.79839, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.3406 - tp: 13475.0000 - fp: 1940.0000 - tn: 29784.0000 - fn: 2387.0000 - precision: 0.8741 - recall: 0.8495 - auc: 0.9686 - prc: 0.9442 - accuracy: 0.8622 - val_loss: 0.5715 - val_tp: 1575.0000 - val_fp: 390.0000 - val_tn: 3578.0000 - val_fn: 409.0000 - val_precision: 0.8015 - val_recall: 0.7939 - val_auc: 0.9377 - val_prc: 0.8900 - val_accuracy: 0.7984\n",
      "Epoch 84/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3366 - tp: 13537.0000 - fp: 1886.0000 - tn: 29838.0000 - fn: 2325.0000 - precision: 0.8777 - recall: 0.8534 - auc: 0.9696 - prc: 0.9464 - accuracy: 0.8672\n",
      "Epoch 84: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 63s 246ms/step - loss: 0.3366 - tp: 13537.0000 - fp: 1886.0000 - tn: 29838.0000 - fn: 2325.0000 - precision: 0.8777 - recall: 0.8534 - auc: 0.9696 - prc: 0.9464 - accuracy: 0.8672 - val_loss: 0.6057 - val_tp: 1550.0000 - val_fp: 402.0000 - val_tn: 3566.0000 - val_fn: 434.0000 - val_precision: 0.7941 - val_recall: 0.7812 - val_auc: 0.9291 - val_prc: 0.8751 - val_accuracy: 0.7873\n",
      "Epoch 85/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3278 - tp: 13530.0000 - fp: 1860.0000 - tn: 29864.0000 - fn: 2332.0000 - precision: 0.8791 - recall: 0.8530 - auc: 0.9705 - prc: 0.9474 - accuracy: 0.8671\n",
      "Epoch 85: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3278 - tp: 13530.0000 - fp: 1860.0000 - tn: 29864.0000 - fn: 2332.0000 - precision: 0.8791 - recall: 0.8530 - auc: 0.9705 - prc: 0.9474 - accuracy: 0.8671 - val_loss: 0.6643 - val_tp: 1537.0000 - val_fp: 426.0000 - val_tn: 3542.0000 - val_fn: 447.0000 - val_precision: 0.7830 - val_recall: 0.7747 - val_auc: 0.9241 - val_prc: 0.8650 - val_accuracy: 0.7787\n",
      "Epoch 86/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3333 - tp: 13525.0000 - fp: 1908.0000 - tn: 29816.0000 - fn: 2337.0000 - precision: 0.8764 - recall: 0.8527 - auc: 0.9696 - prc: 0.9461 - accuracy: 0.8634\n",
      "Epoch 86: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.3333 - tp: 13525.0000 - fp: 1908.0000 - tn: 29816.0000 - fn: 2337.0000 - precision: 0.8764 - recall: 0.8527 - auc: 0.9696 - prc: 0.9461 - accuracy: 0.8634 - val_loss: 0.5866 - val_tp: 1547.0000 - val_fp: 414.0000 - val_tn: 3554.0000 - val_fn: 437.0000 - val_precision: 0.7889 - val_recall: 0.7797 - val_auc: 0.9316 - val_prc: 0.8778 - val_accuracy: 0.7833\n",
      "Epoch 87/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3236 - tp: 13584.0000 - fp: 1846.0000 - tn: 29878.0000 - fn: 2278.0000 - precision: 0.8804 - recall: 0.8564 - auc: 0.9711 - prc: 0.9483 - accuracy: 0.8693\n",
      "Epoch 87: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3236 - tp: 13584.0000 - fp: 1846.0000 - tn: 29878.0000 - fn: 2278.0000 - precision: 0.8804 - recall: 0.8564 - auc: 0.9711 - prc: 0.9483 - accuracy: 0.8693 - val_loss: 0.6242 - val_tp: 1536.0000 - val_fp: 428.0000 - val_tn: 3540.0000 - val_fn: 448.0000 - val_precision: 0.7821 - val_recall: 0.7742 - val_auc: 0.9251 - val_prc: 0.8683 - val_accuracy: 0.7792\n",
      "Epoch 88/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3305 - tp: 13581.0000 - fp: 1875.0000 - tn: 29849.0000 - fn: 2281.0000 - precision: 0.8787 - recall: 0.8562 - auc: 0.9701 - prc: 0.9471 - accuracy: 0.8678\n",
      "Epoch 88: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3305 - tp: 13581.0000 - fp: 1875.0000 - tn: 29849.0000 - fn: 2281.0000 - precision: 0.8787 - recall: 0.8562 - auc: 0.9701 - prc: 0.9471 - accuracy: 0.8678 - val_loss: 0.6035 - val_tp: 1536.0000 - val_fp: 411.0000 - val_tn: 3557.0000 - val_fn: 448.0000 - val_precision: 0.7889 - val_recall: 0.7742 - val_auc: 0.9267 - val_prc: 0.8736 - val_accuracy: 0.7823\n",
      "Epoch 89/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3280 - tp: 13585.0000 - fp: 1852.0000 - tn: 29872.0000 - fn: 2277.0000 - precision: 0.8800 - recall: 0.8564 - auc: 0.9702 - prc: 0.9467 - accuracy: 0.8693\n",
      "Epoch 89: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.3280 - tp: 13585.0000 - fp: 1852.0000 - tn: 29872.0000 - fn: 2277.0000 - precision: 0.8800 - recall: 0.8564 - auc: 0.9702 - prc: 0.9467 - accuracy: 0.8693 - val_loss: 0.7271 - val_tp: 1502.0000 - val_fp: 455.0000 - val_tn: 3513.0000 - val_fn: 482.0000 - val_precision: 0.7675 - val_recall: 0.7571 - val_auc: 0.9103 - val_prc: 0.8454 - val_accuracy: 0.7636\n",
      "Epoch 90/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3220 - tp: 13617.0000 - fp: 1825.0000 - tn: 29899.0000 - fn: 2245.0000 - precision: 0.8818 - recall: 0.8585 - auc: 0.9715 - prc: 0.9493 - accuracy: 0.8698\n",
      "Epoch 90: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3220 - tp: 13617.0000 - fp: 1825.0000 - tn: 29899.0000 - fn: 2245.0000 - precision: 0.8818 - recall: 0.8585 - auc: 0.9715 - prc: 0.9493 - accuracy: 0.8698 - val_loss: 0.5828 - val_tp: 1561.0000 - val_fp: 396.0000 - val_tn: 3572.0000 - val_fn: 423.0000 - val_precision: 0.7976 - val_recall: 0.7868 - val_auc: 0.9330 - val_prc: 0.8844 - val_accuracy: 0.7928\n",
      "Epoch 91/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3316 - tp: 13579.0000 - fp: 1828.0000 - tn: 29896.0000 - fn: 2283.0000 - precision: 0.8814 - recall: 0.8561 - auc: 0.9701 - prc: 0.9470 - accuracy: 0.8689\n",
      "Epoch 91: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3316 - tp: 13579.0000 - fp: 1828.0000 - tn: 29896.0000 - fn: 2283.0000 - precision: 0.8814 - recall: 0.8561 - auc: 0.9701 - prc: 0.9470 - accuracy: 0.8689 - val_loss: 0.6330 - val_tp: 1545.0000 - val_fp: 418.0000 - val_tn: 3550.0000 - val_fn: 439.0000 - val_precision: 0.7871 - val_recall: 0.7787 - val_auc: 0.9264 - val_prc: 0.8714 - val_accuracy: 0.7818\n",
      "Epoch 92/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3266 - tp: 13544.0000 - fp: 1863.0000 - tn: 29861.0000 - fn: 2318.0000 - precision: 0.8791 - recall: 0.8539 - auc: 0.9708 - prc: 0.9481 - accuracy: 0.8674\n",
      "Epoch 92: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3266 - tp: 13544.0000 - fp: 1863.0000 - tn: 29861.0000 - fn: 2318.0000 - precision: 0.8791 - recall: 0.8539 - auc: 0.9708 - prc: 0.9481 - accuracy: 0.8674 - val_loss: 0.5930 - val_tp: 1538.0000 - val_fp: 423.0000 - val_tn: 3545.0000 - val_fn: 446.0000 - val_precision: 0.7843 - val_recall: 0.7752 - val_auc: 0.9317 - val_prc: 0.8797 - val_accuracy: 0.7792\n",
      "Epoch 93/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3331 - tp: 13552.0000 - fp: 1877.0000 - tn: 29847.0000 - fn: 2310.0000 - precision: 0.8783 - recall: 0.8544 - auc: 0.9704 - prc: 0.9475 - accuracy: 0.8681\n",
      "Epoch 93: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3331 - tp: 13552.0000 - fp: 1877.0000 - tn: 29847.0000 - fn: 2310.0000 - precision: 0.8783 - recall: 0.8544 - auc: 0.9704 - prc: 0.9475 - accuracy: 0.8681 - val_loss: 0.5995 - val_tp: 1539.0000 - val_fp: 404.0000 - val_tn: 3564.0000 - val_fn: 445.0000 - val_precision: 0.7921 - val_recall: 0.7757 - val_auc: 0.9312 - val_prc: 0.8805 - val_accuracy: 0.7848\n",
      "Epoch 94/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3170 - tp: 13677.0000 - fp: 1788.0000 - tn: 29936.0000 - fn: 2185.0000 - precision: 0.8844 - recall: 0.8622 - auc: 0.9728 - prc: 0.9516 - accuracy: 0.8736\n",
      "Epoch 94: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.3170 - tp: 13677.0000 - fp: 1788.0000 - tn: 29936.0000 - fn: 2185.0000 - precision: 0.8844 - recall: 0.8622 - auc: 0.9728 - prc: 0.9516 - accuracy: 0.8736 - val_loss: 0.6199 - val_tp: 1552.0000 - val_fp: 413.0000 - val_tn: 3555.0000 - val_fn: 432.0000 - val_precision: 0.7898 - val_recall: 0.7823 - val_auc: 0.9315 - val_prc: 0.8771 - val_accuracy: 0.7878\n",
      "Epoch 95/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3037 - tp: 13824.0000 - fp: 1684.0000 - tn: 30040.0000 - fn: 2038.0000 - precision: 0.8914 - recall: 0.8715 - auc: 0.9744 - prc: 0.9542 - accuracy: 0.8818\n",
      "Epoch 95: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.3037 - tp: 13824.0000 - fp: 1684.0000 - tn: 30040.0000 - fn: 2038.0000 - precision: 0.8914 - recall: 0.8715 - auc: 0.9744 - prc: 0.9542 - accuracy: 0.8818 - val_loss: 0.6655 - val_tp: 1559.0000 - val_fp: 408.0000 - val_tn: 3560.0000 - val_fn: 425.0000 - val_precision: 0.7926 - val_recall: 0.7858 - val_auc: 0.9263 - val_prc: 0.8672 - val_accuracy: 0.7913\n",
      "Epoch 96/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3067 - tp: 13724.0000 - fp: 1749.0000 - tn: 29975.0000 - fn: 2138.0000 - precision: 0.8870 - recall: 0.8652 - auc: 0.9738 - prc: 0.9531 - accuracy: 0.8766\n",
      "Epoch 96: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 63s 246ms/step - loss: 0.3067 - tp: 13724.0000 - fp: 1749.0000 - tn: 29975.0000 - fn: 2138.0000 - precision: 0.8870 - recall: 0.8652 - auc: 0.9738 - prc: 0.9531 - accuracy: 0.8766 - val_loss: 0.6446 - val_tp: 1547.0000 - val_fp: 405.0000 - val_tn: 3563.0000 - val_fn: 437.0000 - val_precision: 0.7925 - val_recall: 0.7797 - val_auc: 0.9301 - val_prc: 0.8770 - val_accuracy: 0.7858\n",
      "Epoch 97/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3034 - tp: 13729.0000 - fp: 1730.0000 - tn: 29994.0000 - fn: 2133.0000 - precision: 0.8881 - recall: 0.8655 - auc: 0.9746 - prc: 0.9547 - accuracy: 0.8773\n",
      "Epoch 97: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.3034 - tp: 13729.0000 - fp: 1730.0000 - tn: 29994.0000 - fn: 2133.0000 - precision: 0.8881 - recall: 0.8655 - auc: 0.9746 - prc: 0.9547 - accuracy: 0.8773 - val_loss: 0.6529 - val_tp: 1539.0000 - val_fp: 425.0000 - val_tn: 3543.0000 - val_fn: 445.0000 - val_precision: 0.7836 - val_recall: 0.7757 - val_auc: 0.9271 - val_prc: 0.8710 - val_accuracy: 0.7802\n",
      "Epoch 98/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3109 - tp: 13705.0000 - fp: 1762.0000 - tn: 29962.0000 - fn: 2157.0000 - precision: 0.8861 - recall: 0.8640 - auc: 0.9736 - prc: 0.9529 - accuracy: 0.8762\n",
      "Epoch 98: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 62s 243ms/step - loss: 0.3109 - tp: 13705.0000 - fp: 1762.0000 - tn: 29962.0000 - fn: 2157.0000 - precision: 0.8861 - recall: 0.8640 - auc: 0.9736 - prc: 0.9529 - accuracy: 0.8762 - val_loss: 0.6280 - val_tp: 1548.0000 - val_fp: 411.0000 - val_tn: 3557.0000 - val_fn: 436.0000 - val_precision: 0.7902 - val_recall: 0.7802 - val_auc: 0.9312 - val_prc: 0.8796 - val_accuracy: 0.7863\n",
      "Epoch 99/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.3069 - tp: 13760.0000 - fp: 1737.0000 - tn: 29987.0000 - fn: 2102.0000 - precision: 0.8879 - recall: 0.8675 - auc: 0.9738 - prc: 0.9529 - accuracy: 0.8778\n",
      "Epoch 99: val_accuracy did not improve from 0.79839\n",
      "248/248 [==============================] - 60s 236ms/step - loss: 0.3069 - tp: 13760.0000 - fp: 1737.0000 - tn: 29987.0000 - fn: 2102.0000 - precision: 0.8879 - recall: 0.8675 - auc: 0.9738 - prc: 0.9529 - accuracy: 0.8778 - val_loss: 0.6552 - val_tp: 1537.0000 - val_fp: 419.0000 - val_tn: 3549.0000 - val_fn: 447.0000 - val_precision: 0.7858 - val_recall: 0.7747 - val_auc: 0.9270 - val_prc: 0.8714 - val_accuracy: 0.7802\n",
      "Epoch 100/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2978 - tp: 13840.0000 - fp: 1668.0000 - tn: 30056.0000 - fn: 2022.0000 - precision: 0.8924 - recall: 0.8725 - auc: 0.9756 - prc: 0.9562 - accuracy: 0.8829\n",
      "Epoch 100: val_accuracy improved from 0.79839 to 0.80645, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 65s 255ms/step - loss: 0.2978 - tp: 13840.0000 - fp: 1668.0000 - tn: 30056.0000 - fn: 2022.0000 - precision: 0.8924 - recall: 0.8725 - auc: 0.9756 - prc: 0.9562 - accuracy: 0.8829 - val_loss: 0.5724 - val_tp: 1588.0000 - val_fp: 374.0000 - val_tn: 3594.0000 - val_fn: 396.0000 - val_precision: 0.8094 - val_recall: 0.8004 - val_auc: 0.9380 - val_prc: 0.8894 - val_accuracy: 0.8065\n",
      "Epoch 101/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2948 - tp: 13829.0000 - fp: 1678.0000 - tn: 30046.0000 - fn: 2033.0000 - precision: 0.8918 - recall: 0.8718 - auc: 0.9761 - prc: 0.9571 - accuracy: 0.8823\n",
      "Epoch 101: val_accuracy did not improve from 0.80645\n",
      "248/248 [==============================] - 67s 262ms/step - loss: 0.2948 - tp: 13829.0000 - fp: 1678.0000 - tn: 30046.0000 - fn: 2033.0000 - precision: 0.8918 - recall: 0.8718 - auc: 0.9761 - prc: 0.9571 - accuracy: 0.8823 - val_loss: 0.6184 - val_tp: 1555.0000 - val_fp: 405.0000 - val_tn: 3563.0000 - val_fn: 429.0000 - val_precision: 0.7934 - val_recall: 0.7838 - val_auc: 0.9295 - val_prc: 0.8736 - val_accuracy: 0.7888\n",
      "Epoch 102/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2990 - tp: 13776.0000 - fp: 1739.0000 - tn: 29985.0000 - fn: 2086.0000 - precision: 0.8879 - recall: 0.8685 - auc: 0.9750 - prc: 0.9553 - accuracy: 0.8782\n",
      "Epoch 102: val_accuracy did not improve from 0.80645\n",
      "248/248 [==============================] - 66s 256ms/step - loss: 0.2990 - tp: 13776.0000 - fp: 1739.0000 - tn: 29985.0000 - fn: 2086.0000 - precision: 0.8879 - recall: 0.8685 - auc: 0.9750 - prc: 0.9553 - accuracy: 0.8782 - val_loss: 0.6328 - val_tp: 1562.0000 - val_fp: 407.0000 - val_tn: 3561.0000 - val_fn: 422.0000 - val_precision: 0.7933 - val_recall: 0.7873 - val_auc: 0.9287 - val_prc: 0.8745 - val_accuracy: 0.7913\n",
      "Epoch 103/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2884 - tp: 13911.0000 - fp: 1626.0000 - tn: 30098.0000 - fn: 1951.0000 - precision: 0.8953 - recall: 0.8770 - auc: 0.9771 - prc: 0.9588 - accuracy: 0.8859\n",
      "Epoch 103: val_accuracy did not improve from 0.80645\n",
      "248/248 [==============================] - 61s 240ms/step - loss: 0.2884 - tp: 13911.0000 - fp: 1626.0000 - tn: 30098.0000 - fn: 1951.0000 - precision: 0.8953 - recall: 0.8770 - auc: 0.9771 - prc: 0.9588 - accuracy: 0.8859 - val_loss: 0.5852 - val_tp: 1558.0000 - val_fp: 404.0000 - val_tn: 3564.0000 - val_fn: 426.0000 - val_precision: 0.7941 - val_recall: 0.7853 - val_auc: 0.9338 - val_prc: 0.8825 - val_accuracy: 0.7898\n",
      "Epoch 104/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2930 - tp: 13835.0000 - fp: 1658.0000 - tn: 30066.0000 - fn: 2027.0000 - precision: 0.8930 - recall: 0.8722 - auc: 0.9760 - prc: 0.9569 - accuracy: 0.8826\n",
      "Epoch 104: val_accuracy did not improve from 0.80645\n",
      "248/248 [==============================] - 63s 246ms/step - loss: 0.2930 - tp: 13835.0000 - fp: 1658.0000 - tn: 30066.0000 - fn: 2027.0000 - precision: 0.8930 - recall: 0.8722 - auc: 0.9760 - prc: 0.9569 - accuracy: 0.8826 - val_loss: 0.6603 - val_tp: 1535.0000 - val_fp: 420.0000 - val_tn: 3548.0000 - val_fn: 449.0000 - val_precision: 0.7852 - val_recall: 0.7737 - val_auc: 0.9261 - val_prc: 0.8708 - val_accuracy: 0.7818\n",
      "Epoch 105/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2903 - tp: 13897.0000 - fp: 1627.0000 - tn: 30097.0000 - fn: 1965.0000 - precision: 0.8952 - recall: 0.8761 - auc: 0.9762 - prc: 0.9571 - accuracy: 0.8864\n",
      "Epoch 105: val_accuracy did not improve from 0.80645\n",
      "248/248 [==============================] - 61s 237ms/step - loss: 0.2903 - tp: 13897.0000 - fp: 1627.0000 - tn: 30097.0000 - fn: 1965.0000 - precision: 0.8952 - recall: 0.8761 - auc: 0.9762 - prc: 0.9571 - accuracy: 0.8864 - val_loss: 0.5997 - val_tp: 1567.0000 - val_fp: 389.0000 - val_tn: 3579.0000 - val_fn: 417.0000 - val_precision: 0.8011 - val_recall: 0.7898 - val_auc: 0.9305 - val_prc: 0.8787 - val_accuracy: 0.7964\n",
      "Epoch 106/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2884 - tp: 13854.0000 - fp: 1687.0000 - tn: 30037.0000 - fn: 2008.0000 - precision: 0.8914 - recall: 0.8734 - auc: 0.9766 - prc: 0.9581 - accuracy: 0.8837\n",
      "Epoch 106: val_accuracy did not improve from 0.80645\n",
      "248/248 [==============================] - 66s 260ms/step - loss: 0.2884 - tp: 13854.0000 - fp: 1687.0000 - tn: 30037.0000 - fn: 2008.0000 - precision: 0.8914 - recall: 0.8734 - auc: 0.9766 - prc: 0.9581 - accuracy: 0.8837 - val_loss: 0.5874 - val_tp: 1548.0000 - val_fp: 405.0000 - val_tn: 3563.0000 - val_fn: 436.0000 - val_precision: 0.7926 - val_recall: 0.7802 - val_auc: 0.9302 - val_prc: 0.8803 - val_accuracy: 0.7873\n",
      "Epoch 107/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2846 - tp: 13926.0000 - fp: 1604.0000 - tn: 30120.0000 - fn: 1936.0000 - precision: 0.8967 - recall: 0.8779 - auc: 0.9771 - prc: 0.9587 - accuracy: 0.8876\n",
      "Epoch 107: val_accuracy improved from 0.80645 to 0.81300, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 62s 240ms/step - loss: 0.2846 - tp: 13926.0000 - fp: 1604.0000 - tn: 30120.0000 - fn: 1936.0000 - precision: 0.8967 - recall: 0.8779 - auc: 0.9771 - prc: 0.9587 - accuracy: 0.8876 - val_loss: 0.5213 - val_tp: 1602.0000 - val_fp: 358.0000 - val_tn: 3610.0000 - val_fn: 382.0000 - val_precision: 0.8173 - val_recall: 0.8075 - val_auc: 0.9439 - val_prc: 0.9004 - val_accuracy: 0.8130\n",
      "Epoch 108/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2811 - tp: 13916.0000 - fp: 1604.0000 - tn: 30120.0000 - fn: 1946.0000 - precision: 0.8966 - recall: 0.8773 - auc: 0.9782 - prc: 0.9606 - accuracy: 0.8881\n",
      "Epoch 108: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.2811 - tp: 13916.0000 - fp: 1604.0000 - tn: 30120.0000 - fn: 1946.0000 - precision: 0.8966 - recall: 0.8773 - auc: 0.9782 - prc: 0.9606 - accuracy: 0.8881 - val_loss: 0.6068 - val_tp: 1565.0000 - val_fp: 393.0000 - val_tn: 3575.0000 - val_fn: 419.0000 - val_precision: 0.7993 - val_recall: 0.7888 - val_auc: 0.9333 - val_prc: 0.8826 - val_accuracy: 0.7954\n",
      "Epoch 109/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2842 - tp: 13911.0000 - fp: 1623.0000 - tn: 30101.0000 - fn: 1951.0000 - precision: 0.8955 - recall: 0.8770 - auc: 0.9773 - prc: 0.9591 - accuracy: 0.8861\n",
      "Epoch 109: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 58s 225ms/step - loss: 0.2842 - tp: 13911.0000 - fp: 1623.0000 - tn: 30101.0000 - fn: 1951.0000 - precision: 0.8955 - recall: 0.8770 - auc: 0.9773 - prc: 0.9591 - accuracy: 0.8861 - val_loss: 0.5368 - val_tp: 1600.0000 - val_fp: 361.0000 - val_tn: 3607.0000 - val_fn: 384.0000 - val_precision: 0.8159 - val_recall: 0.8065 - val_auc: 0.9422 - val_prc: 0.8974 - val_accuracy: 0.8125\n",
      "Epoch 110/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2750 - tp: 13978.0000 - fp: 1561.0000 - tn: 30163.0000 - fn: 1884.0000 - precision: 0.8995 - recall: 0.8812 - auc: 0.9789 - prc: 0.9623 - accuracy: 0.8897\n",
      "Epoch 110: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2750 - tp: 13978.0000 - fp: 1561.0000 - tn: 30163.0000 - fn: 1884.0000 - precision: 0.8995 - recall: 0.8812 - auc: 0.9789 - prc: 0.9623 - accuracy: 0.8897 - val_loss: 0.6888 - val_tp: 1550.0000 - val_fp: 409.0000 - val_tn: 3559.0000 - val_fn: 434.0000 - val_precision: 0.7912 - val_recall: 0.7812 - val_auc: 0.9241 - val_prc: 0.8692 - val_accuracy: 0.7873\n",
      "Epoch 111/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2823 - tp: 13990.0000 - fp: 1559.0000 - tn: 30165.0000 - fn: 1872.0000 - precision: 0.8997 - recall: 0.8820 - auc: 0.9781 - prc: 0.9608 - accuracy: 0.8901\n",
      "Epoch 111: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2823 - tp: 13990.0000 - fp: 1559.0000 - tn: 30165.0000 - fn: 1872.0000 - precision: 0.8997 - recall: 0.8820 - auc: 0.9781 - prc: 0.9608 - accuracy: 0.8901 - val_loss: 0.6829 - val_tp: 1553.0000 - val_fp: 409.0000 - val_tn: 3559.0000 - val_fn: 431.0000 - val_precision: 0.7915 - val_recall: 0.7828 - val_auc: 0.9247 - val_prc: 0.8690 - val_accuracy: 0.7878\n",
      "Epoch 112/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2743 - tp: 13916.0000 - fp: 1634.0000 - tn: 30090.0000 - fn: 1946.0000 - precision: 0.8949 - recall: 0.8773 - auc: 0.9786 - prc: 0.9616 - accuracy: 0.8864\n",
      "Epoch 112: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2743 - tp: 13916.0000 - fp: 1634.0000 - tn: 30090.0000 - fn: 1946.0000 - precision: 0.8949 - recall: 0.8773 - auc: 0.9786 - prc: 0.9616 - accuracy: 0.8864 - val_loss: 0.7078 - val_tp: 1568.0000 - val_fp: 400.0000 - val_tn: 3568.0000 - val_fn: 416.0000 - val_precision: 0.7967 - val_recall: 0.7903 - val_auc: 0.9245 - val_prc: 0.8659 - val_accuracy: 0.7939\n",
      "Epoch 113/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2787 - tp: 13986.0000 - fp: 1585.0000 - tn: 30139.0000 - fn: 1876.0000 - precision: 0.8982 - recall: 0.8817 - auc: 0.9783 - prc: 0.9612 - accuracy: 0.8899\n",
      "Epoch 113: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2787 - tp: 13986.0000 - fp: 1585.0000 - tn: 30139.0000 - fn: 1876.0000 - precision: 0.8982 - recall: 0.8817 - auc: 0.9783 - prc: 0.9612 - accuracy: 0.8899 - val_loss: 0.6257 - val_tp: 1591.0000 - val_fp: 373.0000 - val_tn: 3595.0000 - val_fn: 393.0000 - val_precision: 0.8101 - val_recall: 0.8019 - val_auc: 0.9328 - val_prc: 0.8826 - val_accuracy: 0.8054\n",
      "Epoch 114/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2753 - tp: 13952.0000 - fp: 1600.0000 - tn: 30124.0000 - fn: 1910.0000 - precision: 0.8971 - recall: 0.8796 - auc: 0.9781 - prc: 0.9607 - accuracy: 0.8883\n",
      "Epoch 114: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.2753 - tp: 13952.0000 - fp: 1600.0000 - tn: 30124.0000 - fn: 1910.0000 - precision: 0.8971 - recall: 0.8796 - auc: 0.9781 - prc: 0.9607 - accuracy: 0.8883 - val_loss: 0.6300 - val_tp: 1576.0000 - val_fp: 391.0000 - val_tn: 3577.0000 - val_fn: 408.0000 - val_precision: 0.8012 - val_recall: 0.7944 - val_auc: 0.9327 - val_prc: 0.8779 - val_accuracy: 0.7984\n",
      "Epoch 115/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2816 - tp: 13923.0000 - fp: 1628.0000 - tn: 30096.0000 - fn: 1939.0000 - precision: 0.8953 - recall: 0.8778 - auc: 0.9777 - prc: 0.9598 - accuracy: 0.8865\n",
      "Epoch 115: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2816 - tp: 13923.0000 - fp: 1628.0000 - tn: 30096.0000 - fn: 1939.0000 - precision: 0.8953 - recall: 0.8778 - auc: 0.9777 - prc: 0.9598 - accuracy: 0.8865 - val_loss: 0.6256 - val_tp: 1571.0000 - val_fp: 389.0000 - val_tn: 3579.0000 - val_fn: 413.0000 - val_precision: 0.8015 - val_recall: 0.7918 - val_auc: 0.9327 - val_prc: 0.8787 - val_accuracy: 0.7959\n",
      "Epoch 116/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2672 - tp: 14098.0000 - fp: 1477.0000 - tn: 30247.0000 - fn: 1764.0000 - precision: 0.9052 - recall: 0.8888 - auc: 0.9800 - prc: 0.9637 - accuracy: 0.8962\n",
      "Epoch 116: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2672 - tp: 14098.0000 - fp: 1477.0000 - tn: 30247.0000 - fn: 1764.0000 - precision: 0.9052 - recall: 0.8888 - auc: 0.9800 - prc: 0.9637 - accuracy: 0.8962 - val_loss: 0.5964 - val_tp: 1591.0000 - val_fp: 375.0000 - val_tn: 3593.0000 - val_fn: 393.0000 - val_precision: 0.8093 - val_recall: 0.8019 - val_auc: 0.9374 - val_prc: 0.8893 - val_accuracy: 0.8054\n",
      "Epoch 117/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2672 - tp: 14059.0000 - fp: 1520.0000 - tn: 30204.0000 - fn: 1803.0000 - precision: 0.9024 - recall: 0.8863 - auc: 0.9796 - prc: 0.9633 - accuracy: 0.8939\n",
      "Epoch 117: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.2672 - tp: 14059.0000 - fp: 1520.0000 - tn: 30204.0000 - fn: 1803.0000 - precision: 0.9024 - recall: 0.8863 - auc: 0.9796 - prc: 0.9633 - accuracy: 0.8939 - val_loss: 0.5906 - val_tp: 1600.0000 - val_fp: 367.0000 - val_tn: 3601.0000 - val_fn: 384.0000 - val_precision: 0.8134 - val_recall: 0.8065 - val_auc: 0.9401 - val_prc: 0.8937 - val_accuracy: 0.8095\n",
      "Epoch 118/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2771 - tp: 13945.0000 - fp: 1621.0000 - tn: 30103.0000 - fn: 1917.0000 - precision: 0.8959 - recall: 0.8791 - auc: 0.9781 - prc: 0.9606 - accuracy: 0.8880\n",
      "Epoch 118: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.2771 - tp: 13945.0000 - fp: 1621.0000 - tn: 30103.0000 - fn: 1917.0000 - precision: 0.8959 - recall: 0.8791 - auc: 0.9781 - prc: 0.9606 - accuracy: 0.8880 - val_loss: 0.6405 - val_tp: 1566.0000 - val_fp: 405.0000 - val_tn: 3563.0000 - val_fn: 418.0000 - val_precision: 0.7945 - val_recall: 0.7893 - val_auc: 0.9321 - val_prc: 0.8786 - val_accuracy: 0.7933\n",
      "Epoch 119/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2720 - tp: 13995.0000 - fp: 1574.0000 - tn: 30150.0000 - fn: 1867.0000 - precision: 0.8989 - recall: 0.8823 - auc: 0.9793 - prc: 0.9626 - accuracy: 0.8899\n",
      "Epoch 119: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2720 - tp: 13995.0000 - fp: 1574.0000 - tn: 30150.0000 - fn: 1867.0000 - precision: 0.8989 - recall: 0.8823 - auc: 0.9793 - prc: 0.9626 - accuracy: 0.8899 - val_loss: 0.6239 - val_tp: 1571.0000 - val_fp: 393.0000 - val_tn: 3575.0000 - val_fn: 413.0000 - val_precision: 0.7999 - val_recall: 0.7918 - val_auc: 0.9314 - val_prc: 0.8798 - val_accuracy: 0.7959\n",
      "Epoch 120/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2698 - tp: 14019.0000 - fp: 1567.0000 - tn: 30157.0000 - fn: 1843.0000 - precision: 0.8995 - recall: 0.8838 - auc: 0.9796 - prc: 0.9631 - accuracy: 0.8915\n",
      "Epoch 120: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2698 - tp: 14019.0000 - fp: 1567.0000 - tn: 30157.0000 - fn: 1843.0000 - precision: 0.8995 - recall: 0.8838 - auc: 0.9796 - prc: 0.9631 - accuracy: 0.8915 - val_loss: 0.6092 - val_tp: 1551.0000 - val_fp: 401.0000 - val_tn: 3567.0000 - val_fn: 433.0000 - val_precision: 0.7946 - val_recall: 0.7818 - val_auc: 0.9321 - val_prc: 0.8822 - val_accuracy: 0.7893\n",
      "Epoch 121/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2597 - tp: 14072.0000 - fp: 1511.0000 - tn: 30213.0000 - fn: 1790.0000 - precision: 0.9030 - recall: 0.8872 - auc: 0.9805 - prc: 0.9645 - accuracy: 0.8950\n",
      "Epoch 121: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2597 - tp: 14072.0000 - fp: 1511.0000 - tn: 30213.0000 - fn: 1790.0000 - precision: 0.9030 - recall: 0.8872 - auc: 0.9805 - prc: 0.9645 - accuracy: 0.8950 - val_loss: 0.6044 - val_tp: 1577.0000 - val_fp: 373.0000 - val_tn: 3595.0000 - val_fn: 407.0000 - val_precision: 0.8087 - val_recall: 0.7949 - val_auc: 0.9332 - val_prc: 0.8836 - val_accuracy: 0.8024\n",
      "Epoch 122/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2659 - tp: 14065.0000 - fp: 1494.0000 - tn: 30230.0000 - fn: 1797.0000 - precision: 0.9040 - recall: 0.8867 - auc: 0.9801 - prc: 0.9641 - accuracy: 0.8954\n",
      "Epoch 122: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2659 - tp: 14065.0000 - fp: 1494.0000 - tn: 30230.0000 - fn: 1797.0000 - precision: 0.9040 - recall: 0.8867 - auc: 0.9801 - prc: 0.9641 - accuracy: 0.8954 - val_loss: 0.5711 - val_tp: 1593.0000 - val_fp: 365.0000 - val_tn: 3603.0000 - val_fn: 391.0000 - val_precision: 0.8136 - val_recall: 0.8029 - val_auc: 0.9376 - val_prc: 0.8907 - val_accuracy: 0.8085\n",
      "Epoch 123/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2582 - tp: 14103.0000 - fp: 1495.0000 - tn: 30229.0000 - fn: 1759.0000 - precision: 0.9042 - recall: 0.8891 - auc: 0.9813 - prc: 0.9660 - accuracy: 0.8959\n",
      "Epoch 123: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.2582 - tp: 14103.0000 - fp: 1495.0000 - tn: 30229.0000 - fn: 1759.0000 - precision: 0.9042 - recall: 0.8891 - auc: 0.9813 - prc: 0.9660 - accuracy: 0.8959 - val_loss: 0.5813 - val_tp: 1586.0000 - val_fp: 368.0000 - val_tn: 3600.0000 - val_fn: 398.0000 - val_precision: 0.8117 - val_recall: 0.7994 - val_auc: 0.9375 - val_prc: 0.8901 - val_accuracy: 0.8039\n",
      "Epoch 124/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2551 - tp: 14140.0000 - fp: 1449.0000 - tn: 30275.0000 - fn: 1722.0000 - precision: 0.9070 - recall: 0.8914 - auc: 0.9813 - prc: 0.9664 - accuracy: 0.8996\n",
      "Epoch 124: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.2551 - tp: 14140.0000 - fp: 1449.0000 - tn: 30275.0000 - fn: 1722.0000 - precision: 0.9070 - recall: 0.8914 - auc: 0.9813 - prc: 0.9664 - accuracy: 0.8996 - val_loss: 0.6197 - val_tp: 1563.0000 - val_fp: 387.0000 - val_tn: 3581.0000 - val_fn: 421.0000 - val_precision: 0.8015 - val_recall: 0.7878 - val_auc: 0.9298 - val_prc: 0.8736 - val_accuracy: 0.7959\n",
      "Epoch 125/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2597 - tp: 14081.0000 - fp: 1532.0000 - tn: 30192.0000 - fn: 1781.0000 - precision: 0.9019 - recall: 0.8877 - auc: 0.9811 - prc: 0.9659 - accuracy: 0.8953\n",
      "Epoch 125: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.2597 - tp: 14081.0000 - fp: 1532.0000 - tn: 30192.0000 - fn: 1781.0000 - precision: 0.9019 - recall: 0.8877 - auc: 0.9811 - prc: 0.9659 - accuracy: 0.8953 - val_loss: 0.5986 - val_tp: 1590.0000 - val_fp: 381.0000 - val_tn: 3587.0000 - val_fn: 394.0000 - val_precision: 0.8067 - val_recall: 0.8014 - val_auc: 0.9350 - val_prc: 0.8855 - val_accuracy: 0.8039\n",
      "Epoch 126/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2546 - tp: 14148.0000 - fp: 1427.0000 - tn: 30297.0000 - fn: 1714.0000 - precision: 0.9084 - recall: 0.8919 - auc: 0.9815 - prc: 0.9663 - accuracy: 0.9002\n",
      "Epoch 126: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.2546 - tp: 14148.0000 - fp: 1427.0000 - tn: 30297.0000 - fn: 1714.0000 - precision: 0.9084 - recall: 0.8919 - auc: 0.9815 - prc: 0.9663 - accuracy: 0.9002 - val_loss: 0.5932 - val_tp: 1579.0000 - val_fp: 384.0000 - val_tn: 3584.0000 - val_fn: 405.0000 - val_precision: 0.8044 - val_recall: 0.7959 - val_auc: 0.9352 - val_prc: 0.8873 - val_accuracy: 0.7999\n",
      "Epoch 127/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2565 - tp: 14123.0000 - fp: 1491.0000 - tn: 30233.0000 - fn: 1739.0000 - precision: 0.9045 - recall: 0.8904 - auc: 0.9815 - prc: 0.9665 - accuracy: 0.8982\n",
      "Epoch 127: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.2565 - tp: 14123.0000 - fp: 1491.0000 - tn: 30233.0000 - fn: 1739.0000 - precision: 0.9045 - recall: 0.8904 - auc: 0.9815 - prc: 0.9665 - accuracy: 0.8982 - val_loss: 0.6965 - val_tp: 1556.0000 - val_fp: 395.0000 - val_tn: 3573.0000 - val_fn: 428.0000 - val_precision: 0.7975 - val_recall: 0.7843 - val_auc: 0.9202 - val_prc: 0.8599 - val_accuracy: 0.7903\n",
      "Epoch 128/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2530 - tp: 14184.0000 - fp: 1427.0000 - tn: 30297.0000 - fn: 1678.0000 - precision: 0.9086 - recall: 0.8942 - auc: 0.9815 - prc: 0.9665 - accuracy: 0.9010\n",
      "Epoch 128: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.2530 - tp: 14184.0000 - fp: 1427.0000 - tn: 30297.0000 - fn: 1678.0000 - precision: 0.9086 - recall: 0.8942 - auc: 0.9815 - prc: 0.9665 - accuracy: 0.9010 - val_loss: 0.5903 - val_tp: 1568.0000 - val_fp: 379.0000 - val_tn: 3589.0000 - val_fn: 416.0000 - val_precision: 0.8053 - val_recall: 0.7903 - val_auc: 0.9326 - val_prc: 0.8795 - val_accuracy: 0.7979\n",
      "Epoch 129/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2550 - tp: 14159.0000 - fp: 1451.0000 - tn: 30273.0000 - fn: 1703.0000 - precision: 0.9070 - recall: 0.8926 - auc: 0.9815 - prc: 0.9669 - accuracy: 0.9003\n",
      "Epoch 129: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.2550 - tp: 14159.0000 - fp: 1451.0000 - tn: 30273.0000 - fn: 1703.0000 - precision: 0.9070 - recall: 0.8926 - auc: 0.9815 - prc: 0.9669 - accuracy: 0.9003 - val_loss: 0.6150 - val_tp: 1555.0000 - val_fp: 390.0000 - val_tn: 3578.0000 - val_fn: 429.0000 - val_precision: 0.7995 - val_recall: 0.7838 - val_auc: 0.9279 - val_prc: 0.8731 - val_accuracy: 0.7928\n",
      "Epoch 130/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2547 - tp: 14185.0000 - fp: 1411.0000 - tn: 30313.0000 - fn: 1677.0000 - precision: 0.9095 - recall: 0.8943 - auc: 0.9815 - prc: 0.9666 - accuracy: 0.9034\n",
      "Epoch 130: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.2547 - tp: 14185.0000 - fp: 1411.0000 - tn: 30313.0000 - fn: 1677.0000 - precision: 0.9095 - recall: 0.8943 - auc: 0.9815 - prc: 0.9666 - accuracy: 0.9034 - val_loss: 0.6669 - val_tp: 1559.0000 - val_fp: 408.0000 - val_tn: 3560.0000 - val_fn: 425.0000 - val_precision: 0.7926 - val_recall: 0.7858 - val_auc: 0.9263 - val_prc: 0.8711 - val_accuracy: 0.7888\n",
      "Epoch 131/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2485 - tp: 14174.0000 - fp: 1440.0000 - tn: 30284.0000 - fn: 1688.0000 - precision: 0.9078 - recall: 0.8936 - auc: 0.9823 - prc: 0.9675 - accuracy: 0.9010\n",
      "Epoch 131: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.2485 - tp: 14174.0000 - fp: 1440.0000 - tn: 30284.0000 - fn: 1688.0000 - precision: 0.9078 - recall: 0.8936 - auc: 0.9823 - prc: 0.9675 - accuracy: 0.9010 - val_loss: 0.5958 - val_tp: 1563.0000 - val_fp: 396.0000 - val_tn: 3572.0000 - val_fn: 421.0000 - val_precision: 0.7979 - val_recall: 0.7878 - val_auc: 0.9365 - val_prc: 0.8886 - val_accuracy: 0.7913\n",
      "Epoch 132/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2480 - tp: 14188.0000 - fp: 1426.0000 - tn: 30298.0000 - fn: 1674.0000 - precision: 0.9087 - recall: 0.8945 - auc: 0.9824 - prc: 0.9680 - accuracy: 0.9022\n",
      "Epoch 132: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.2480 - tp: 14188.0000 - fp: 1426.0000 - tn: 30298.0000 - fn: 1674.0000 - precision: 0.9087 - recall: 0.8945 - auc: 0.9824 - prc: 0.9680 - accuracy: 0.9022 - val_loss: 0.6757 - val_tp: 1570.0000 - val_fp: 393.0000 - val_tn: 3575.0000 - val_fn: 414.0000 - val_precision: 0.7998 - val_recall: 0.7913 - val_auc: 0.9286 - val_prc: 0.8746 - val_accuracy: 0.7974\n",
      "Epoch 133/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2429 - tp: 14228.0000 - fp: 1383.0000 - tn: 30341.0000 - fn: 1634.0000 - precision: 0.9114 - recall: 0.8970 - auc: 0.9833 - prc: 0.9696 - accuracy: 0.9049\n",
      "Epoch 133: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.2429 - tp: 14228.0000 - fp: 1383.0000 - tn: 30341.0000 - fn: 1634.0000 - precision: 0.9114 - recall: 0.8970 - auc: 0.9833 - prc: 0.9696 - accuracy: 0.9049 - val_loss: 0.7466 - val_tp: 1543.0000 - val_fp: 430.0000 - val_tn: 3538.0000 - val_fn: 441.0000 - val_precision: 0.7821 - val_recall: 0.7777 - val_auc: 0.9205 - val_prc: 0.8612 - val_accuracy: 0.7807\n",
      "Epoch 134/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2440 - tp: 14257.0000 - fp: 1377.0000 - tn: 30347.0000 - fn: 1605.0000 - precision: 0.9119 - recall: 0.8988 - auc: 0.9829 - prc: 0.9689 - accuracy: 0.9058\n",
      "Epoch 134: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.2440 - tp: 14257.0000 - fp: 1377.0000 - tn: 30347.0000 - fn: 1605.0000 - precision: 0.9119 - recall: 0.8988 - auc: 0.9829 - prc: 0.9689 - accuracy: 0.9058 - val_loss: 0.6354 - val_tp: 1582.0000 - val_fp: 377.0000 - val_tn: 3591.0000 - val_fn: 402.0000 - val_precision: 0.8076 - val_recall: 0.7974 - val_auc: 0.9319 - val_prc: 0.8806 - val_accuracy: 0.8014\n",
      "Epoch 135/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2451 - tp: 14240.0000 - fp: 1403.0000 - tn: 30321.0000 - fn: 1622.0000 - precision: 0.9103 - recall: 0.8977 - auc: 0.9831 - prc: 0.9696 - accuracy: 0.9037\n",
      "Epoch 135: val_accuracy did not improve from 0.81300\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.2451 - tp: 14240.0000 - fp: 1403.0000 - tn: 30321.0000 - fn: 1622.0000 - precision: 0.9103 - recall: 0.8977 - auc: 0.9831 - prc: 0.9696 - accuracy: 0.9037 - val_loss: 0.5747 - val_tp: 1603.0000 - val_fp: 362.0000 - val_tn: 3606.0000 - val_fn: 381.0000 - val_precision: 0.8158 - val_recall: 0.8080 - val_auc: 0.9398 - val_prc: 0.8930 - val_accuracy: 0.8130\n",
      "Epoch 136/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2390 - tp: 14240.0000 - fp: 1371.0000 - tn: 30353.0000 - fn: 1622.0000 - precision: 0.9122 - recall: 0.8977 - auc: 0.9837 - prc: 0.9705 - accuracy: 0.9052\n",
      "Epoch 136: val_accuracy improved from 0.81300 to 0.81905, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.2390 - tp: 14240.0000 - fp: 1371.0000 - tn: 30353.0000 - fn: 1622.0000 - precision: 0.9122 - recall: 0.8977 - auc: 0.9837 - prc: 0.9705 - accuracy: 0.9052 - val_loss: 0.5759 - val_tp: 1615.0000 - val_fp: 348.0000 - val_tn: 3620.0000 - val_fn: 369.0000 - val_precision: 0.8227 - val_recall: 0.8140 - val_auc: 0.9425 - val_prc: 0.8975 - val_accuracy: 0.8191\n",
      "Epoch 137/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2492 - tp: 14182.0000 - fp: 1424.0000 - tn: 30300.0000 - fn: 1680.0000 - precision: 0.9088 - recall: 0.8941 - auc: 0.9822 - prc: 0.9679 - accuracy: 0.9020\n",
      "Epoch 137: val_accuracy did not improve from 0.81905\n",
      "248/248 [==============================] - 58s 229ms/step - loss: 0.2492 - tp: 14182.0000 - fp: 1424.0000 - tn: 30300.0000 - fn: 1680.0000 - precision: 0.9088 - recall: 0.8941 - auc: 0.9822 - prc: 0.9679 - accuracy: 0.9020 - val_loss: 0.6091 - val_tp: 1599.0000 - val_fp: 368.0000 - val_tn: 3600.0000 - val_fn: 385.0000 - val_precision: 0.8129 - val_recall: 0.8059 - val_auc: 0.9373 - val_prc: 0.8873 - val_accuracy: 0.8095\n",
      "Epoch 138/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2437 - tp: 14236.0000 - fp: 1387.0000 - tn: 30337.0000 - fn: 1626.0000 - precision: 0.9112 - recall: 0.8975 - auc: 0.9829 - prc: 0.9689 - accuracy: 0.9052\n",
      "Epoch 138: val_accuracy improved from 0.81905 to 0.82460, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.2437 - tp: 14236.0000 - fp: 1387.0000 - tn: 30337.0000 - fn: 1626.0000 - precision: 0.9112 - recall: 0.8975 - auc: 0.9829 - prc: 0.9689 - accuracy: 0.9052 - val_loss: 0.5700 - val_tp: 1625.0000 - val_fp: 337.0000 - val_tn: 3631.0000 - val_fn: 359.0000 - val_precision: 0.8282 - val_recall: 0.8191 - val_auc: 0.9427 - val_prc: 0.8983 - val_accuracy: 0.8246\n",
      "Epoch 139/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2352 - tp: 14317.0000 - fp: 1318.0000 - tn: 30406.0000 - fn: 1545.0000 - precision: 0.9157 - recall: 0.9026 - auc: 0.9843 - prc: 0.9715 - accuracy: 0.9095\n",
      "Epoch 139: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.2352 - tp: 14317.0000 - fp: 1318.0000 - tn: 30406.0000 - fn: 1545.0000 - precision: 0.9157 - recall: 0.9026 - auc: 0.9843 - prc: 0.9715 - accuracy: 0.9095 - val_loss: 0.6793 - val_tp: 1571.0000 - val_fp: 392.0000 - val_tn: 3576.0000 - val_fn: 413.0000 - val_precision: 0.8003 - val_recall: 0.7918 - val_auc: 0.9267 - val_prc: 0.8723 - val_accuracy: 0.7959\n",
      "Epoch 140/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2373 - tp: 14277.0000 - fp: 1373.0000 - tn: 30351.0000 - fn: 1585.0000 - precision: 0.9123 - recall: 0.9001 - auc: 0.9837 - prc: 0.9701 - accuracy: 0.9052\n",
      "Epoch 140: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.2373 - tp: 14277.0000 - fp: 1373.0000 - tn: 30351.0000 - fn: 1585.0000 - precision: 0.9123 - recall: 0.9001 - auc: 0.9837 - prc: 0.9701 - accuracy: 0.9052 - val_loss: 0.6140 - val_tp: 1597.0000 - val_fp: 364.0000 - val_tn: 3604.0000 - val_fn: 387.0000 - val_precision: 0.8144 - val_recall: 0.8049 - val_auc: 0.9390 - val_prc: 0.8930 - val_accuracy: 0.8115\n",
      "Epoch 141/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2344 - tp: 14297.0000 - fp: 1337.0000 - tn: 30387.0000 - fn: 1565.0000 - precision: 0.9145 - recall: 0.9013 - auc: 0.9847 - prc: 0.9723 - accuracy: 0.9081\n",
      "Epoch 141: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 228ms/step - loss: 0.2344 - tp: 14297.0000 - fp: 1337.0000 - tn: 30387.0000 - fn: 1565.0000 - precision: 0.9145 - recall: 0.9013 - auc: 0.9847 - prc: 0.9723 - accuracy: 0.9081 - val_loss: 0.6077 - val_tp: 1603.0000 - val_fp: 364.0000 - val_tn: 3604.0000 - val_fn: 381.0000 - val_precision: 0.8149 - val_recall: 0.8080 - val_auc: 0.9368 - val_prc: 0.8883 - val_accuracy: 0.8120\n",
      "Epoch 142/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2284 - tp: 14264.0000 - fp: 1349.0000 - tn: 30375.0000 - fn: 1598.0000 - precision: 0.9136 - recall: 0.8993 - auc: 0.9847 - prc: 0.9720 - accuracy: 0.9068\n",
      "Epoch 142: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 229ms/step - loss: 0.2284 - tp: 14264.0000 - fp: 1349.0000 - tn: 30375.0000 - fn: 1598.0000 - precision: 0.9136 - recall: 0.8993 - auc: 0.9847 - prc: 0.9720 - accuracy: 0.9068 - val_loss: 0.7245 - val_tp: 1574.0000 - val_fp: 395.0000 - val_tn: 3573.0000 - val_fn: 410.0000 - val_precision: 0.7994 - val_recall: 0.7933 - val_auc: 0.9264 - val_prc: 0.8694 - val_accuracy: 0.7959\n",
      "Epoch 143/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2425 - tp: 14277.0000 - fp: 1362.0000 - tn: 30362.0000 - fn: 1585.0000 - precision: 0.9129 - recall: 0.9001 - auc: 0.9833 - prc: 0.9697 - accuracy: 0.9076\n",
      "Epoch 143: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.2425 - tp: 14277.0000 - fp: 1362.0000 - tn: 30362.0000 - fn: 1585.0000 - precision: 0.9129 - recall: 0.9001 - auc: 0.9833 - prc: 0.9697 - accuracy: 0.9076 - val_loss: 0.6897 - val_tp: 1564.0000 - val_fp: 398.0000 - val_tn: 3570.0000 - val_fn: 420.0000 - val_precision: 0.7971 - val_recall: 0.7883 - val_auc: 0.9277 - val_prc: 0.8719 - val_accuracy: 0.7908\n",
      "Epoch 144/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2343 - tp: 14277.0000 - fp: 1360.0000 - tn: 30364.0000 - fn: 1585.0000 - precision: 0.9130 - recall: 0.9001 - auc: 0.9840 - prc: 0.9708 - accuracy: 0.9064\n",
      "Epoch 144: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.2343 - tp: 14277.0000 - fp: 1360.0000 - tn: 30364.0000 - fn: 1585.0000 - precision: 0.9130 - recall: 0.9001 - auc: 0.9840 - prc: 0.9708 - accuracy: 0.9064 - val_loss: 0.5994 - val_tp: 1596.0000 - val_fp: 370.0000 - val_tn: 3598.0000 - val_fn: 388.0000 - val_precision: 0.8118 - val_recall: 0.8044 - val_auc: 0.9379 - val_prc: 0.8910 - val_accuracy: 0.8070\n",
      "Epoch 145/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2311 - tp: 14306.0000 - fp: 1327.0000 - tn: 30397.0000 - fn: 1556.0000 - precision: 0.9151 - recall: 0.9019 - auc: 0.9848 - prc: 0.9723 - accuracy: 0.9093\n",
      "Epoch 145: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.2311 - tp: 14306.0000 - fp: 1327.0000 - tn: 30397.0000 - fn: 1556.0000 - precision: 0.9151 - recall: 0.9019 - auc: 0.9848 - prc: 0.9723 - accuracy: 0.9093 - val_loss: 0.5912 - val_tp: 1607.0000 - val_fp: 360.0000 - val_tn: 3608.0000 - val_fn: 377.0000 - val_precision: 0.8170 - val_recall: 0.8100 - val_auc: 0.9407 - val_prc: 0.8942 - val_accuracy: 0.8135\n",
      "Epoch 146/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2258 - tp: 14331.0000 - fp: 1306.0000 - tn: 30418.0000 - fn: 1531.0000 - precision: 0.9165 - recall: 0.9035 - auc: 0.9852 - prc: 0.9729 - accuracy: 0.9103\n",
      "Epoch 146: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.2258 - tp: 14331.0000 - fp: 1306.0000 - tn: 30418.0000 - fn: 1531.0000 - precision: 0.9165 - recall: 0.9035 - auc: 0.9852 - prc: 0.9729 - accuracy: 0.9103 - val_loss: 0.6550 - val_tp: 1580.0000 - val_fp: 392.0000 - val_tn: 3576.0000 - val_fn: 404.0000 - val_precision: 0.8012 - val_recall: 0.7964 - val_auc: 0.9323 - val_prc: 0.8785 - val_accuracy: 0.7999\n",
      "Epoch 147/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2271 - tp: 14371.0000 - fp: 1282.0000 - tn: 30442.0000 - fn: 1491.0000 - precision: 0.9181 - recall: 0.9060 - auc: 0.9851 - prc: 0.9730 - accuracy: 0.9112\n",
      "Epoch 147: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.2271 - tp: 14371.0000 - fp: 1282.0000 - tn: 30442.0000 - fn: 1491.0000 - precision: 0.9181 - recall: 0.9060 - auc: 0.9851 - prc: 0.9730 - accuracy: 0.9112 - val_loss: 0.6046 - val_tp: 1599.0000 - val_fp: 359.0000 - val_tn: 3609.0000 - val_fn: 385.0000 - val_precision: 0.8166 - val_recall: 0.8059 - val_auc: 0.9373 - val_prc: 0.8858 - val_accuracy: 0.8140\n",
      "Epoch 148/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2273 - tp: 14339.0000 - fp: 1347.0000 - tn: 30377.0000 - fn: 1523.0000 - precision: 0.9141 - recall: 0.9040 - auc: 0.9845 - prc: 0.9718 - accuracy: 0.9074\n",
      "Epoch 148: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.2273 - tp: 14339.0000 - fp: 1347.0000 - tn: 30377.0000 - fn: 1523.0000 - precision: 0.9141 - recall: 0.9040 - auc: 0.9845 - prc: 0.9718 - accuracy: 0.9074 - val_loss: 0.6378 - val_tp: 1594.0000 - val_fp: 373.0000 - val_tn: 3595.0000 - val_fn: 390.0000 - val_precision: 0.8104 - val_recall: 0.8034 - val_auc: 0.9336 - val_prc: 0.8812 - val_accuracy: 0.8070\n",
      "Epoch 149/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2220 - tp: 14405.0000 - fp: 1253.0000 - tn: 30471.0000 - fn: 1457.0000 - precision: 0.9200 - recall: 0.9081 - auc: 0.9855 - prc: 0.9733 - accuracy: 0.9141\n",
      "Epoch 149: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.2220 - tp: 14405.0000 - fp: 1253.0000 - tn: 30471.0000 - fn: 1457.0000 - precision: 0.9200 - recall: 0.9081 - auc: 0.9855 - prc: 0.9733 - accuracy: 0.9141 - val_loss: 0.6516 - val_tp: 1591.0000 - val_fp: 381.0000 - val_tn: 3587.0000 - val_fn: 393.0000 - val_precision: 0.8068 - val_recall: 0.8019 - val_auc: 0.9330 - val_prc: 0.8815 - val_accuracy: 0.8065\n",
      "Epoch 150/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2258 - tp: 14366.0000 - fp: 1286.0000 - tn: 30438.0000 - fn: 1496.0000 - precision: 0.9178 - recall: 0.9057 - auc: 0.9851 - prc: 0.9728 - accuracy: 0.9126\n",
      "Epoch 150: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.2258 - tp: 14366.0000 - fp: 1286.0000 - tn: 30438.0000 - fn: 1496.0000 - precision: 0.9178 - recall: 0.9057 - auc: 0.9851 - prc: 0.9728 - accuracy: 0.9126 - val_loss: 0.6077 - val_tp: 1602.0000 - val_fp: 359.0000 - val_tn: 3609.0000 - val_fn: 382.0000 - val_precision: 0.8169 - val_recall: 0.8075 - val_auc: 0.9386 - val_prc: 0.8882 - val_accuracy: 0.8115\n",
      "Epoch 151/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2219 - tp: 14382.0000 - fp: 1304.0000 - tn: 30420.0000 - fn: 1480.0000 - precision: 0.9169 - recall: 0.9067 - auc: 0.9859 - prc: 0.9741 - accuracy: 0.9122\n",
      "Epoch 151: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.2219 - tp: 14382.0000 - fp: 1304.0000 - tn: 30420.0000 - fn: 1480.0000 - precision: 0.9169 - recall: 0.9067 - auc: 0.9859 - prc: 0.9741 - accuracy: 0.9122 - val_loss: 0.6301 - val_tp: 1609.0000 - val_fp: 357.0000 - val_tn: 3611.0000 - val_fn: 375.0000 - val_precision: 0.8184 - val_recall: 0.8110 - val_auc: 0.9354 - val_prc: 0.8838 - val_accuracy: 0.8155\n",
      "Epoch 152/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2212 - tp: 14398.0000 - fp: 1257.0000 - tn: 30467.0000 - fn: 1464.0000 - precision: 0.9197 - recall: 0.9077 - auc: 0.9858 - prc: 0.9740 - accuracy: 0.9129\n",
      "Epoch 152: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 60s 234ms/step - loss: 0.2212 - tp: 14398.0000 - fp: 1257.0000 - tn: 30467.0000 - fn: 1464.0000 - precision: 0.9197 - recall: 0.9077 - auc: 0.9858 - prc: 0.9740 - accuracy: 0.9129 - val_loss: 0.6660 - val_tp: 1596.0000 - val_fp: 370.0000 - val_tn: 3598.0000 - val_fn: 388.0000 - val_precision: 0.8118 - val_recall: 0.8044 - val_auc: 0.9322 - val_prc: 0.8781 - val_accuracy: 0.8075\n",
      "Epoch 153/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2276 - tp: 14396.0000 - fp: 1293.0000 - tn: 30431.0000 - fn: 1466.0000 - precision: 0.9176 - recall: 0.9076 - auc: 0.9854 - prc: 0.9737 - accuracy: 0.9126\n",
      "Epoch 153: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 233ms/step - loss: 0.2276 - tp: 14396.0000 - fp: 1293.0000 - tn: 30431.0000 - fn: 1466.0000 - precision: 0.9176 - recall: 0.9076 - auc: 0.9854 - prc: 0.9737 - accuracy: 0.9126 - val_loss: 0.7168 - val_tp: 1576.0000 - val_fp: 390.0000 - val_tn: 3578.0000 - val_fn: 408.0000 - val_precision: 0.8016 - val_recall: 0.7944 - val_auc: 0.9301 - val_prc: 0.8742 - val_accuracy: 0.7969\n",
      "Epoch 154/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2225 - tp: 14411.0000 - fp: 1251.0000 - tn: 30473.0000 - fn: 1451.0000 - precision: 0.9201 - recall: 0.9085 - auc: 0.9857 - prc: 0.9740 - accuracy: 0.9143\n",
      "Epoch 154: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 230ms/step - loss: 0.2225 - tp: 14411.0000 - fp: 1251.0000 - tn: 30473.0000 - fn: 1451.0000 - precision: 0.9201 - recall: 0.9085 - auc: 0.9857 - prc: 0.9740 - accuracy: 0.9143 - val_loss: 0.6269 - val_tp: 1605.0000 - val_fp: 362.0000 - val_tn: 3606.0000 - val_fn: 379.0000 - val_precision: 0.8160 - val_recall: 0.8090 - val_auc: 0.9379 - val_prc: 0.8923 - val_accuracy: 0.8115\n",
      "Epoch 155/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2275 - tp: 14318.0000 - fp: 1314.0000 - tn: 30410.0000 - fn: 1544.0000 - precision: 0.9159 - recall: 0.9027 - auc: 0.9847 - prc: 0.9721 - accuracy: 0.9097\n",
      "Epoch 155: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.2275 - tp: 14318.0000 - fp: 1314.0000 - tn: 30410.0000 - fn: 1544.0000 - precision: 0.9159 - recall: 0.9027 - auc: 0.9847 - prc: 0.9721 - accuracy: 0.9097 - val_loss: 0.6316 - val_tp: 1577.0000 - val_fp: 390.0000 - val_tn: 3578.0000 - val_fn: 407.0000 - val_precision: 0.8017 - val_recall: 0.7949 - val_auc: 0.9359 - val_prc: 0.8862 - val_accuracy: 0.7974\n",
      "Epoch 156/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2103 - tp: 14444.0000 - fp: 1225.0000 - tn: 30499.0000 - fn: 1418.0000 - precision: 0.9218 - recall: 0.9106 - auc: 0.9871 - prc: 0.9763 - accuracy: 0.9160\n",
      "Epoch 156: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 225ms/step - loss: 0.2103 - tp: 14444.0000 - fp: 1225.0000 - tn: 30499.0000 - fn: 1418.0000 - precision: 0.9218 - recall: 0.9106 - auc: 0.9871 - prc: 0.9763 - accuracy: 0.9160 - val_loss: 0.6822 - val_tp: 1596.0000 - val_fp: 378.0000 - val_tn: 3590.0000 - val_fn: 388.0000 - val_precision: 0.8085 - val_recall: 0.8044 - val_auc: 0.9333 - val_prc: 0.8798 - val_accuracy: 0.8070\n",
      "Epoch 157/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2187 - tp: 14428.0000 - fp: 1249.0000 - tn: 30475.0000 - fn: 1434.0000 - precision: 0.9203 - recall: 0.9096 - auc: 0.9863 - prc: 0.9750 - accuracy: 0.9158\n",
      "Epoch 157: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.2187 - tp: 14428.0000 - fp: 1249.0000 - tn: 30475.0000 - fn: 1434.0000 - precision: 0.9203 - recall: 0.9096 - auc: 0.9863 - prc: 0.9750 - accuracy: 0.9158 - val_loss: 0.6205 - val_tp: 1627.0000 - val_fp: 348.0000 - val_tn: 3620.0000 - val_fn: 357.0000 - val_precision: 0.8238 - val_recall: 0.8201 - val_auc: 0.9401 - val_prc: 0.8931 - val_accuracy: 0.8221\n",
      "Epoch 158/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2182 - tp: 14430.0000 - fp: 1231.0000 - tn: 30493.0000 - fn: 1432.0000 - precision: 0.9214 - recall: 0.9097 - auc: 0.9858 - prc: 0.9737 - accuracy: 0.9159\n",
      "Epoch 158: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 61s 240ms/step - loss: 0.2182 - tp: 14430.0000 - fp: 1231.0000 - tn: 30493.0000 - fn: 1432.0000 - precision: 0.9214 - recall: 0.9097 - auc: 0.9858 - prc: 0.9737 - accuracy: 0.9159 - val_loss: 0.5877 - val_tp: 1622.0000 - val_fp: 345.0000 - val_tn: 3623.0000 - val_fn: 362.0000 - val_precision: 0.8246 - val_recall: 0.8175 - val_auc: 0.9420 - val_prc: 0.8961 - val_accuracy: 0.8226\n",
      "Epoch 159/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2169 - tp: 14433.0000 - fp: 1234.0000 - tn: 30490.0000 - fn: 1429.0000 - precision: 0.9212 - recall: 0.9099 - auc: 0.9863 - prc: 0.9750 - accuracy: 0.9159\n",
      "Epoch 159: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 60s 235ms/step - loss: 0.2169 - tp: 14433.0000 - fp: 1234.0000 - tn: 30490.0000 - fn: 1429.0000 - precision: 0.9212 - recall: 0.9099 - auc: 0.9863 - prc: 0.9750 - accuracy: 0.9159 - val_loss: 0.6281 - val_tp: 1605.0000 - val_fp: 361.0000 - val_tn: 3607.0000 - val_fn: 379.0000 - val_precision: 0.8164 - val_recall: 0.8090 - val_auc: 0.9390 - val_prc: 0.8920 - val_accuracy: 0.8125\n",
      "Epoch 160/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2104 - tp: 14474.0000 - fp: 1187.0000 - tn: 30537.0000 - fn: 1388.0000 - precision: 0.9242 - recall: 0.9125 - auc: 0.9869 - prc: 0.9757 - accuracy: 0.9177\n",
      "Epoch 160: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 58s 225ms/step - loss: 0.2104 - tp: 14474.0000 - fp: 1187.0000 - tn: 30537.0000 - fn: 1388.0000 - precision: 0.9242 - recall: 0.9125 - auc: 0.9869 - prc: 0.9757 - accuracy: 0.9177 - val_loss: 0.5924 - val_tp: 1619.0000 - val_fp: 346.0000 - val_tn: 3622.0000 - val_fn: 365.0000 - val_precision: 0.8239 - val_recall: 0.8160 - val_auc: 0.9399 - val_prc: 0.8914 - val_accuracy: 0.8211\n",
      "Epoch 161/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2162 - tp: 14419.0000 - fp: 1224.0000 - tn: 30500.0000 - fn: 1443.0000 - precision: 0.9218 - recall: 0.9090 - auc: 0.9865 - prc: 0.9751 - accuracy: 0.9155\n",
      "Epoch 161: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2162 - tp: 14419.0000 - fp: 1224.0000 - tn: 30500.0000 - fn: 1443.0000 - precision: 0.9218 - recall: 0.9090 - auc: 0.9865 - prc: 0.9751 - accuracy: 0.9155 - val_loss: 0.6195 - val_tp: 1612.0000 - val_fp: 357.0000 - val_tn: 3611.0000 - val_fn: 372.0000 - val_precision: 0.8187 - val_recall: 0.8125 - val_auc: 0.9375 - val_prc: 0.8854 - val_accuracy: 0.8160\n",
      "Epoch 162/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2138 - tp: 14457.0000 - fp: 1227.0000 - tn: 30497.0000 - fn: 1405.0000 - precision: 0.9218 - recall: 0.9114 - auc: 0.9868 - prc: 0.9757 - accuracy: 0.9166\n",
      "Epoch 162: val_accuracy did not improve from 0.82460\n",
      "248/248 [==============================] - 57s 221ms/step - loss: 0.2138 - tp: 14457.0000 - fp: 1227.0000 - tn: 30497.0000 - fn: 1405.0000 - precision: 0.9218 - recall: 0.9114 - auc: 0.9868 - prc: 0.9757 - accuracy: 0.9166 - val_loss: 0.6492 - val_tp: 1595.0000 - val_fp: 375.0000 - val_tn: 3593.0000 - val_fn: 389.0000 - val_precision: 0.8096 - val_recall: 0.8039 - val_auc: 0.9341 - val_prc: 0.8822 - val_accuracy: 0.8054\n",
      "Epoch 163/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2128 - tp: 14458.0000 - fp: 1218.0000 - tn: 30506.0000 - fn: 1404.0000 - precision: 0.9223 - recall: 0.9115 - auc: 0.9869 - prc: 0.9761 - accuracy: 0.9168\n",
      "Epoch 163: val_accuracy improved from 0.82460 to 0.83065, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.2128 - tp: 14458.0000 - fp: 1218.0000 - tn: 30506.0000 - fn: 1404.0000 - precision: 0.9223 - recall: 0.9115 - auc: 0.9869 - prc: 0.9761 - accuracy: 0.9168 - val_loss: 0.5394 - val_tp: 1641.0000 - val_fp: 328.0000 - val_tn: 3640.0000 - val_fn: 343.0000 - val_precision: 0.8334 - val_recall: 0.8271 - val_auc: 0.9470 - val_prc: 0.9063 - val_accuracy: 0.8306\n",
      "Epoch 164/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2196 - tp: 14419.0000 - fp: 1253.0000 - tn: 30471.0000 - fn: 1443.0000 - precision: 0.9200 - recall: 0.9090 - auc: 0.9864 - prc: 0.9752 - accuracy: 0.9129\n",
      "Epoch 164: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2196 - tp: 14419.0000 - fp: 1253.0000 - tn: 30471.0000 - fn: 1443.0000 - precision: 0.9200 - recall: 0.9090 - auc: 0.9864 - prc: 0.9752 - accuracy: 0.9129 - val_loss: 0.6020 - val_tp: 1616.0000 - val_fp: 347.0000 - val_tn: 3621.0000 - val_fn: 368.0000 - val_precision: 0.8232 - val_recall: 0.8145 - val_auc: 0.9386 - val_prc: 0.8896 - val_accuracy: 0.8175\n",
      "Epoch 165/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2081 - tp: 14457.0000 - fp: 1210.0000 - tn: 30514.0000 - fn: 1405.0000 - precision: 0.9228 - recall: 0.9114 - auc: 0.9873 - prc: 0.9769 - accuracy: 0.9175\n",
      "Epoch 165: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 57s 221ms/step - loss: 0.2081 - tp: 14457.0000 - fp: 1210.0000 - tn: 30514.0000 - fn: 1405.0000 - precision: 0.9228 - recall: 0.9114 - auc: 0.9873 - prc: 0.9769 - accuracy: 0.9175 - val_loss: 0.5744 - val_tp: 1612.0000 - val_fp: 351.0000 - val_tn: 3617.0000 - val_fn: 372.0000 - val_precision: 0.8212 - val_recall: 0.8125 - val_auc: 0.9416 - val_prc: 0.8950 - val_accuracy: 0.8175\n",
      "Epoch 166/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2102 - tp: 14469.0000 - fp: 1227.0000 - tn: 30497.0000 - fn: 1393.0000 - precision: 0.9218 - recall: 0.9122 - auc: 0.9871 - prc: 0.9764 - accuracy: 0.9173\n",
      "Epoch 166: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.2102 - tp: 14469.0000 - fp: 1227.0000 - tn: 30497.0000 - fn: 1393.0000 - precision: 0.9218 - recall: 0.9122 - auc: 0.9871 - prc: 0.9764 - accuracy: 0.9173 - val_loss: 0.5974 - val_tp: 1603.0000 - val_fp: 361.0000 - val_tn: 3607.0000 - val_fn: 381.0000 - val_precision: 0.8162 - val_recall: 0.8080 - val_auc: 0.9400 - val_prc: 0.8960 - val_accuracy: 0.8125\n",
      "Epoch 167/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2058 - tp: 14503.0000 - fp: 1198.0000 - tn: 30526.0000 - fn: 1359.0000 - precision: 0.9237 - recall: 0.9143 - auc: 0.9874 - prc: 0.9772 - accuracy: 0.9193\n",
      "Epoch 167: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2058 - tp: 14503.0000 - fp: 1198.0000 - tn: 30526.0000 - fn: 1359.0000 - precision: 0.9237 - recall: 0.9143 - auc: 0.9874 - prc: 0.9772 - accuracy: 0.9193 - val_loss: 0.6364 - val_tp: 1596.0000 - val_fp: 372.0000 - val_tn: 3596.0000 - val_fn: 388.0000 - val_precision: 0.8110 - val_recall: 0.8044 - val_auc: 0.9379 - val_prc: 0.8909 - val_accuracy: 0.8075\n",
      "Epoch 168/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2149 - tp: 14443.0000 - fp: 1235.0000 - tn: 30489.0000 - fn: 1419.0000 - precision: 0.9212 - recall: 0.9105 - auc: 0.9869 - prc: 0.9761 - accuracy: 0.9152\n",
      "Epoch 168: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2149 - tp: 14443.0000 - fp: 1235.0000 - tn: 30489.0000 - fn: 1419.0000 - precision: 0.9212 - recall: 0.9105 - auc: 0.9869 - prc: 0.9761 - accuracy: 0.9152 - val_loss: 0.6623 - val_tp: 1576.0000 - val_fp: 391.0000 - val_tn: 3577.0000 - val_fn: 408.0000 - val_precision: 0.8012 - val_recall: 0.7944 - val_auc: 0.9316 - val_prc: 0.8786 - val_accuracy: 0.7994\n",
      "Epoch 169/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1997 - tp: 14552.0000 - fp: 1138.0000 - tn: 30586.0000 - fn: 1310.0000 - precision: 0.9275 - recall: 0.9174 - auc: 0.9882 - prc: 0.9782 - accuracy: 0.9228\n",
      "Epoch 169: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1997 - tp: 14552.0000 - fp: 1138.0000 - tn: 30586.0000 - fn: 1310.0000 - precision: 0.9275 - recall: 0.9174 - auc: 0.9882 - prc: 0.9782 - accuracy: 0.9228 - val_loss: 0.6579 - val_tp: 1587.0000 - val_fp: 376.0000 - val_tn: 3592.0000 - val_fn: 397.0000 - val_precision: 0.8085 - val_recall: 0.7999 - val_auc: 0.9329 - val_prc: 0.8797 - val_accuracy: 0.8054\n",
      "Epoch 170/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2082 - tp: 14525.0000 - fp: 1172.0000 - tn: 30552.0000 - fn: 1337.0000 - precision: 0.9253 - recall: 0.9157 - auc: 0.9874 - prc: 0.9768 - accuracy: 0.9202\n",
      "Epoch 170: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2082 - tp: 14525.0000 - fp: 1172.0000 - tn: 30552.0000 - fn: 1337.0000 - precision: 0.9253 - recall: 0.9157 - auc: 0.9874 - prc: 0.9768 - accuracy: 0.9202 - val_loss: 0.6183 - val_tp: 1601.0000 - val_fp: 364.0000 - val_tn: 3604.0000 - val_fn: 383.0000 - val_precision: 0.8148 - val_recall: 0.8070 - val_auc: 0.9373 - val_prc: 0.8891 - val_accuracy: 0.8100\n",
      "Epoch 171/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1975 - tp: 14534.0000 - fp: 1145.0000 - tn: 30579.0000 - fn: 1328.0000 - precision: 0.9270 - recall: 0.9163 - auc: 0.9885 - prc: 0.9786 - accuracy: 0.9220\n",
      "Epoch 171: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.1975 - tp: 14534.0000 - fp: 1145.0000 - tn: 30579.0000 - fn: 1328.0000 - precision: 0.9270 - recall: 0.9163 - auc: 0.9885 - prc: 0.9786 - accuracy: 0.9220 - val_loss: 0.6765 - val_tp: 1587.0000 - val_fp: 373.0000 - val_tn: 3595.0000 - val_fn: 397.0000 - val_precision: 0.8097 - val_recall: 0.7999 - val_auc: 0.9303 - val_prc: 0.8764 - val_accuracy: 0.8059\n",
      "Epoch 172/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2109 - tp: 14512.0000 - fp: 1179.0000 - tn: 30545.0000 - fn: 1350.0000 - precision: 0.9249 - recall: 0.9149 - auc: 0.9875 - prc: 0.9769 - accuracy: 0.9199\n",
      "Epoch 172: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.2109 - tp: 14512.0000 - fp: 1179.0000 - tn: 30545.0000 - fn: 1350.0000 - precision: 0.9249 - recall: 0.9149 - auc: 0.9875 - prc: 0.9769 - accuracy: 0.9199 - val_loss: 0.6723 - val_tp: 1583.0000 - val_fp: 383.0000 - val_tn: 3585.0000 - val_fn: 401.0000 - val_precision: 0.8052 - val_recall: 0.7979 - val_auc: 0.9300 - val_prc: 0.8761 - val_accuracy: 0.8014\n",
      "Epoch 173/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2062 - tp: 14497.0000 - fp: 1198.0000 - tn: 30526.0000 - fn: 1365.0000 - precision: 0.9237 - recall: 0.9139 - auc: 0.9872 - prc: 0.9761 - accuracy: 0.9188\n",
      "Epoch 173: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2062 - tp: 14497.0000 - fp: 1198.0000 - tn: 30526.0000 - fn: 1365.0000 - precision: 0.9237 - recall: 0.9139 - auc: 0.9872 - prc: 0.9761 - accuracy: 0.9188 - val_loss: 0.6194 - val_tp: 1612.0000 - val_fp: 357.0000 - val_tn: 3611.0000 - val_fn: 372.0000 - val_precision: 0.8187 - val_recall: 0.8125 - val_auc: 0.9367 - val_prc: 0.8852 - val_accuracy: 0.8150\n",
      "Epoch 174/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1981 - tp: 14527.0000 - fp: 1165.0000 - tn: 30559.0000 - fn: 1335.0000 - precision: 0.9258 - recall: 0.9158 - auc: 0.9881 - prc: 0.9779 - accuracy: 0.9215\n",
      "Epoch 174: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1981 - tp: 14527.0000 - fp: 1165.0000 - tn: 30559.0000 - fn: 1335.0000 - precision: 0.9258 - recall: 0.9158 - auc: 0.9881 - prc: 0.9779 - accuracy: 0.9215 - val_loss: 0.5966 - val_tp: 1638.0000 - val_fp: 335.0000 - val_tn: 3633.0000 - val_fn: 346.0000 - val_precision: 0.8302 - val_recall: 0.8256 - val_auc: 0.9397 - val_prc: 0.8906 - val_accuracy: 0.8276\n",
      "Epoch 175/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1893 - tp: 14634.0000 - fp: 1075.0000 - tn: 30649.0000 - fn: 1228.0000 - precision: 0.9316 - recall: 0.9226 - auc: 0.9892 - prc: 0.9802 - accuracy: 0.9267\n",
      "Epoch 175: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1893 - tp: 14634.0000 - fp: 1075.0000 - tn: 30649.0000 - fn: 1228.0000 - precision: 0.9316 - recall: 0.9226 - auc: 0.9892 - prc: 0.9802 - accuracy: 0.9267 - val_loss: 0.6509 - val_tp: 1604.0000 - val_fp: 355.0000 - val_tn: 3613.0000 - val_fn: 380.0000 - val_precision: 0.8188 - val_recall: 0.8085 - val_auc: 0.9343 - val_prc: 0.8804 - val_accuracy: 0.8140\n",
      "Epoch 176/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2064 - tp: 14548.0000 - fp: 1158.0000 - tn: 30566.0000 - fn: 1314.0000 - precision: 0.9263 - recall: 0.9172 - auc: 0.9878 - prc: 0.9778 - accuracy: 0.9217\n",
      "Epoch 176: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2064 - tp: 14548.0000 - fp: 1158.0000 - tn: 30566.0000 - fn: 1314.0000 - precision: 0.9263 - recall: 0.9172 - auc: 0.9878 - prc: 0.9778 - accuracy: 0.9217 - val_loss: 0.6238 - val_tp: 1597.0000 - val_fp: 365.0000 - val_tn: 3603.0000 - val_fn: 387.0000 - val_precision: 0.8140 - val_recall: 0.8049 - val_auc: 0.9342 - val_prc: 0.8799 - val_accuracy: 0.8110\n",
      "Epoch 177/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1951 - tp: 14541.0000 - fp: 1163.0000 - tn: 30561.0000 - fn: 1321.0000 - precision: 0.9259 - recall: 0.9167 - auc: 0.9890 - prc: 0.9797 - accuracy: 0.9211\n",
      "Epoch 177: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1951 - tp: 14541.0000 - fp: 1163.0000 - tn: 30561.0000 - fn: 1321.0000 - precision: 0.9259 - recall: 0.9167 - auc: 0.9890 - prc: 0.9797 - accuracy: 0.9211 - val_loss: 0.6404 - val_tp: 1603.0000 - val_fp: 362.0000 - val_tn: 3606.0000 - val_fn: 381.0000 - val_precision: 0.8158 - val_recall: 0.8080 - val_auc: 0.9338 - val_prc: 0.8789 - val_accuracy: 0.8110\n",
      "Epoch 178/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2044 - tp: 14552.0000 - fp: 1159.0000 - tn: 30565.0000 - fn: 1310.0000 - precision: 0.9262 - recall: 0.9174 - auc: 0.9877 - prc: 0.9771 - accuracy: 0.9215\n",
      "Epoch 178: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.2044 - tp: 14552.0000 - fp: 1159.0000 - tn: 30565.0000 - fn: 1310.0000 - precision: 0.9262 - recall: 0.9174 - auc: 0.9877 - prc: 0.9771 - accuracy: 0.9215 - val_loss: 0.6239 - val_tp: 1614.0000 - val_fp: 358.0000 - val_tn: 3610.0000 - val_fn: 370.0000 - val_precision: 0.8185 - val_recall: 0.8135 - val_auc: 0.9349 - val_prc: 0.8810 - val_accuracy: 0.8165\n",
      "Epoch 179/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.2005 - tp: 14554.0000 - fp: 1132.0000 - tn: 30592.0000 - fn: 1308.0000 - precision: 0.9278 - recall: 0.9175 - auc: 0.9880 - prc: 0.9782 - accuracy: 0.9227\n",
      "Epoch 179: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.2005 - tp: 14554.0000 - fp: 1132.0000 - tn: 30592.0000 - fn: 1308.0000 - precision: 0.9278 - recall: 0.9175 - auc: 0.9880 - prc: 0.9782 - accuracy: 0.9227 - val_loss: 0.6383 - val_tp: 1613.0000 - val_fp: 360.0000 - val_tn: 3608.0000 - val_fn: 371.0000 - val_precision: 0.8175 - val_recall: 0.8130 - val_auc: 0.9336 - val_prc: 0.8799 - val_accuracy: 0.8140\n",
      "Epoch 180/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1897 - tp: 14636.0000 - fp: 1055.0000 - tn: 30669.0000 - fn: 1226.0000 - precision: 0.9328 - recall: 0.9227 - auc: 0.9893 - prc: 0.9803 - accuracy: 0.9278\n",
      "Epoch 180: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1897 - tp: 14636.0000 - fp: 1055.0000 - tn: 30669.0000 - fn: 1226.0000 - precision: 0.9328 - recall: 0.9227 - auc: 0.9893 - prc: 0.9803 - accuracy: 0.9278 - val_loss: 0.6635 - val_tp: 1595.0000 - val_fp: 377.0000 - val_tn: 3591.0000 - val_fn: 389.0000 - val_precision: 0.8088 - val_recall: 0.8039 - val_auc: 0.9329 - val_prc: 0.8772 - val_accuracy: 0.8070\n",
      "Epoch 181/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1980 - tp: 14527.0000 - fp: 1169.0000 - tn: 30555.0000 - fn: 1335.0000 - precision: 0.9255 - recall: 0.9158 - auc: 0.9883 - prc: 0.9782 - accuracy: 0.9208\n",
      "Epoch 181: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1980 - tp: 14527.0000 - fp: 1169.0000 - tn: 30555.0000 - fn: 1335.0000 - precision: 0.9255 - recall: 0.9158 - auc: 0.9883 - prc: 0.9782 - accuracy: 0.9208 - val_loss: 0.6161 - val_tp: 1627.0000 - val_fp: 346.0000 - val_tn: 3622.0000 - val_fn: 357.0000 - val_precision: 0.8246 - val_recall: 0.8201 - val_auc: 0.9382 - val_prc: 0.8891 - val_accuracy: 0.8226\n",
      "Epoch 182/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1933 - tp: 14610.0000 - fp: 1098.0000 - tn: 30626.0000 - fn: 1252.0000 - precision: 0.9301 - recall: 0.9211 - auc: 0.9890 - prc: 0.9800 - accuracy: 0.9250\n",
      "Epoch 182: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1933 - tp: 14610.0000 - fp: 1098.0000 - tn: 30626.0000 - fn: 1252.0000 - precision: 0.9301 - recall: 0.9211 - auc: 0.9890 - prc: 0.9800 - accuracy: 0.9250 - val_loss: 0.6408 - val_tp: 1617.0000 - val_fp: 359.0000 - val_tn: 3609.0000 - val_fn: 367.0000 - val_precision: 0.8183 - val_recall: 0.8150 - val_auc: 0.9383 - val_prc: 0.8890 - val_accuracy: 0.8160\n",
      "Epoch 183/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1976 - tp: 14551.0000 - fp: 1148.0000 - tn: 30576.0000 - fn: 1311.0000 - precision: 0.9269 - recall: 0.9173 - auc: 0.9889 - prc: 0.9795 - accuracy: 0.9223\n",
      "Epoch 183: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1976 - tp: 14551.0000 - fp: 1148.0000 - tn: 30576.0000 - fn: 1311.0000 - precision: 0.9269 - recall: 0.9173 - auc: 0.9889 - prc: 0.9795 - accuracy: 0.9223 - val_loss: 0.6504 - val_tp: 1608.0000 - val_fp: 368.0000 - val_tn: 3600.0000 - val_fn: 376.0000 - val_precision: 0.8138 - val_recall: 0.8105 - val_auc: 0.9370 - val_prc: 0.8867 - val_accuracy: 0.8120\n",
      "Epoch 184/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1948 - tp: 14567.0000 - fp: 1153.0000 - tn: 30571.0000 - fn: 1295.0000 - precision: 0.9267 - recall: 0.9184 - auc: 0.9887 - prc: 0.9792 - accuracy: 0.9227\n",
      "Epoch 184: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1948 - tp: 14567.0000 - fp: 1153.0000 - tn: 30571.0000 - fn: 1295.0000 - precision: 0.9267 - recall: 0.9184 - auc: 0.9887 - prc: 0.9792 - accuracy: 0.9227 - val_loss: 0.6642 - val_tp: 1616.0000 - val_fp: 356.0000 - val_tn: 3612.0000 - val_fn: 368.0000 - val_precision: 0.8195 - val_recall: 0.8145 - val_auc: 0.9366 - val_prc: 0.8862 - val_accuracy: 0.8165\n",
      "Epoch 185/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1886 - tp: 14620.0000 - fp: 1083.0000 - tn: 30641.0000 - fn: 1242.0000 - precision: 0.9310 - recall: 0.9217 - auc: 0.9894 - prc: 0.9805 - accuracy: 0.9271\n",
      "Epoch 185: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1886 - tp: 14620.0000 - fp: 1083.0000 - tn: 30641.0000 - fn: 1242.0000 - precision: 0.9310 - recall: 0.9217 - auc: 0.9894 - prc: 0.9805 - accuracy: 0.9271 - val_loss: 0.6931 - val_tp: 1596.0000 - val_fp: 369.0000 - val_tn: 3599.0000 - val_fn: 388.0000 - val_precision: 0.8122 - val_recall: 0.8044 - val_auc: 0.9311 - val_prc: 0.8757 - val_accuracy: 0.8095\n",
      "Epoch 186/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1903 - tp: 14622.0000 - fp: 1090.0000 - tn: 30634.0000 - fn: 1240.0000 - precision: 0.9306 - recall: 0.9218 - auc: 0.9892 - prc: 0.9800 - accuracy: 0.9264\n",
      "Epoch 186: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1903 - tp: 14622.0000 - fp: 1090.0000 - tn: 30634.0000 - fn: 1240.0000 - precision: 0.9306 - recall: 0.9218 - auc: 0.9892 - prc: 0.9800 - accuracy: 0.9264 - val_loss: 0.6393 - val_tp: 1608.0000 - val_fp: 357.0000 - val_tn: 3611.0000 - val_fn: 376.0000 - val_precision: 0.8183 - val_recall: 0.8105 - val_auc: 0.9370 - val_prc: 0.8870 - val_accuracy: 0.8140\n",
      "Epoch 187/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1934 - tp: 14593.0000 - fp: 1100.0000 - tn: 30624.0000 - fn: 1269.0000 - precision: 0.9299 - recall: 0.9200 - auc: 0.9889 - prc: 0.9794 - accuracy: 0.9250\n",
      "Epoch 187: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.1934 - tp: 14593.0000 - fp: 1100.0000 - tn: 30624.0000 - fn: 1269.0000 - precision: 0.9299 - recall: 0.9200 - auc: 0.9889 - prc: 0.9794 - accuracy: 0.9250 - val_loss: 0.6559 - val_tp: 1608.0000 - val_fp: 357.0000 - val_tn: 3611.0000 - val_fn: 376.0000 - val_precision: 0.8183 - val_recall: 0.8105 - val_auc: 0.9338 - val_prc: 0.8809 - val_accuracy: 0.8140\n",
      "Epoch 188/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1924 - tp: 14586.0000 - fp: 1124.0000 - tn: 30600.0000 - fn: 1276.0000 - precision: 0.9285 - recall: 0.9196 - auc: 0.9890 - prc: 0.9796 - accuracy: 0.9249\n",
      "Epoch 188: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.1924 - tp: 14586.0000 - fp: 1124.0000 - tn: 30600.0000 - fn: 1276.0000 - precision: 0.9285 - recall: 0.9196 - auc: 0.9890 - prc: 0.9796 - accuracy: 0.9249 - val_loss: 0.7050 - val_tp: 1592.0000 - val_fp: 375.0000 - val_tn: 3593.0000 - val_fn: 392.0000 - val_precision: 0.8094 - val_recall: 0.8024 - val_auc: 0.9292 - val_prc: 0.8715 - val_accuracy: 0.8075\n",
      "Epoch 189/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1803 - tp: 14708.0000 - fp: 1001.0000 - tn: 30723.0000 - fn: 1154.0000 - precision: 0.9363 - recall: 0.9272 - auc: 0.9902 - prc: 0.9817 - accuracy: 0.9318\n",
      "Epoch 189: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1803 - tp: 14708.0000 - fp: 1001.0000 - tn: 30723.0000 - fn: 1154.0000 - precision: 0.9363 - recall: 0.9272 - auc: 0.9902 - prc: 0.9817 - accuracy: 0.9318 - val_loss: 0.6365 - val_tp: 1635.0000 - val_fp: 335.0000 - val_tn: 3633.0000 - val_fn: 349.0000 - val_precision: 0.8299 - val_recall: 0.8241 - val_auc: 0.9383 - val_prc: 0.8883 - val_accuracy: 0.8271\n",
      "Epoch 190/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1866 - tp: 14625.0000 - fp: 1096.0000 - tn: 30628.0000 - fn: 1237.0000 - precision: 0.9303 - recall: 0.9220 - auc: 0.9894 - prc: 0.9806 - accuracy: 0.9257\n",
      "Epoch 190: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1866 - tp: 14625.0000 - fp: 1096.0000 - tn: 30628.0000 - fn: 1237.0000 - precision: 0.9303 - recall: 0.9220 - auc: 0.9894 - prc: 0.9806 - accuracy: 0.9257 - val_loss: 0.6634 - val_tp: 1625.0000 - val_fp: 347.0000 - val_tn: 3621.0000 - val_fn: 359.0000 - val_precision: 0.8240 - val_recall: 0.8191 - val_auc: 0.9378 - val_prc: 0.8875 - val_accuracy: 0.8206\n",
      "Epoch 191/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1966 - tp: 14576.0000 - fp: 1116.0000 - tn: 30608.0000 - fn: 1286.0000 - precision: 0.9289 - recall: 0.9189 - auc: 0.9889 - prc: 0.9794 - accuracy: 0.9237\n",
      "Epoch 191: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 56s 220ms/step - loss: 0.1966 - tp: 14576.0000 - fp: 1116.0000 - tn: 30608.0000 - fn: 1286.0000 - precision: 0.9289 - recall: 0.9189 - auc: 0.9889 - prc: 0.9794 - accuracy: 0.9237 - val_loss: 0.6839 - val_tp: 1615.0000 - val_fp: 357.0000 - val_tn: 3611.0000 - val_fn: 369.0000 - val_precision: 0.8190 - val_recall: 0.8140 - val_auc: 0.9344 - val_prc: 0.8805 - val_accuracy: 0.8165\n",
      "Epoch 192/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1823 - tp: 14697.0000 - fp: 1044.0000 - tn: 30680.0000 - fn: 1165.0000 - precision: 0.9337 - recall: 0.9266 - auc: 0.9898 - prc: 0.9810 - accuracy: 0.9301\n",
      "Epoch 192: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1823 - tp: 14697.0000 - fp: 1044.0000 - tn: 30680.0000 - fn: 1165.0000 - precision: 0.9337 - recall: 0.9266 - auc: 0.9898 - prc: 0.9810 - accuracy: 0.9301 - val_loss: 0.6672 - val_tp: 1623.0000 - val_fp: 350.0000 - val_tn: 3618.0000 - val_fn: 361.0000 - val_precision: 0.8226 - val_recall: 0.8180 - val_auc: 0.9361 - val_prc: 0.8840 - val_accuracy: 0.8185\n",
      "Epoch 193/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1897 - tp: 14651.0000 - fp: 1062.0000 - tn: 30662.0000 - fn: 1211.0000 - precision: 0.9324 - recall: 0.9237 - auc: 0.9896 - prc: 0.9810 - accuracy: 0.9276\n",
      "Epoch 193: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1897 - tp: 14651.0000 - fp: 1062.0000 - tn: 30662.0000 - fn: 1211.0000 - precision: 0.9324 - recall: 0.9237 - auc: 0.9896 - prc: 0.9810 - accuracy: 0.9276 - val_loss: 0.6378 - val_tp: 1632.0000 - val_fp: 344.0000 - val_tn: 3624.0000 - val_fn: 352.0000 - val_precision: 0.8259 - val_recall: 0.8226 - val_auc: 0.9406 - val_prc: 0.8928 - val_accuracy: 0.8241\n",
      "Epoch 194/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1928 - tp: 14650.0000 - fp: 1061.0000 - tn: 30663.0000 - fn: 1212.0000 - precision: 0.9325 - recall: 0.9236 - auc: 0.9890 - prc: 0.9799 - accuracy: 0.9277\n",
      "Epoch 194: val_accuracy did not improve from 0.83065\n",
      "248/248 [==============================] - 58s 228ms/step - loss: 0.1928 - tp: 14650.0000 - fp: 1061.0000 - tn: 30663.0000 - fn: 1212.0000 - precision: 0.9325 - recall: 0.9236 - auc: 0.9890 - prc: 0.9799 - accuracy: 0.9277 - val_loss: 0.6228 - val_tp: 1633.0000 - val_fp: 336.0000 - val_tn: 3632.0000 - val_fn: 351.0000 - val_precision: 0.8294 - val_recall: 0.8231 - val_auc: 0.9423 - val_prc: 0.8948 - val_accuracy: 0.8251\n",
      "Epoch 195/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1893 - tp: 14632.0000 - fp: 1074.0000 - tn: 30650.0000 - fn: 1230.0000 - precision: 0.9316 - recall: 0.9225 - auc: 0.9895 - prc: 0.9807 - accuracy: 0.9264\n",
      "Epoch 195: val_accuracy improved from 0.83065 to 0.83115, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 61s 238ms/step - loss: 0.1893 - tp: 14632.0000 - fp: 1074.0000 - tn: 30650.0000 - fn: 1230.0000 - precision: 0.9316 - recall: 0.9225 - auc: 0.9895 - prc: 0.9807 - accuracy: 0.9264 - val_loss: 0.6362 - val_tp: 1641.0000 - val_fp: 328.0000 - val_tn: 3640.0000 - val_fn: 343.0000 - val_precision: 0.8334 - val_recall: 0.8271 - val_auc: 0.9410 - val_prc: 0.8934 - val_accuracy: 0.8311\n",
      "Epoch 196/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1827 - tp: 14646.0000 - fp: 1065.0000 - tn: 30659.0000 - fn: 1216.0000 - precision: 0.9322 - recall: 0.9233 - auc: 0.9897 - prc: 0.9811 - accuracy: 0.9278\n",
      "Epoch 196: val_accuracy improved from 0.83115 to 0.83367, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 67s 264ms/step - loss: 0.1827 - tp: 14646.0000 - fp: 1065.0000 - tn: 30659.0000 - fn: 1216.0000 - precision: 0.9322 - recall: 0.9233 - auc: 0.9897 - prc: 0.9811 - accuracy: 0.9278 - val_loss: 0.6419 - val_tp: 1648.0000 - val_fp: 325.0000 - val_tn: 3643.0000 - val_fn: 336.0000 - val_precision: 0.8353 - val_recall: 0.8306 - val_auc: 0.9420 - val_prc: 0.8925 - val_accuracy: 0.8337\n",
      "Epoch 197/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1882 - tp: 14660.0000 - fp: 1061.0000 - tn: 30663.0000 - fn: 1202.0000 - precision: 0.9325 - recall: 0.9242 - auc: 0.9897 - prc: 0.9810 - accuracy: 0.9286\n",
      "Epoch 197: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 60s 233ms/step - loss: 0.1882 - tp: 14660.0000 - fp: 1061.0000 - tn: 30663.0000 - fn: 1202.0000 - precision: 0.9325 - recall: 0.9242 - auc: 0.9897 - prc: 0.9810 - accuracy: 0.9286 - val_loss: 0.6998 - val_tp: 1628.0000 - val_fp: 348.0000 - val_tn: 3620.0000 - val_fn: 356.0000 - val_precision: 0.8239 - val_recall: 0.8206 - val_auc: 0.9364 - val_prc: 0.8844 - val_accuracy: 0.8221\n",
      "Epoch 198/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1872 - tp: 14629.0000 - fp: 1086.0000 - tn: 30638.0000 - fn: 1233.0000 - precision: 0.9309 - recall: 0.9223 - auc: 0.9898 - prc: 0.9811 - accuracy: 0.9266\n",
      "Epoch 198: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.1872 - tp: 14629.0000 - fp: 1086.0000 - tn: 30638.0000 - fn: 1233.0000 - precision: 0.9309 - recall: 0.9223 - auc: 0.9898 - prc: 0.9811 - accuracy: 0.9266 - val_loss: 0.7123 - val_tp: 1602.0000 - val_fp: 369.0000 - val_tn: 3599.0000 - val_fn: 382.0000 - val_precision: 0.8128 - val_recall: 0.8075 - val_auc: 0.9293 - val_prc: 0.8735 - val_accuracy: 0.8110\n",
      "Epoch 199/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1891 - tp: 14628.0000 - fp: 1095.0000 - tn: 30629.0000 - fn: 1234.0000 - precision: 0.9304 - recall: 0.9222 - auc: 0.9892 - prc: 0.9802 - accuracy: 0.9259\n",
      "Epoch 199: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 64s 251ms/step - loss: 0.1891 - tp: 14628.0000 - fp: 1095.0000 - tn: 30629.0000 - fn: 1234.0000 - precision: 0.9304 - recall: 0.9222 - auc: 0.9892 - prc: 0.9802 - accuracy: 0.9259 - val_loss: 0.6109 - val_tp: 1631.0000 - val_fp: 334.0000 - val_tn: 3634.0000 - val_fn: 353.0000 - val_precision: 0.8300 - val_recall: 0.8221 - val_auc: 0.9417 - val_prc: 0.8962 - val_accuracy: 0.8276\n",
      "Epoch 200/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1692 - tp: 14735.0000 - fp: 1009.0000 - tn: 30715.0000 - fn: 1127.0000 - precision: 0.9359 - recall: 0.9289 - auc: 0.9914 - prc: 0.9840 - accuracy: 0.9325\n",
      "Epoch 200: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 67s 263ms/step - loss: 0.1692 - tp: 14735.0000 - fp: 1009.0000 - tn: 30715.0000 - fn: 1127.0000 - precision: 0.9359 - recall: 0.9289 - auc: 0.9914 - prc: 0.9840 - accuracy: 0.9325 - val_loss: 0.6929 - val_tp: 1621.0000 - val_fp: 352.0000 - val_tn: 3616.0000 - val_fn: 363.0000 - val_precision: 0.8216 - val_recall: 0.8170 - val_auc: 0.9338 - val_prc: 0.8799 - val_accuracy: 0.8185\n",
      "Epoch 201/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1843 - tp: 14643.0000 - fp: 1079.0000 - tn: 30645.0000 - fn: 1219.0000 - precision: 0.9314 - recall: 0.9231 - auc: 0.9902 - prc: 0.9818 - accuracy: 0.9275\n",
      "Epoch 201: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.1843 - tp: 14643.0000 - fp: 1079.0000 - tn: 30645.0000 - fn: 1219.0000 - precision: 0.9314 - recall: 0.9231 - auc: 0.9902 - prc: 0.9818 - accuracy: 0.9275 - val_loss: 0.6523 - val_tp: 1628.0000 - val_fp: 339.0000 - val_tn: 3629.0000 - val_fn: 356.0000 - val_precision: 0.8277 - val_recall: 0.8206 - val_auc: 0.9372 - val_prc: 0.8851 - val_accuracy: 0.8241\n",
      "Epoch 202/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1853 - tp: 14701.0000 - fp: 1029.0000 - tn: 30695.0000 - fn: 1161.0000 - precision: 0.9346 - recall: 0.9268 - auc: 0.9897 - prc: 0.9810 - accuracy: 0.9305\n",
      "Epoch 202: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1853 - tp: 14701.0000 - fp: 1029.0000 - tn: 30695.0000 - fn: 1161.0000 - precision: 0.9346 - recall: 0.9268 - auc: 0.9897 - prc: 0.9810 - accuracy: 0.9305 - val_loss: 0.6951 - val_tp: 1614.0000 - val_fp: 359.0000 - val_tn: 3609.0000 - val_fn: 370.0000 - val_precision: 0.8180 - val_recall: 0.8135 - val_auc: 0.9334 - val_prc: 0.8795 - val_accuracy: 0.8160\n",
      "Epoch 203/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1786 - tp: 14715.0000 - fp: 1015.0000 - tn: 30709.0000 - fn: 1147.0000 - precision: 0.9355 - recall: 0.9277 - auc: 0.9906 - prc: 0.9825 - accuracy: 0.9316\n",
      "Epoch 203: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1786 - tp: 14715.0000 - fp: 1015.0000 - tn: 30709.0000 - fn: 1147.0000 - precision: 0.9355 - recall: 0.9277 - auc: 0.9906 - prc: 0.9825 - accuracy: 0.9316 - val_loss: 0.7651 - val_tp: 1585.0000 - val_fp: 387.0000 - val_tn: 3581.0000 - val_fn: 399.0000 - val_precision: 0.8038 - val_recall: 0.7989 - val_auc: 0.9252 - val_prc: 0.8637 - val_accuracy: 0.8009\n",
      "Epoch 204/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1834 - tp: 14703.0000 - fp: 1024.0000 - tn: 30700.0000 - fn: 1159.0000 - precision: 0.9349 - recall: 0.9269 - auc: 0.9903 - prc: 0.9819 - accuracy: 0.9305\n",
      "Epoch 204: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1834 - tp: 14703.0000 - fp: 1024.0000 - tn: 30700.0000 - fn: 1159.0000 - precision: 0.9349 - recall: 0.9269 - auc: 0.9903 - prc: 0.9819 - accuracy: 0.9305 - val_loss: 0.7456 - val_tp: 1597.0000 - val_fp: 378.0000 - val_tn: 3590.0000 - val_fn: 387.0000 - val_precision: 0.8086 - val_recall: 0.8049 - val_auc: 0.9296 - val_prc: 0.8713 - val_accuracy: 0.8070\n",
      "Epoch 205/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1770 - tp: 14743.0000 - fp: 998.0000 - tn: 30726.0000 - fn: 1119.0000 - precision: 0.9366 - recall: 0.9295 - auc: 0.9909 - prc: 0.9830 - accuracy: 0.9328\n",
      "Epoch 205: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.1770 - tp: 14743.0000 - fp: 998.0000 - tn: 30726.0000 - fn: 1119.0000 - precision: 0.9366 - recall: 0.9295 - auc: 0.9909 - prc: 0.9830 - accuracy: 0.9328 - val_loss: 0.7803 - val_tp: 1596.0000 - val_fp: 379.0000 - val_tn: 3589.0000 - val_fn: 388.0000 - val_precision: 0.8081 - val_recall: 0.8044 - val_auc: 0.9243 - val_prc: 0.8666 - val_accuracy: 0.8044\n",
      "Epoch 206/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1679 - tp: 14788.0000 - fp: 952.0000 - tn: 30772.0000 - fn: 1074.0000 - precision: 0.9395 - recall: 0.9323 - auc: 0.9916 - prc: 0.9844 - accuracy: 0.9362\n",
      "Epoch 206: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1679 - tp: 14788.0000 - fp: 952.0000 - tn: 30772.0000 - fn: 1074.0000 - precision: 0.9395 - recall: 0.9323 - auc: 0.9916 - prc: 0.9844 - accuracy: 0.9362 - val_loss: 0.8797 - val_tp: 1566.0000 - val_fp: 407.0000 - val_tn: 3561.0000 - val_fn: 418.0000 - val_precision: 0.7937 - val_recall: 0.7893 - val_auc: 0.9164 - val_prc: 0.8492 - val_accuracy: 0.7913\n",
      "Epoch 207/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1775 - tp: 14652.0000 - fp: 1072.0000 - tn: 30652.0000 - fn: 1210.0000 - precision: 0.9318 - recall: 0.9237 - auc: 0.9903 - prc: 0.9820 - accuracy: 0.9274\n",
      "Epoch 207: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1775 - tp: 14652.0000 - fp: 1072.0000 - tn: 30652.0000 - fn: 1210.0000 - precision: 0.9318 - recall: 0.9237 - auc: 0.9903 - prc: 0.9820 - accuracy: 0.9274 - val_loss: 0.7871 - val_tp: 1584.0000 - val_fp: 384.0000 - val_tn: 3584.0000 - val_fn: 400.0000 - val_precision: 0.8049 - val_recall: 0.7984 - val_auc: 0.9233 - val_prc: 0.8631 - val_accuracy: 0.8019\n",
      "Epoch 208/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1767 - tp: 14728.0000 - fp: 1013.0000 - tn: 30711.0000 - fn: 1134.0000 - precision: 0.9356 - recall: 0.9285 - auc: 0.9907 - prc: 0.9828 - accuracy: 0.9322\n",
      "Epoch 208: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.1767 - tp: 14728.0000 - fp: 1013.0000 - tn: 30711.0000 - fn: 1134.0000 - precision: 0.9356 - recall: 0.9285 - auc: 0.9907 - prc: 0.9828 - accuracy: 0.9322 - val_loss: 0.7602 - val_tp: 1596.0000 - val_fp: 372.0000 - val_tn: 3596.0000 - val_fn: 388.0000 - val_precision: 0.8110 - val_recall: 0.8044 - val_auc: 0.9263 - val_prc: 0.8663 - val_accuracy: 0.8085\n",
      "Epoch 209/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1860 - tp: 14669.0000 - fp: 1056.0000 - tn: 30668.0000 - fn: 1193.0000 - precision: 0.9328 - recall: 0.9248 - auc: 0.9901 - prc: 0.9818 - accuracy: 0.9293\n",
      "Epoch 209: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1860 - tp: 14669.0000 - fp: 1056.0000 - tn: 30668.0000 - fn: 1193.0000 - precision: 0.9328 - recall: 0.9248 - auc: 0.9901 - prc: 0.9818 - accuracy: 0.9293 - val_loss: 0.6911 - val_tp: 1627.0000 - val_fp: 343.0000 - val_tn: 3625.0000 - val_fn: 357.0000 - val_precision: 0.8259 - val_recall: 0.8201 - val_auc: 0.9357 - val_prc: 0.8831 - val_accuracy: 0.8231\n",
      "Epoch 210/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1780 - tp: 14724.0000 - fp: 1000.0000 - tn: 30724.0000 - fn: 1138.0000 - precision: 0.9364 - recall: 0.9283 - auc: 0.9906 - prc: 0.9825 - accuracy: 0.9323\n",
      "Epoch 210: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.1780 - tp: 14724.0000 - fp: 1000.0000 - tn: 30724.0000 - fn: 1138.0000 - precision: 0.9364 - recall: 0.9283 - auc: 0.9906 - prc: 0.9825 - accuracy: 0.9323 - val_loss: 0.6489 - val_tp: 1636.0000 - val_fp: 338.0000 - val_tn: 3630.0000 - val_fn: 348.0000 - val_precision: 0.8288 - val_recall: 0.8246 - val_auc: 0.9403 - val_prc: 0.8928 - val_accuracy: 0.8271\n",
      "Epoch 211/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1705 - tp: 14779.0000 - fp: 964.0000 - tn: 30760.0000 - fn: 1083.0000 - precision: 0.9388 - recall: 0.9317 - auc: 0.9910 - prc: 0.9833 - accuracy: 0.9356\n",
      "Epoch 211: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 54s 212ms/step - loss: 0.1705 - tp: 14779.0000 - fp: 964.0000 - tn: 30760.0000 - fn: 1083.0000 - precision: 0.9388 - recall: 0.9317 - auc: 0.9910 - prc: 0.9833 - accuracy: 0.9356 - val_loss: 0.6769 - val_tp: 1602.0000 - val_fp: 367.0000 - val_tn: 3601.0000 - val_fn: 382.0000 - val_precision: 0.8136 - val_recall: 0.8075 - val_auc: 0.9370 - val_prc: 0.8859 - val_accuracy: 0.8095\n",
      "Epoch 212/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1804 - tp: 14748.0000 - fp: 971.0000 - tn: 30753.0000 - fn: 1114.0000 - precision: 0.9382 - recall: 0.9298 - auc: 0.9906 - prc: 0.9827 - accuracy: 0.9336\n",
      "Epoch 212: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 56s 218ms/step - loss: 0.1804 - tp: 14748.0000 - fp: 971.0000 - tn: 30753.0000 - fn: 1114.0000 - precision: 0.9382 - recall: 0.9298 - auc: 0.9906 - prc: 0.9827 - accuracy: 0.9336 - val_loss: 0.7412 - val_tp: 1600.0000 - val_fp: 361.0000 - val_tn: 3607.0000 - val_fn: 384.0000 - val_precision: 0.8159 - val_recall: 0.8065 - val_auc: 0.9303 - val_prc: 0.8768 - val_accuracy: 0.8125\n",
      "Epoch 213/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1725 - tp: 14735.0000 - fp: 1007.0000 - tn: 30717.0000 - fn: 1127.0000 - precision: 0.9360 - recall: 0.9289 - auc: 0.9909 - prc: 0.9832 - accuracy: 0.9324\n",
      "Epoch 213: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 55s 214ms/step - loss: 0.1725 - tp: 14735.0000 - fp: 1007.0000 - tn: 30717.0000 - fn: 1127.0000 - precision: 0.9360 - recall: 0.9289 - auc: 0.9909 - prc: 0.9832 - accuracy: 0.9324 - val_loss: 0.6714 - val_tp: 1624.0000 - val_fp: 346.0000 - val_tn: 3622.0000 - val_fn: 360.0000 - val_precision: 0.8244 - val_recall: 0.8185 - val_auc: 0.9363 - val_prc: 0.8837 - val_accuracy: 0.8211\n",
      "Epoch 214/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1766 - tp: 14726.0000 - fp: 984.0000 - tn: 30740.0000 - fn: 1136.0000 - precision: 0.9374 - recall: 0.9284 - auc: 0.9908 - prc: 0.9830 - accuracy: 0.9335\n",
      "Epoch 214: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 55s 214ms/step - loss: 0.1766 - tp: 14726.0000 - fp: 984.0000 - tn: 30740.0000 - fn: 1136.0000 - precision: 0.9374 - recall: 0.9284 - auc: 0.9908 - prc: 0.9830 - accuracy: 0.9335 - val_loss: 0.6602 - val_tp: 1628.0000 - val_fp: 337.0000 - val_tn: 3631.0000 - val_fn: 356.0000 - val_precision: 0.8285 - val_recall: 0.8206 - val_auc: 0.9389 - val_prc: 0.8885 - val_accuracy: 0.8251\n",
      "Epoch 215/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1720 - tp: 14758.0000 - fp: 985.0000 - tn: 30739.0000 - fn: 1104.0000 - precision: 0.9374 - recall: 0.9304 - auc: 0.9912 - prc: 0.9836 - accuracy: 0.9338\n",
      "Epoch 215: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 54s 214ms/step - loss: 0.1720 - tp: 14758.0000 - fp: 985.0000 - tn: 30739.0000 - fn: 1104.0000 - precision: 0.9374 - recall: 0.9304 - auc: 0.9912 - prc: 0.9836 - accuracy: 0.9338 - val_loss: 0.6659 - val_tp: 1628.0000 - val_fp: 346.0000 - val_tn: 3622.0000 - val_fn: 356.0000 - val_precision: 0.8247 - val_recall: 0.8206 - val_auc: 0.9392 - val_prc: 0.8894 - val_accuracy: 0.8221\n",
      "Epoch 216/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1729 - tp: 14750.0000 - fp: 987.0000 - tn: 30737.0000 - fn: 1112.0000 - precision: 0.9373 - recall: 0.9299 - auc: 0.9906 - prc: 0.9826 - accuracy: 0.9339\n",
      "Epoch 216: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 55s 214ms/step - loss: 0.1729 - tp: 14750.0000 - fp: 987.0000 - tn: 30737.0000 - fn: 1112.0000 - precision: 0.9373 - recall: 0.9299 - auc: 0.9906 - prc: 0.9826 - accuracy: 0.9339 - val_loss: 0.6437 - val_tp: 1645.0000 - val_fp: 330.0000 - val_tn: 3638.0000 - val_fn: 339.0000 - val_precision: 0.8329 - val_recall: 0.8291 - val_auc: 0.9422 - val_prc: 0.8933 - val_accuracy: 0.8296\n",
      "Epoch 217/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1657 - tp: 14807.0000 - fp: 926.0000 - tn: 30798.0000 - fn: 1055.0000 - precision: 0.9411 - recall: 0.9335 - auc: 0.9916 - prc: 0.9844 - accuracy: 0.9376\n",
      "Epoch 217: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 54s 213ms/step - loss: 0.1657 - tp: 14807.0000 - fp: 926.0000 - tn: 30798.0000 - fn: 1055.0000 - precision: 0.9411 - recall: 0.9335 - auc: 0.9916 - prc: 0.9844 - accuracy: 0.9376 - val_loss: 0.6665 - val_tp: 1639.0000 - val_fp: 333.0000 - val_tn: 3635.0000 - val_fn: 345.0000 - val_precision: 0.8311 - val_recall: 0.8261 - val_auc: 0.9383 - val_prc: 0.8870 - val_accuracy: 0.8271\n",
      "Epoch 218/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1763 - tp: 14738.0000 - fp: 971.0000 - tn: 30753.0000 - fn: 1124.0000 - precision: 0.9382 - recall: 0.9291 - auc: 0.9909 - prc: 0.9831 - accuracy: 0.9339\n",
      "Epoch 218: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 55s 215ms/step - loss: 0.1763 - tp: 14738.0000 - fp: 971.0000 - tn: 30753.0000 - fn: 1124.0000 - precision: 0.9382 - recall: 0.9291 - auc: 0.9909 - prc: 0.9831 - accuracy: 0.9339 - val_loss: 0.6427 - val_tp: 1639.0000 - val_fp: 328.0000 - val_tn: 3640.0000 - val_fn: 345.0000 - val_precision: 0.8332 - val_recall: 0.8261 - val_auc: 0.9422 - val_prc: 0.8980 - val_accuracy: 0.8291\n",
      "Epoch 219/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1655 - tp: 14813.0000 - fp: 941.0000 - tn: 30783.0000 - fn: 1049.0000 - precision: 0.9403 - recall: 0.9339 - auc: 0.9917 - prc: 0.9844 - accuracy: 0.9371\n",
      "Epoch 219: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 54s 213ms/step - loss: 0.1655 - tp: 14813.0000 - fp: 941.0000 - tn: 30783.0000 - fn: 1049.0000 - precision: 0.9403 - recall: 0.9339 - auc: 0.9917 - prc: 0.9844 - accuracy: 0.9371 - val_loss: 0.7263 - val_tp: 1635.0000 - val_fp: 338.0000 - val_tn: 3630.0000 - val_fn: 349.0000 - val_precision: 0.8287 - val_recall: 0.8241 - val_auc: 0.9350 - val_prc: 0.8820 - val_accuracy: 0.8261\n",
      "Epoch 220/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1639 - tp: 14807.0000 - fp: 937.0000 - tn: 30787.0000 - fn: 1055.0000 - precision: 0.9405 - recall: 0.9335 - auc: 0.9919 - prc: 0.9849 - accuracy: 0.9371\n",
      "Epoch 220: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1639 - tp: 14807.0000 - fp: 937.0000 - tn: 30787.0000 - fn: 1055.0000 - precision: 0.9405 - recall: 0.9335 - auc: 0.9919 - prc: 0.9849 - accuracy: 0.9371 - val_loss: 0.6469 - val_tp: 1629.0000 - val_fp: 338.0000 - val_tn: 3630.0000 - val_fn: 355.0000 - val_precision: 0.8282 - val_recall: 0.8211 - val_auc: 0.9403 - val_prc: 0.8914 - val_accuracy: 0.8246\n",
      "Epoch 221/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1670 - tp: 14806.0000 - fp: 941.0000 - tn: 30783.0000 - fn: 1056.0000 - precision: 0.9402 - recall: 0.9334 - auc: 0.9915 - prc: 0.9842 - accuracy: 0.9373\n",
      "Epoch 221: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.1670 - tp: 14806.0000 - fp: 941.0000 - tn: 30783.0000 - fn: 1056.0000 - precision: 0.9402 - recall: 0.9334 - auc: 0.9915 - prc: 0.9842 - accuracy: 0.9373 - val_loss: 0.6555 - val_tp: 1625.0000 - val_fp: 343.0000 - val_tn: 3625.0000 - val_fn: 359.0000 - val_precision: 0.8257 - val_recall: 0.8191 - val_auc: 0.9407 - val_prc: 0.8950 - val_accuracy: 0.8211\n",
      "Epoch 222/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1706 - tp: 14732.0000 - fp: 1006.0000 - tn: 30718.0000 - fn: 1130.0000 - precision: 0.9361 - recall: 0.9288 - auc: 0.9911 - prc: 0.9832 - accuracy: 0.9322\n",
      "Epoch 222: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1706 - tp: 14732.0000 - fp: 1006.0000 - tn: 30718.0000 - fn: 1130.0000 - precision: 0.9361 - recall: 0.9288 - auc: 0.9911 - prc: 0.9832 - accuracy: 0.9322 - val_loss: 0.6334 - val_tp: 1630.0000 - val_fp: 344.0000 - val_tn: 3624.0000 - val_fn: 354.0000 - val_precision: 0.8257 - val_recall: 0.8216 - val_auc: 0.9424 - val_prc: 0.8964 - val_accuracy: 0.8241\n",
      "Epoch 223/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1819 - tp: 14695.0000 - fp: 1046.0000 - tn: 30678.0000 - fn: 1167.0000 - precision: 0.9335 - recall: 0.9264 - auc: 0.9903 - prc: 0.9820 - accuracy: 0.9305\n",
      "Epoch 223: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 221ms/step - loss: 0.1819 - tp: 14695.0000 - fp: 1046.0000 - tn: 30678.0000 - fn: 1167.0000 - precision: 0.9335 - recall: 0.9264 - auc: 0.9903 - prc: 0.9820 - accuracy: 0.9305 - val_loss: 0.6409 - val_tp: 1618.0000 - val_fp: 348.0000 - val_tn: 3620.0000 - val_fn: 366.0000 - val_precision: 0.8230 - val_recall: 0.8155 - val_auc: 0.9393 - val_prc: 0.8880 - val_accuracy: 0.8175\n",
      "Epoch 224/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1631 - tp: 14820.0000 - fp: 921.0000 - tn: 30803.0000 - fn: 1042.0000 - precision: 0.9415 - recall: 0.9343 - auc: 0.9919 - prc: 0.9851 - accuracy: 0.9385\n",
      "Epoch 224: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1631 - tp: 14820.0000 - fp: 921.0000 - tn: 30803.0000 - fn: 1042.0000 - precision: 0.9415 - recall: 0.9343 - auc: 0.9919 - prc: 0.9851 - accuracy: 0.9385 - val_loss: 0.5974 - val_tp: 1643.0000 - val_fp: 317.0000 - val_tn: 3651.0000 - val_fn: 341.0000 - val_precision: 0.8383 - val_recall: 0.8281 - val_auc: 0.9453 - val_prc: 0.9016 - val_accuracy: 0.8327\n",
      "Epoch 225/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1620 - tp: 14814.0000 - fp: 930.0000 - tn: 30794.0000 - fn: 1048.0000 - precision: 0.9409 - recall: 0.9339 - auc: 0.9919 - prc: 0.9850 - accuracy: 0.9377\n",
      "Epoch 225: val_accuracy did not improve from 0.83367\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1620 - tp: 14814.0000 - fp: 930.0000 - tn: 30794.0000 - fn: 1048.0000 - precision: 0.9409 - recall: 0.9339 - auc: 0.9919 - prc: 0.9850 - accuracy: 0.9377 - val_loss: 0.6145 - val_tp: 1653.0000 - val_fp: 320.0000 - val_tn: 3648.0000 - val_fn: 331.0000 - val_precision: 0.8378 - val_recall: 0.8332 - val_auc: 0.9441 - val_prc: 0.8997 - val_accuracy: 0.8332\n",
      "Epoch 226/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1607 - tp: 14806.0000 - fp: 965.0000 - tn: 30759.0000 - fn: 1056.0000 - precision: 0.9388 - recall: 0.9334 - auc: 0.9921 - prc: 0.9853 - accuracy: 0.9360\n",
      "Epoch 226: val_accuracy improved from 0.83367 to 0.84375, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.1607 - tp: 14806.0000 - fp: 965.0000 - tn: 30759.0000 - fn: 1056.0000 - precision: 0.9388 - recall: 0.9334 - auc: 0.9921 - prc: 0.9853 - accuracy: 0.9360 - val_loss: 0.5462 - val_tp: 1669.0000 - val_fp: 302.0000 - val_tn: 3666.0000 - val_fn: 315.0000 - val_precision: 0.8468 - val_recall: 0.8412 - val_auc: 0.9515 - val_prc: 0.9109 - val_accuracy: 0.8438\n",
      "Epoch 227/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1633 - tp: 14796.0000 - fp: 932.0000 - tn: 30792.0000 - fn: 1066.0000 - precision: 0.9407 - recall: 0.9328 - auc: 0.9921 - prc: 0.9854 - accuracy: 0.9361\n",
      "Epoch 227: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1633 - tp: 14796.0000 - fp: 932.0000 - tn: 30792.0000 - fn: 1066.0000 - precision: 0.9407 - recall: 0.9328 - auc: 0.9921 - prc: 0.9854 - accuracy: 0.9361 - val_loss: 0.5695 - val_tp: 1660.0000 - val_fp: 315.0000 - val_tn: 3653.0000 - val_fn: 324.0000 - val_precision: 0.8405 - val_recall: 0.8367 - val_auc: 0.9479 - val_prc: 0.9060 - val_accuracy: 0.8387\n",
      "Epoch 228/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1669 - tp: 14785.0000 - fp: 949.0000 - tn: 30775.0000 - fn: 1077.0000 - precision: 0.9397 - recall: 0.9321 - auc: 0.9916 - prc: 0.9843 - accuracy: 0.9359\n",
      "Epoch 228: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1669 - tp: 14785.0000 - fp: 949.0000 - tn: 30775.0000 - fn: 1077.0000 - precision: 0.9397 - recall: 0.9321 - auc: 0.9916 - prc: 0.9843 - accuracy: 0.9359 - val_loss: 0.5802 - val_tp: 1672.0000 - val_fp: 302.0000 - val_tn: 3666.0000 - val_fn: 312.0000 - val_precision: 0.8470 - val_recall: 0.8427 - val_auc: 0.9478 - val_prc: 0.9046 - val_accuracy: 0.8438\n",
      "Epoch 229/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1634 - tp: 14858.0000 - fp: 889.0000 - tn: 30835.0000 - fn: 1004.0000 - precision: 0.9435 - recall: 0.9367 - auc: 0.9920 - prc: 0.9852 - accuracy: 0.9395\n",
      "Epoch 229: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1634 - tp: 14858.0000 - fp: 889.0000 - tn: 30835.0000 - fn: 1004.0000 - precision: 0.9435 - recall: 0.9367 - auc: 0.9920 - prc: 0.9852 - accuracy: 0.9395 - val_loss: 0.6898 - val_tp: 1616.0000 - val_fp: 355.0000 - val_tn: 3613.0000 - val_fn: 368.0000 - val_precision: 0.8199 - val_recall: 0.8145 - val_auc: 0.9375 - val_prc: 0.8889 - val_accuracy: 0.8160\n",
      "Epoch 230/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1615 - tp: 14801.0000 - fp: 945.0000 - tn: 30779.0000 - fn: 1061.0000 - precision: 0.9400 - recall: 0.9331 - auc: 0.9920 - prc: 0.9848 - accuracy: 0.9363\n",
      "Epoch 230: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1615 - tp: 14801.0000 - fp: 945.0000 - tn: 30779.0000 - fn: 1061.0000 - precision: 0.9400 - recall: 0.9331 - auc: 0.9920 - prc: 0.9848 - accuracy: 0.9363 - val_loss: 0.6228 - val_tp: 1626.0000 - val_fp: 346.0000 - val_tn: 3622.0000 - val_fn: 358.0000 - val_precision: 0.8245 - val_recall: 0.8196 - val_auc: 0.9428 - val_prc: 0.8975 - val_accuracy: 0.8211\n",
      "Epoch 231/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1640 - tp: 14814.0000 - fp: 932.0000 - tn: 30792.0000 - fn: 1048.0000 - precision: 0.9408 - recall: 0.9339 - auc: 0.9918 - prc: 0.9847 - accuracy: 0.9372\n",
      "Epoch 231: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1640 - tp: 14814.0000 - fp: 932.0000 - tn: 30792.0000 - fn: 1048.0000 - precision: 0.9408 - recall: 0.9339 - auc: 0.9918 - prc: 0.9847 - accuracy: 0.9372 - val_loss: 0.6702 - val_tp: 1634.0000 - val_fp: 332.0000 - val_tn: 3636.0000 - val_fn: 350.0000 - val_precision: 0.8311 - val_recall: 0.8236 - val_auc: 0.9374 - val_prc: 0.8885 - val_accuracy: 0.8261\n",
      "Epoch 232/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1675 - tp: 14788.0000 - fp: 947.0000 - tn: 30777.0000 - fn: 1074.0000 - precision: 0.9398 - recall: 0.9323 - auc: 0.9917 - prc: 0.9847 - accuracy: 0.9357\n",
      "Epoch 232: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1675 - tp: 14788.0000 - fp: 947.0000 - tn: 30777.0000 - fn: 1074.0000 - precision: 0.9398 - recall: 0.9323 - auc: 0.9917 - prc: 0.9847 - accuracy: 0.9357 - val_loss: 0.6891 - val_tp: 1618.0000 - val_fp: 349.0000 - val_tn: 3619.0000 - val_fn: 366.0000 - val_precision: 0.8226 - val_recall: 0.8155 - val_auc: 0.9325 - val_prc: 0.8766 - val_accuracy: 0.8170\n",
      "Epoch 233/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1570 - tp: 14879.0000 - fp: 885.0000 - tn: 30839.0000 - fn: 983.0000 - precision: 0.9439 - recall: 0.9380 - auc: 0.9926 - prc: 0.9862 - accuracy: 0.9406\n",
      "Epoch 233: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1570 - tp: 14879.0000 - fp: 885.0000 - tn: 30839.0000 - fn: 983.0000 - precision: 0.9439 - recall: 0.9380 - auc: 0.9926 - prc: 0.9862 - accuracy: 0.9406 - val_loss: 0.6852 - val_tp: 1623.0000 - val_fp: 342.0000 - val_tn: 3626.0000 - val_fn: 361.0000 - val_precision: 0.8260 - val_recall: 0.8180 - val_auc: 0.9355 - val_prc: 0.8846 - val_accuracy: 0.8226\n",
      "Epoch 234/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1585 - tp: 14855.0000 - fp: 922.0000 - tn: 30802.0000 - fn: 1007.0000 - precision: 0.9416 - recall: 0.9365 - auc: 0.9923 - prc: 0.9858 - accuracy: 0.9394\n",
      "Epoch 234: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1585 - tp: 14855.0000 - fp: 922.0000 - tn: 30802.0000 - fn: 1007.0000 - precision: 0.9416 - recall: 0.9365 - auc: 0.9923 - prc: 0.9858 - accuracy: 0.9394 - val_loss: 0.6245 - val_tp: 1631.0000 - val_fp: 334.0000 - val_tn: 3634.0000 - val_fn: 353.0000 - val_precision: 0.8300 - val_recall: 0.8221 - val_auc: 0.9402 - val_prc: 0.8923 - val_accuracy: 0.8266\n",
      "Epoch 235/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1649 - tp: 14799.0000 - fp: 960.0000 - tn: 30764.0000 - fn: 1063.0000 - precision: 0.9391 - recall: 0.9330 - auc: 0.9918 - prc: 0.9845 - accuracy: 0.9355\n",
      "Epoch 235: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1649 - tp: 14799.0000 - fp: 960.0000 - tn: 30764.0000 - fn: 1063.0000 - precision: 0.9391 - recall: 0.9330 - auc: 0.9918 - prc: 0.9845 - accuracy: 0.9355 - val_loss: 0.6459 - val_tp: 1651.0000 - val_fp: 322.0000 - val_tn: 3646.0000 - val_fn: 333.0000 - val_precision: 0.8368 - val_recall: 0.8322 - val_auc: 0.9408 - val_prc: 0.8943 - val_accuracy: 0.8337\n",
      "Epoch 236/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1610 - tp: 14827.0000 - fp: 925.0000 - tn: 30799.0000 - fn: 1035.0000 - precision: 0.9413 - recall: 0.9347 - auc: 0.9920 - prc: 0.9852 - accuracy: 0.9383\n",
      "Epoch 236: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1610 - tp: 14827.0000 - fp: 925.0000 - tn: 30799.0000 - fn: 1035.0000 - precision: 0.9413 - recall: 0.9347 - auc: 0.9920 - prc: 0.9852 - accuracy: 0.9383 - val_loss: 0.6154 - val_tp: 1656.0000 - val_fp: 314.0000 - val_tn: 3654.0000 - val_fn: 328.0000 - val_precision: 0.8406 - val_recall: 0.8347 - val_auc: 0.9441 - val_prc: 0.8996 - val_accuracy: 0.8387\n",
      "Epoch 237/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1660 - tp: 14809.0000 - fp: 932.0000 - tn: 30792.0000 - fn: 1053.0000 - precision: 0.9408 - recall: 0.9336 - auc: 0.9915 - prc: 0.9839 - accuracy: 0.9371\n",
      "Epoch 237: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1660 - tp: 14809.0000 - fp: 932.0000 - tn: 30792.0000 - fn: 1053.0000 - precision: 0.9408 - recall: 0.9336 - auc: 0.9915 - prc: 0.9839 - accuracy: 0.9371 - val_loss: 0.5788 - val_tp: 1641.0000 - val_fp: 330.0000 - val_tn: 3638.0000 - val_fn: 343.0000 - val_precision: 0.8326 - val_recall: 0.8271 - val_auc: 0.9475 - val_prc: 0.9055 - val_accuracy: 0.8296\n",
      "Epoch 238/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1652 - tp: 14811.0000 - fp: 922.0000 - tn: 30802.0000 - fn: 1051.0000 - precision: 0.9414 - recall: 0.9337 - auc: 0.9921 - prc: 0.9854 - accuracy: 0.9376\n",
      "Epoch 238: val_accuracy did not improve from 0.84375\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1652 - tp: 14811.0000 - fp: 922.0000 - tn: 30802.0000 - fn: 1051.0000 - precision: 0.9414 - recall: 0.9337 - auc: 0.9921 - prc: 0.9854 - accuracy: 0.9376 - val_loss: 0.5552 - val_tp: 1659.0000 - val_fp: 311.0000 - val_tn: 3657.0000 - val_fn: 325.0000 - val_precision: 0.8421 - val_recall: 0.8362 - val_auc: 0.9508 - val_prc: 0.9119 - val_accuracy: 0.8387\n",
      "Epoch 239/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1584 - tp: 14891.0000 - fp: 863.0000 - tn: 30861.0000 - fn: 971.0000 - precision: 0.9452 - recall: 0.9388 - auc: 0.9926 - prc: 0.9862 - accuracy: 0.9417\n",
      "Epoch 239: val_accuracy improved from 0.84375 to 0.84728, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.1584 - tp: 14891.0000 - fp: 863.0000 - tn: 30861.0000 - fn: 971.0000 - precision: 0.9452 - recall: 0.9388 - auc: 0.9926 - prc: 0.9862 - accuracy: 0.9417 - val_loss: 0.5525 - val_tp: 1670.0000 - val_fp: 291.0000 - val_tn: 3677.0000 - val_fn: 314.0000 - val_precision: 0.8516 - val_recall: 0.8417 - val_auc: 0.9486 - val_prc: 0.9078 - val_accuracy: 0.8473\n",
      "Epoch 240/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1593 - tp: 14854.0000 - fp: 891.0000 - tn: 30833.0000 - fn: 1008.0000 - precision: 0.9434 - recall: 0.9365 - auc: 0.9926 - prc: 0.9863 - accuracy: 0.9397\n",
      "Epoch 240: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1593 - tp: 14854.0000 - fp: 891.0000 - tn: 30833.0000 - fn: 1008.0000 - precision: 0.9434 - recall: 0.9365 - auc: 0.9926 - prc: 0.9863 - accuracy: 0.9397 - val_loss: 0.5360 - val_tp: 1657.0000 - val_fp: 315.0000 - val_tn: 3653.0000 - val_fn: 327.0000 - val_precision: 0.8403 - val_recall: 0.8352 - val_auc: 0.9512 - val_prc: 0.9125 - val_accuracy: 0.8377\n",
      "Epoch 241/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1523 - tp: 14903.0000 - fp: 850.0000 - tn: 30874.0000 - fn: 959.0000 - precision: 0.9460 - recall: 0.9395 - auc: 0.9926 - prc: 0.9862 - accuracy: 0.9428\n",
      "Epoch 241: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1523 - tp: 14903.0000 - fp: 850.0000 - tn: 30874.0000 - fn: 959.0000 - precision: 0.9460 - recall: 0.9395 - auc: 0.9926 - prc: 0.9862 - accuracy: 0.9428 - val_loss: 0.5560 - val_tp: 1653.0000 - val_fp: 318.0000 - val_tn: 3650.0000 - val_fn: 331.0000 - val_precision: 0.8387 - val_recall: 0.8332 - val_auc: 0.9492 - val_prc: 0.9068 - val_accuracy: 0.8357\n",
      "Epoch 242/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1571 - tp: 14859.0000 - fp: 903.0000 - tn: 30821.0000 - fn: 1003.0000 - precision: 0.9427 - recall: 0.9368 - auc: 0.9924 - prc: 0.9861 - accuracy: 0.9402\n",
      "Epoch 242: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1571 - tp: 14859.0000 - fp: 903.0000 - tn: 30821.0000 - fn: 1003.0000 - precision: 0.9427 - recall: 0.9368 - auc: 0.9924 - prc: 0.9861 - accuracy: 0.9402 - val_loss: 0.6031 - val_tp: 1646.0000 - val_fp: 327.0000 - val_tn: 3641.0000 - val_fn: 338.0000 - val_precision: 0.8343 - val_recall: 0.8296 - val_auc: 0.9446 - val_prc: 0.9012 - val_accuracy: 0.8311\n",
      "Epoch 243/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1559 - tp: 14844.0000 - fp: 904.0000 - tn: 30820.0000 - fn: 1018.0000 - precision: 0.9426 - recall: 0.9358 - auc: 0.9927 - prc: 0.9863 - accuracy: 0.9392\n",
      "Epoch 243: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1559 - tp: 14844.0000 - fp: 904.0000 - tn: 30820.0000 - fn: 1018.0000 - precision: 0.9426 - recall: 0.9358 - auc: 0.9927 - prc: 0.9863 - accuracy: 0.9392 - val_loss: 0.6183 - val_tp: 1648.0000 - val_fp: 320.0000 - val_tn: 3648.0000 - val_fn: 336.0000 - val_precision: 0.8374 - val_recall: 0.8306 - val_auc: 0.9406 - val_prc: 0.8932 - val_accuracy: 0.8327\n",
      "Epoch 244/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1581 - tp: 14848.0000 - fp: 897.0000 - tn: 30827.0000 - fn: 1014.0000 - precision: 0.9430 - recall: 0.9361 - auc: 0.9926 - prc: 0.9861 - accuracy: 0.9401\n",
      "Epoch 244: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1581 - tp: 14848.0000 - fp: 897.0000 - tn: 30827.0000 - fn: 1014.0000 - precision: 0.9430 - recall: 0.9361 - auc: 0.9926 - prc: 0.9861 - accuracy: 0.9401 - val_loss: 0.6568 - val_tp: 1643.0000 - val_fp: 323.0000 - val_tn: 3645.0000 - val_fn: 341.0000 - val_precision: 0.8357 - val_recall: 0.8281 - val_auc: 0.9378 - val_prc: 0.8876 - val_accuracy: 0.8322\n",
      "Epoch 245/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1523 - tp: 14857.0000 - fp: 898.0000 - tn: 30826.0000 - fn: 1005.0000 - precision: 0.9430 - recall: 0.9366 - auc: 0.9931 - prc: 0.9871 - accuracy: 0.9396\n",
      "Epoch 245: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1523 - tp: 14857.0000 - fp: 898.0000 - tn: 30826.0000 - fn: 1005.0000 - precision: 0.9430 - recall: 0.9366 - auc: 0.9931 - prc: 0.9871 - accuracy: 0.9396 - val_loss: 0.6355 - val_tp: 1640.0000 - val_fp: 329.0000 - val_tn: 3639.0000 - val_fn: 344.0000 - val_precision: 0.8329 - val_recall: 0.8266 - val_auc: 0.9392 - val_prc: 0.8888 - val_accuracy: 0.8291\n",
      "Epoch 246/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1611 - tp: 14817.0000 - fp: 933.0000 - tn: 30791.0000 - fn: 1045.0000 - precision: 0.9408 - recall: 0.9341 - auc: 0.9917 - prc: 0.9842 - accuracy: 0.9378\n",
      "Epoch 246: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1611 - tp: 14817.0000 - fp: 933.0000 - tn: 30791.0000 - fn: 1045.0000 - precision: 0.9408 - recall: 0.9341 - auc: 0.9917 - prc: 0.9842 - accuracy: 0.9378 - val_loss: 0.6487 - val_tp: 1638.0000 - val_fp: 324.0000 - val_tn: 3644.0000 - val_fn: 346.0000 - val_precision: 0.8349 - val_recall: 0.8256 - val_auc: 0.9396 - val_prc: 0.8912 - val_accuracy: 0.8311\n",
      "Epoch 247/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1598 - tp: 14829.0000 - fp: 921.0000 - tn: 30803.0000 - fn: 1033.0000 - precision: 0.9415 - recall: 0.9349 - auc: 0.9920 - prc: 0.9854 - accuracy: 0.9385\n",
      "Epoch 247: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1598 - tp: 14829.0000 - fp: 921.0000 - tn: 30803.0000 - fn: 1033.0000 - precision: 0.9415 - recall: 0.9349 - auc: 0.9920 - prc: 0.9854 - accuracy: 0.9385 - val_loss: 0.7014 - val_tp: 1632.0000 - val_fp: 340.0000 - val_tn: 3628.0000 - val_fn: 352.0000 - val_precision: 0.8276 - val_recall: 0.8226 - val_auc: 0.9376 - val_prc: 0.8866 - val_accuracy: 0.8236\n",
      "Epoch 248/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1498 - tp: 14911.0000 - fp: 849.0000 - tn: 30875.0000 - fn: 951.0000 - precision: 0.9461 - recall: 0.9400 - auc: 0.9931 - prc: 0.9871 - accuracy: 0.9426\n",
      "Epoch 248: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1498 - tp: 14911.0000 - fp: 849.0000 - tn: 30875.0000 - fn: 951.0000 - precision: 0.9461 - recall: 0.9400 - auc: 0.9931 - prc: 0.9871 - accuracy: 0.9426 - val_loss: 0.6970 - val_tp: 1646.0000 - val_fp: 329.0000 - val_tn: 3639.0000 - val_fn: 338.0000 - val_precision: 0.8334 - val_recall: 0.8296 - val_auc: 0.9348 - val_prc: 0.8813 - val_accuracy: 0.8301\n",
      "Epoch 249/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1560 - tp: 14862.0000 - fp: 889.0000 - tn: 30835.0000 - fn: 1000.0000 - precision: 0.9436 - recall: 0.9370 - auc: 0.9925 - prc: 0.9862 - accuracy: 0.9394\n",
      "Epoch 249: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1560 - tp: 14862.0000 - fp: 889.0000 - tn: 30835.0000 - fn: 1000.0000 - precision: 0.9436 - recall: 0.9370 - auc: 0.9925 - prc: 0.9862 - accuracy: 0.9394 - val_loss: 0.6326 - val_tp: 1642.0000 - val_fp: 328.0000 - val_tn: 3640.0000 - val_fn: 342.0000 - val_precision: 0.8335 - val_recall: 0.8276 - val_auc: 0.9433 - val_prc: 0.8974 - val_accuracy: 0.8311\n",
      "Epoch 250/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1493 - tp: 14877.0000 - fp: 881.0000 - tn: 30843.0000 - fn: 985.0000 - precision: 0.9441 - recall: 0.9379 - auc: 0.9931 - prc: 0.9869 - accuracy: 0.9407\n",
      "Epoch 250: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1493 - tp: 14877.0000 - fp: 881.0000 - tn: 30843.0000 - fn: 985.0000 - precision: 0.9441 - recall: 0.9379 - auc: 0.9931 - prc: 0.9869 - accuracy: 0.9407 - val_loss: 0.6600 - val_tp: 1634.0000 - val_fp: 341.0000 - val_tn: 3627.0000 - val_fn: 350.0000 - val_precision: 0.8273 - val_recall: 0.8236 - val_auc: 0.9386 - val_prc: 0.8874 - val_accuracy: 0.8256\n",
      "Epoch 251/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1563 - tp: 14873.0000 - fp: 893.0000 - tn: 30831.0000 - fn: 989.0000 - precision: 0.9434 - recall: 0.9376 - auc: 0.9922 - prc: 0.9854 - accuracy: 0.9405\n",
      "Epoch 251: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1563 - tp: 14873.0000 - fp: 893.0000 - tn: 30831.0000 - fn: 989.0000 - precision: 0.9434 - recall: 0.9376 - auc: 0.9922 - prc: 0.9854 - accuracy: 0.9405 - val_loss: 0.6220 - val_tp: 1655.0000 - val_fp: 312.0000 - val_tn: 3656.0000 - val_fn: 329.0000 - val_precision: 0.8414 - val_recall: 0.8342 - val_auc: 0.9428 - val_prc: 0.8976 - val_accuracy: 0.8377\n",
      "Epoch 252/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1524 - tp: 14862.0000 - fp: 897.0000 - tn: 30827.0000 - fn: 1000.0000 - precision: 0.9431 - recall: 0.9370 - auc: 0.9926 - prc: 0.9863 - accuracy: 0.9402\n",
      "Epoch 252: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1524 - tp: 14862.0000 - fp: 897.0000 - tn: 30827.0000 - fn: 1000.0000 - precision: 0.9431 - recall: 0.9370 - auc: 0.9926 - prc: 0.9863 - accuracy: 0.9402 - val_loss: 0.6736 - val_tp: 1645.0000 - val_fp: 325.0000 - val_tn: 3643.0000 - val_fn: 339.0000 - val_precision: 0.8350 - val_recall: 0.8291 - val_auc: 0.9387 - val_prc: 0.8896 - val_accuracy: 0.8327\n",
      "Epoch 253/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1473 - tp: 14917.0000 - fp: 837.0000 - tn: 30887.0000 - fn: 945.0000 - precision: 0.9469 - recall: 0.9404 - auc: 0.9932 - prc: 0.9874 - accuracy: 0.9437\n",
      "Epoch 253: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1473 - tp: 14917.0000 - fp: 837.0000 - tn: 30887.0000 - fn: 945.0000 - precision: 0.9469 - recall: 0.9404 - auc: 0.9932 - prc: 0.9874 - accuracy: 0.9437 - val_loss: 0.6778 - val_tp: 1626.0000 - val_fp: 345.0000 - val_tn: 3623.0000 - val_fn: 358.0000 - val_precision: 0.8250 - val_recall: 0.8196 - val_auc: 0.9390 - val_prc: 0.8893 - val_accuracy: 0.8216\n",
      "Epoch 254/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1525 - tp: 14902.0000 - fp: 869.0000 - tn: 30855.0000 - fn: 960.0000 - precision: 0.9449 - recall: 0.9395 - auc: 0.9931 - prc: 0.9871 - accuracy: 0.9420\n",
      "Epoch 254: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1525 - tp: 14902.0000 - fp: 869.0000 - tn: 30855.0000 - fn: 960.0000 - precision: 0.9449 - recall: 0.9395 - auc: 0.9931 - prc: 0.9871 - accuracy: 0.9420 - val_loss: 0.6568 - val_tp: 1628.0000 - val_fp: 347.0000 - val_tn: 3621.0000 - val_fn: 356.0000 - val_precision: 0.8243 - val_recall: 0.8206 - val_auc: 0.9386 - val_prc: 0.8898 - val_accuracy: 0.8221\n",
      "Epoch 255/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1444 - tp: 14937.0000 - fp: 830.0000 - tn: 30894.0000 - fn: 925.0000 - precision: 0.9474 - recall: 0.9417 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9444\n",
      "Epoch 255: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1444 - tp: 14937.0000 - fp: 830.0000 - tn: 30894.0000 - fn: 925.0000 - precision: 0.9474 - recall: 0.9417 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9444 - val_loss: 0.6655 - val_tp: 1633.0000 - val_fp: 337.0000 - val_tn: 3631.0000 - val_fn: 351.0000 - val_precision: 0.8289 - val_recall: 0.8231 - val_auc: 0.9377 - val_prc: 0.8870 - val_accuracy: 0.8256\n",
      "Epoch 256/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1617 - tp: 14810.0000 - fp: 966.0000 - tn: 30758.0000 - fn: 1052.0000 - precision: 0.9388 - recall: 0.9337 - auc: 0.9922 - prc: 0.9855 - accuracy: 0.9360\n",
      "Epoch 256: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1617 - tp: 14810.0000 - fp: 966.0000 - tn: 30758.0000 - fn: 1052.0000 - precision: 0.9388 - recall: 0.9337 - auc: 0.9922 - prc: 0.9855 - accuracy: 0.9360 - val_loss: 0.5974 - val_tp: 1663.0000 - val_fp: 311.0000 - val_tn: 3657.0000 - val_fn: 321.0000 - val_precision: 0.8425 - val_recall: 0.8382 - val_auc: 0.9490 - val_prc: 0.9075 - val_accuracy: 0.8407\n",
      "Epoch 257/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1482 - tp: 14911.0000 - fp: 854.0000 - tn: 30870.0000 - fn: 951.0000 - precision: 0.9458 - recall: 0.9400 - auc: 0.9933 - prc: 0.9875 - accuracy: 0.9429\n",
      "Epoch 257: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1482 - tp: 14911.0000 - fp: 854.0000 - tn: 30870.0000 - fn: 951.0000 - precision: 0.9458 - recall: 0.9400 - auc: 0.9933 - prc: 0.9875 - accuracy: 0.9429 - val_loss: 0.5445 - val_tp: 1667.0000 - val_fp: 302.0000 - val_tn: 3666.0000 - val_fn: 317.0000 - val_precision: 0.8466 - val_recall: 0.8402 - val_auc: 0.9512 - val_prc: 0.9116 - val_accuracy: 0.8432\n",
      "Epoch 258/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1498 - tp: 14890.0000 - fp: 870.0000 - tn: 30854.0000 - fn: 972.0000 - precision: 0.9448 - recall: 0.9387 - auc: 0.9934 - prc: 0.9878 - accuracy: 0.9413\n",
      "Epoch 258: val_accuracy did not improve from 0.84728\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1498 - tp: 14890.0000 - fp: 870.0000 - tn: 30854.0000 - fn: 972.0000 - precision: 0.9448 - recall: 0.9387 - auc: 0.9934 - prc: 0.9878 - accuracy: 0.9413 - val_loss: 0.5518 - val_tp: 1667.0000 - val_fp: 303.0000 - val_tn: 3665.0000 - val_fn: 317.0000 - val_precision: 0.8462 - val_recall: 0.8402 - val_auc: 0.9501 - val_prc: 0.9114 - val_accuracy: 0.8448\n",
      "Epoch 259/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1500 - tp: 14888.0000 - fp: 873.0000 - tn: 30851.0000 - fn: 974.0000 - precision: 0.9446 - recall: 0.9386 - auc: 0.9934 - prc: 0.9877 - accuracy: 0.9421\n",
      "Epoch 259: val_accuracy improved from 0.84728 to 0.85181, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 59s 232ms/step - loss: 0.1500 - tp: 14888.0000 - fp: 873.0000 - tn: 30851.0000 - fn: 974.0000 - precision: 0.9446 - recall: 0.9386 - auc: 0.9934 - prc: 0.9877 - accuracy: 0.9421 - val_loss: 0.5488 - val_tp: 1688.0000 - val_fp: 286.0000 - val_tn: 3682.0000 - val_fn: 296.0000 - val_precision: 0.8551 - val_recall: 0.8508 - val_auc: 0.9522 - val_prc: 0.9141 - val_accuracy: 0.8518\n",
      "Epoch 260/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1441 - tp: 14928.0000 - fp: 845.0000 - tn: 30879.0000 - fn: 934.0000 - precision: 0.9464 - recall: 0.9411 - auc: 0.9934 - prc: 0.9877 - accuracy: 0.9438\n",
      "Epoch 260: val_accuracy did not improve from 0.85181\n",
      "248/248 [==============================] - 58s 229ms/step - loss: 0.1441 - tp: 14928.0000 - fp: 845.0000 - tn: 30879.0000 - fn: 934.0000 - precision: 0.9464 - recall: 0.9411 - auc: 0.9934 - prc: 0.9877 - accuracy: 0.9438 - val_loss: 0.5700 - val_tp: 1674.0000 - val_fp: 298.0000 - val_tn: 3670.0000 - val_fn: 310.0000 - val_precision: 0.8489 - val_recall: 0.8438 - val_auc: 0.9499 - val_prc: 0.9083 - val_accuracy: 0.8473\n",
      "Epoch 261/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1521 - tp: 14918.0000 - fp: 852.0000 - tn: 30872.0000 - fn: 944.0000 - precision: 0.9460 - recall: 0.9405 - auc: 0.9930 - prc: 0.9869 - accuracy: 0.9429\n",
      "Epoch 261: val_accuracy did not improve from 0.85181\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1521 - tp: 14918.0000 - fp: 852.0000 - tn: 30872.0000 - fn: 944.0000 - precision: 0.9460 - recall: 0.9405 - auc: 0.9930 - prc: 0.9869 - accuracy: 0.9429 - val_loss: 0.5576 - val_tp: 1682.0000 - val_fp: 289.0000 - val_tn: 3679.0000 - val_fn: 302.0000 - val_precision: 0.8534 - val_recall: 0.8478 - val_auc: 0.9519 - val_prc: 0.9143 - val_accuracy: 0.8493\n",
      "Epoch 262/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1562 - tp: 14878.0000 - fp: 867.0000 - tn: 30857.0000 - fn: 984.0000 - precision: 0.9449 - recall: 0.9380 - auc: 0.9923 - prc: 0.9856 - accuracy: 0.9421\n",
      "Epoch 262: val_accuracy did not improve from 0.85181\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1562 - tp: 14878.0000 - fp: 867.0000 - tn: 30857.0000 - fn: 984.0000 - precision: 0.9449 - recall: 0.9380 - auc: 0.9923 - prc: 0.9856 - accuracy: 0.9421 - val_loss: 0.6114 - val_tp: 1670.0000 - val_fp: 308.0000 - val_tn: 3660.0000 - val_fn: 314.0000 - val_precision: 0.8443 - val_recall: 0.8417 - val_auc: 0.9452 - val_prc: 0.9002 - val_accuracy: 0.8432\n",
      "Epoch 263/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1446 - tp: 14949.0000 - fp: 815.0000 - tn: 30909.0000 - fn: 913.0000 - precision: 0.9483 - recall: 0.9424 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9452\n",
      "Epoch 263: val_accuracy improved from 0.85181 to 0.85585, saving model to ../two_image(3_label)_mob3i_RESULT\\cp-0300.ckpt\n",
      "248/248 [==============================] - 58s 226ms/step - loss: 0.1446 - tp: 14949.0000 - fp: 815.0000 - tn: 30909.0000 - fn: 913.0000 - precision: 0.9483 - recall: 0.9424 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9452 - val_loss: 0.5963 - val_tp: 1693.0000 - val_fp: 280.0000 - val_tn: 3688.0000 - val_fn: 291.0000 - val_precision: 0.8581 - val_recall: 0.8533 - val_auc: 0.9483 - val_prc: 0.9065 - val_accuracy: 0.8558\n",
      "Epoch 264/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1452 - tp: 14940.0000 - fp: 815.0000 - tn: 30909.0000 - fn: 922.0000 - precision: 0.9483 - recall: 0.9419 - auc: 0.9935 - prc: 0.9879 - accuracy: 0.9454\n",
      "Epoch 264: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1452 - tp: 14940.0000 - fp: 815.0000 - tn: 30909.0000 - fn: 922.0000 - precision: 0.9483 - recall: 0.9419 - auc: 0.9935 - prc: 0.9879 - accuracy: 0.9454 - val_loss: 0.5694 - val_tp: 1681.0000 - val_fp: 294.0000 - val_tn: 3674.0000 - val_fn: 303.0000 - val_precision: 0.8511 - val_recall: 0.8473 - val_auc: 0.9496 - val_prc: 0.9082 - val_accuracy: 0.8498\n",
      "Epoch 265/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1406 - tp: 14967.0000 - fp: 805.0000 - tn: 30919.0000 - fn: 895.0000 - precision: 0.9490 - recall: 0.9436 - auc: 0.9939 - prc: 0.9886 - accuracy: 0.9465\n",
      "Epoch 265: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1406 - tp: 14967.0000 - fp: 805.0000 - tn: 30919.0000 - fn: 895.0000 - precision: 0.9490 - recall: 0.9436 - auc: 0.9939 - prc: 0.9886 - accuracy: 0.9465 - val_loss: 0.6047 - val_tp: 1667.0000 - val_fp: 305.0000 - val_tn: 3663.0000 - val_fn: 317.0000 - val_precision: 0.8453 - val_recall: 0.8402 - val_auc: 0.9470 - val_prc: 0.9045 - val_accuracy: 0.8412\n",
      "Epoch 266/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1526 - tp: 14919.0000 - fp: 839.0000 - tn: 30885.0000 - fn: 943.0000 - precision: 0.9468 - recall: 0.9405 - auc: 0.9931 - prc: 0.9872 - accuracy: 0.9434\n",
      "Epoch 266: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1526 - tp: 14919.0000 - fp: 839.0000 - tn: 30885.0000 - fn: 943.0000 - precision: 0.9468 - recall: 0.9405 - auc: 0.9931 - prc: 0.9872 - accuracy: 0.9434 - val_loss: 0.5830 - val_tp: 1666.0000 - val_fp: 306.0000 - val_tn: 3662.0000 - val_fn: 318.0000 - val_precision: 0.8448 - val_recall: 0.8397 - val_auc: 0.9476 - val_prc: 0.9033 - val_accuracy: 0.8427\n",
      "Epoch 267/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1470 - tp: 14934.0000 - fp: 848.0000 - tn: 30876.0000 - fn: 928.0000 - precision: 0.9463 - recall: 0.9415 - auc: 0.9929 - prc: 0.9866 - accuracy: 0.9439\n",
      "Epoch 267: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1470 - tp: 14934.0000 - fp: 848.0000 - tn: 30876.0000 - fn: 928.0000 - precision: 0.9463 - recall: 0.9415 - auc: 0.9929 - prc: 0.9866 - accuracy: 0.9439 - val_loss: 0.6629 - val_tp: 1647.0000 - val_fp: 326.0000 - val_tn: 3642.0000 - val_fn: 337.0000 - val_precision: 0.8348 - val_recall: 0.8301 - val_auc: 0.9403 - val_prc: 0.8908 - val_accuracy: 0.8332\n",
      "Epoch 268/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1425 - tp: 14947.0000 - fp: 830.0000 - tn: 30894.0000 - fn: 915.0000 - precision: 0.9474 - recall: 0.9423 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9444\n",
      "Epoch 268: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1425 - tp: 14947.0000 - fp: 830.0000 - tn: 30894.0000 - fn: 915.0000 - precision: 0.9474 - recall: 0.9423 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9444 - val_loss: 0.6444 - val_tp: 1638.0000 - val_fp: 338.0000 - val_tn: 3630.0000 - val_fn: 346.0000 - val_precision: 0.8289 - val_recall: 0.8256 - val_auc: 0.9411 - val_prc: 0.8932 - val_accuracy: 0.8271\n",
      "Epoch 269/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1483 - tp: 14933.0000 - fp: 843.0000 - tn: 30881.0000 - fn: 929.0000 - precision: 0.9466 - recall: 0.9414 - auc: 0.9928 - prc: 0.9866 - accuracy: 0.9440\n",
      "Epoch 269: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 56s 222ms/step - loss: 0.1483 - tp: 14933.0000 - fp: 843.0000 - tn: 30881.0000 - fn: 929.0000 - precision: 0.9466 - recall: 0.9414 - auc: 0.9928 - prc: 0.9866 - accuracy: 0.9440 - val_loss: 0.6491 - val_tp: 1641.0000 - val_fp: 332.0000 - val_tn: 3636.0000 - val_fn: 343.0000 - val_precision: 0.8317 - val_recall: 0.8271 - val_auc: 0.9414 - val_prc: 0.8923 - val_accuracy: 0.8281\n",
      "Epoch 270/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1409 - tp: 14961.0000 - fp: 817.0000 - tn: 30907.0000 - fn: 901.0000 - precision: 0.9482 - recall: 0.9432 - auc: 0.9935 - prc: 0.9878 - accuracy: 0.9457\n",
      "Epoch 270: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1409 - tp: 14961.0000 - fp: 817.0000 - tn: 30907.0000 - fn: 901.0000 - precision: 0.9482 - recall: 0.9432 - auc: 0.9935 - prc: 0.9878 - accuracy: 0.9457 - val_loss: 0.7127 - val_tp: 1624.0000 - val_fp: 352.0000 - val_tn: 3616.0000 - val_fn: 360.0000 - val_precision: 0.8219 - val_recall: 0.8185 - val_auc: 0.9379 - val_prc: 0.8870 - val_accuracy: 0.8211\n",
      "Epoch 271/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1465 - tp: 14922.0000 - fp: 847.0000 - tn: 30877.0000 - fn: 940.0000 - precision: 0.9463 - recall: 0.9407 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9434\n",
      "Epoch 271: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1465 - tp: 14922.0000 - fp: 847.0000 - tn: 30877.0000 - fn: 940.0000 - precision: 0.9463 - recall: 0.9407 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9434 - val_loss: 0.7053 - val_tp: 1631.0000 - val_fp: 343.0000 - val_tn: 3625.0000 - val_fn: 353.0000 - val_precision: 0.8262 - val_recall: 0.8221 - val_auc: 0.9353 - val_prc: 0.8820 - val_accuracy: 0.8251\n",
      "Epoch 272/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1499 - tp: 14923.0000 - fp: 858.0000 - tn: 30866.0000 - fn: 939.0000 - precision: 0.9456 - recall: 0.9408 - auc: 0.9929 - prc: 0.9866 - accuracy: 0.9426\n",
      "Epoch 272: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1499 - tp: 14923.0000 - fp: 858.0000 - tn: 30866.0000 - fn: 939.0000 - precision: 0.9456 - recall: 0.9408 - auc: 0.9929 - prc: 0.9866 - accuracy: 0.9426 - val_loss: 0.6912 - val_tp: 1645.0000 - val_fp: 328.0000 - val_tn: 3640.0000 - val_fn: 339.0000 - val_precision: 0.8338 - val_recall: 0.8291 - val_auc: 0.9384 - val_prc: 0.8876 - val_accuracy: 0.8322\n",
      "Epoch 273/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1417 - tp: 14943.0000 - fp: 823.0000 - tn: 30901.0000 - fn: 919.0000 - precision: 0.9478 - recall: 0.9421 - auc: 0.9937 - prc: 0.9883 - accuracy: 0.9450\n",
      "Epoch 273: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.1417 - tp: 14943.0000 - fp: 823.0000 - tn: 30901.0000 - fn: 919.0000 - precision: 0.9478 - recall: 0.9421 - auc: 0.9937 - prc: 0.9883 - accuracy: 0.9450 - val_loss: 0.7687 - val_tp: 1626.0000 - val_fp: 348.0000 - val_tn: 3620.0000 - val_fn: 358.0000 - val_precision: 0.8237 - val_recall: 0.8196 - val_auc: 0.9297 - val_prc: 0.8718 - val_accuracy: 0.8201\n",
      "Epoch 274/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1424 - tp: 14967.0000 - fp: 793.0000 - tn: 30931.0000 - fn: 895.0000 - precision: 0.9497 - recall: 0.9436 - auc: 0.9935 - prc: 0.9877 - accuracy: 0.9470\n",
      "Epoch 274: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1424 - tp: 14967.0000 - fp: 793.0000 - tn: 30931.0000 - fn: 895.0000 - precision: 0.9497 - recall: 0.9436 - auc: 0.9935 - prc: 0.9877 - accuracy: 0.9470 - val_loss: 0.7890 - val_tp: 1613.0000 - val_fp: 364.0000 - val_tn: 3604.0000 - val_fn: 371.0000 - val_precision: 0.8159 - val_recall: 0.8130 - val_auc: 0.9276 - val_prc: 0.8677 - val_accuracy: 0.8135\n",
      "Epoch 275/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1392 - tp: 14991.0000 - fp: 788.0000 - tn: 30936.0000 - fn: 871.0000 - precision: 0.9501 - recall: 0.9451 - auc: 0.9941 - prc: 0.9889 - accuracy: 0.9472\n",
      "Epoch 275: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1392 - tp: 14991.0000 - fp: 788.0000 - tn: 30936.0000 - fn: 871.0000 - precision: 0.9501 - recall: 0.9451 - auc: 0.9941 - prc: 0.9889 - accuracy: 0.9472 - val_loss: 0.6718 - val_tp: 1661.0000 - val_fp: 320.0000 - val_tn: 3648.0000 - val_fn: 323.0000 - val_precision: 0.8385 - val_recall: 0.8372 - val_auc: 0.9414 - val_prc: 0.8917 - val_accuracy: 0.8377\n",
      "Epoch 276/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1401 - tp: 14973.0000 - fp: 800.0000 - tn: 30924.0000 - fn: 889.0000 - precision: 0.9493 - recall: 0.9440 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9464\n",
      "Epoch 276: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 221ms/step - loss: 0.1401 - tp: 14973.0000 - fp: 800.0000 - tn: 30924.0000 - fn: 889.0000 - precision: 0.9493 - recall: 0.9440 - auc: 0.9936 - prc: 0.9880 - accuracy: 0.9464 - val_loss: 0.6696 - val_tp: 1659.0000 - val_fp: 318.0000 - val_tn: 3650.0000 - val_fn: 325.0000 - val_precision: 0.8392 - val_recall: 0.8362 - val_auc: 0.9413 - val_prc: 0.8936 - val_accuracy: 0.8377\n",
      "Epoch 277/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1469 - tp: 14974.0000 - fp: 799.0000 - tn: 30925.0000 - fn: 888.0000 - precision: 0.9493 - recall: 0.9440 - auc: 0.9933 - prc: 0.9873 - accuracy: 0.9465\n",
      "Epoch 277: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 221ms/step - loss: 0.1469 - tp: 14974.0000 - fp: 799.0000 - tn: 30925.0000 - fn: 888.0000 - precision: 0.9493 - recall: 0.9440 - auc: 0.9933 - prc: 0.9873 - accuracy: 0.9465 - val_loss: 0.6208 - val_tp: 1659.0000 - val_fp: 312.0000 - val_tn: 3656.0000 - val_fn: 325.0000 - val_precision: 0.8417 - val_recall: 0.8362 - val_auc: 0.9453 - val_prc: 0.9003 - val_accuracy: 0.8372\n",
      "Epoch 278/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1434 - tp: 14960.0000 - fp: 819.0000 - tn: 30905.0000 - fn: 902.0000 - precision: 0.9481 - recall: 0.9431 - auc: 0.9937 - prc: 0.9882 - accuracy: 0.9458\n",
      "Epoch 278: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1434 - tp: 14960.0000 - fp: 819.0000 - tn: 30905.0000 - fn: 902.0000 - precision: 0.9481 - recall: 0.9431 - auc: 0.9937 - prc: 0.9882 - accuracy: 0.9458 - val_loss: 0.6277 - val_tp: 1653.0000 - val_fp: 324.0000 - val_tn: 3644.0000 - val_fn: 331.0000 - val_precision: 0.8361 - val_recall: 0.8332 - val_auc: 0.9425 - val_prc: 0.8933 - val_accuracy: 0.8352\n",
      "Epoch 279/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1298 - tp: 15063.0000 - fp: 734.0000 - tn: 30990.0000 - fn: 799.0000 - precision: 0.9535 - recall: 0.9496 - auc: 0.9948 - prc: 0.9901 - accuracy: 0.9515\n",
      "Epoch 279: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 56s 221ms/step - loss: 0.1298 - tp: 15063.0000 - fp: 734.0000 - tn: 30990.0000 - fn: 799.0000 - precision: 0.9535 - recall: 0.9496 - auc: 0.9948 - prc: 0.9901 - accuracy: 0.9515 - val_loss: 0.6180 - val_tp: 1663.0000 - val_fp: 301.0000 - val_tn: 3667.0000 - val_fn: 321.0000 - val_precision: 0.8467 - val_recall: 0.8382 - val_auc: 0.9443 - val_prc: 0.8983 - val_accuracy: 0.8422\n",
      "Epoch 280/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1434 - tp: 14966.0000 - fp: 803.0000 - tn: 30921.0000 - fn: 896.0000 - precision: 0.9491 - recall: 0.9435 - auc: 0.9939 - prc: 0.9885 - accuracy: 0.9463\n",
      "Epoch 280: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1434 - tp: 14966.0000 - fp: 803.0000 - tn: 30921.0000 - fn: 896.0000 - precision: 0.9491 - recall: 0.9435 - auc: 0.9939 - prc: 0.9885 - accuracy: 0.9463 - val_loss: 0.6170 - val_tp: 1650.0000 - val_fp: 320.0000 - val_tn: 3648.0000 - val_fn: 334.0000 - val_precision: 0.8376 - val_recall: 0.8317 - val_auc: 0.9437 - val_prc: 0.8968 - val_accuracy: 0.8332\n",
      "Epoch 281/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1333 - tp: 15041.0000 - fp: 746.0000 - tn: 30978.0000 - fn: 821.0000 - precision: 0.9527 - recall: 0.9482 - auc: 0.9942 - prc: 0.9893 - accuracy: 0.9504\n",
      "Epoch 281: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 56s 222ms/step - loss: 0.1333 - tp: 15041.0000 - fp: 746.0000 - tn: 30978.0000 - fn: 821.0000 - precision: 0.9527 - recall: 0.9482 - auc: 0.9942 - prc: 0.9893 - accuracy: 0.9504 - val_loss: 0.7086 - val_tp: 1634.0000 - val_fp: 340.0000 - val_tn: 3628.0000 - val_fn: 350.0000 - val_precision: 0.8278 - val_recall: 0.8236 - val_auc: 0.9338 - val_prc: 0.8798 - val_accuracy: 0.8266\n",
      "Epoch 282/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1354 - tp: 15019.0000 - fp: 772.0000 - tn: 30952.0000 - fn: 843.0000 - precision: 0.9511 - recall: 0.9469 - auc: 0.9942 - prc: 0.9892 - accuracy: 0.9492\n",
      "Epoch 282: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1354 - tp: 15019.0000 - fp: 772.0000 - tn: 30952.0000 - fn: 843.0000 - precision: 0.9511 - recall: 0.9469 - auc: 0.9942 - prc: 0.9892 - accuracy: 0.9492 - val_loss: 0.6369 - val_tp: 1673.0000 - val_fp: 302.0000 - val_tn: 3666.0000 - val_fn: 311.0000 - val_precision: 0.8471 - val_recall: 0.8432 - val_auc: 0.9439 - val_prc: 0.8972 - val_accuracy: 0.8463\n",
      "Epoch 283/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1365 - tp: 15016.0000 - fp: 775.0000 - tn: 30949.0000 - fn: 846.0000 - precision: 0.9509 - recall: 0.9467 - auc: 0.9941 - prc: 0.9887 - accuracy: 0.9484\n",
      "Epoch 283: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1365 - tp: 15016.0000 - fp: 775.0000 - tn: 30949.0000 - fn: 846.0000 - precision: 0.9509 - recall: 0.9467 - auc: 0.9941 - prc: 0.9887 - accuracy: 0.9484 - val_loss: 0.6196 - val_tp: 1658.0000 - val_fp: 319.0000 - val_tn: 3649.0000 - val_fn: 326.0000 - val_precision: 0.8386 - val_recall: 0.8357 - val_auc: 0.9443 - val_prc: 0.8975 - val_accuracy: 0.8372\n",
      "Epoch 284/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1401 - tp: 14977.0000 - fp: 799.0000 - tn: 30925.0000 - fn: 885.0000 - precision: 0.9494 - recall: 0.9442 - auc: 0.9937 - prc: 0.9881 - accuracy: 0.9466\n",
      "Epoch 284: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 59s 229ms/step - loss: 0.1401 - tp: 14977.0000 - fp: 799.0000 - tn: 30925.0000 - fn: 885.0000 - precision: 0.9494 - recall: 0.9442 - auc: 0.9937 - prc: 0.9881 - accuracy: 0.9466 - val_loss: 0.6970 - val_tp: 1665.0000 - val_fp: 312.0000 - val_tn: 3656.0000 - val_fn: 319.0000 - val_precision: 0.8422 - val_recall: 0.8392 - val_auc: 0.9387 - val_prc: 0.8879 - val_accuracy: 0.8402\n",
      "Epoch 285/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1390 - tp: 14976.0000 - fp: 798.0000 - tn: 30926.0000 - fn: 886.0000 - precision: 0.9494 - recall: 0.9441 - auc: 0.9940 - prc: 0.9889 - accuracy: 0.9470\n",
      "Epoch 285: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1390 - tp: 14976.0000 - fp: 798.0000 - tn: 30926.0000 - fn: 886.0000 - precision: 0.9494 - recall: 0.9441 - auc: 0.9940 - prc: 0.9889 - accuracy: 0.9470 - val_loss: 0.6600 - val_tp: 1662.0000 - val_fp: 314.0000 - val_tn: 3654.0000 - val_fn: 322.0000 - val_precision: 0.8411 - val_recall: 0.8377 - val_auc: 0.9423 - val_prc: 0.8947 - val_accuracy: 0.8397\n",
      "Epoch 286/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1370 - tp: 15031.0000 - fp: 747.0000 - tn: 30977.0000 - fn: 831.0000 - precision: 0.9527 - recall: 0.9476 - auc: 0.9940 - prc: 0.9887 - accuracy: 0.9505\n",
      "Epoch 286: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1370 - tp: 15031.0000 - fp: 747.0000 - tn: 30977.0000 - fn: 831.0000 - precision: 0.9527 - recall: 0.9476 - auc: 0.9940 - prc: 0.9887 - accuracy: 0.9505 - val_loss: 0.6566 - val_tp: 1661.0000 - val_fp: 317.0000 - val_tn: 3651.0000 - val_fn: 323.0000 - val_precision: 0.8397 - val_recall: 0.8372 - val_auc: 0.9415 - val_prc: 0.8942 - val_accuracy: 0.8392\n",
      "Epoch 287/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1270 - tp: 15050.0000 - fp: 741.0000 - tn: 30983.0000 - fn: 812.0000 - precision: 0.9531 - recall: 0.9488 - auc: 0.9946 - prc: 0.9898 - accuracy: 0.9505\n",
      "Epoch 287: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 222ms/step - loss: 0.1270 - tp: 15050.0000 - fp: 741.0000 - tn: 30983.0000 - fn: 812.0000 - precision: 0.9531 - recall: 0.9488 - auc: 0.9946 - prc: 0.9898 - accuracy: 0.9505 - val_loss: 0.6729 - val_tp: 1654.0000 - val_fp: 320.0000 - val_tn: 3648.0000 - val_fn: 330.0000 - val_precision: 0.8379 - val_recall: 0.8337 - val_auc: 0.9399 - val_prc: 0.8913 - val_accuracy: 0.8362\n",
      "Epoch 288/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1339 - tp: 15030.0000 - fp: 748.0000 - tn: 30976.0000 - fn: 832.0000 - precision: 0.9526 - recall: 0.9475 - auc: 0.9943 - prc: 0.9892 - accuracy: 0.9497\n",
      "Epoch 288: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 223ms/step - loss: 0.1339 - tp: 15030.0000 - fp: 748.0000 - tn: 30976.0000 - fn: 832.0000 - precision: 0.9526 - recall: 0.9475 - auc: 0.9943 - prc: 0.9892 - accuracy: 0.9497 - val_loss: 0.7214 - val_tp: 1625.0000 - val_fp: 348.0000 - val_tn: 3620.0000 - val_fn: 359.0000 - val_precision: 0.8236 - val_recall: 0.8191 - val_auc: 0.9351 - val_prc: 0.8832 - val_accuracy: 0.8226\n",
      "Epoch 289/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1323 - tp: 15030.0000 - fp: 752.0000 - tn: 30972.0000 - fn: 832.0000 - precision: 0.9524 - recall: 0.9475 - auc: 0.9945 - prc: 0.9896 - accuracy: 0.9498\n",
      "Epoch 289: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 63s 248ms/step - loss: 0.1323 - tp: 15030.0000 - fp: 752.0000 - tn: 30972.0000 - fn: 832.0000 - precision: 0.9524 - recall: 0.9475 - auc: 0.9945 - prc: 0.9896 - accuracy: 0.9498 - val_loss: 0.5963 - val_tp: 1671.0000 - val_fp: 307.0000 - val_tn: 3661.0000 - val_fn: 313.0000 - val_precision: 0.8448 - val_recall: 0.8422 - val_auc: 0.9507 - val_prc: 0.9097 - val_accuracy: 0.8438\n",
      "Epoch 290/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1356 - tp: 14978.0000 - fp: 810.0000 - tn: 30914.0000 - fn: 884.0000 - precision: 0.9487 - recall: 0.9443 - auc: 0.9944 - prc: 0.9894 - accuracy: 0.9463\n",
      "Epoch 290: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 63s 245ms/step - loss: 0.1356 - tp: 14978.0000 - fp: 810.0000 - tn: 30914.0000 - fn: 884.0000 - precision: 0.9487 - recall: 0.9443 - auc: 0.9944 - prc: 0.9894 - accuracy: 0.9463 - val_loss: 0.6587 - val_tp: 1645.0000 - val_fp: 333.0000 - val_tn: 3635.0000 - val_fn: 339.0000 - val_precision: 0.8316 - val_recall: 0.8291 - val_auc: 0.9420 - val_prc: 0.8956 - val_accuracy: 0.8306\n",
      "Epoch 291/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1452 - tp: 14933.0000 - fp: 824.0000 - tn: 30900.0000 - fn: 929.0000 - precision: 0.9477 - recall: 0.9414 - auc: 0.9937 - prc: 0.9881 - accuracy: 0.9446\n",
      "Epoch 291: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 56s 219ms/step - loss: 0.1452 - tp: 14933.0000 - fp: 824.0000 - tn: 30900.0000 - fn: 929.0000 - precision: 0.9477 - recall: 0.9414 - auc: 0.9937 - prc: 0.9881 - accuracy: 0.9446 - val_loss: 0.6647 - val_tp: 1652.0000 - val_fp: 325.0000 - val_tn: 3643.0000 - val_fn: 332.0000 - val_precision: 0.8356 - val_recall: 0.8327 - val_auc: 0.9386 - val_prc: 0.8897 - val_accuracy: 0.8347\n",
      "Epoch 292/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1377 - tp: 14992.0000 - fp: 782.0000 - tn: 30942.0000 - fn: 870.0000 - precision: 0.9504 - recall: 0.9452 - auc: 0.9942 - prc: 0.9890 - accuracy: 0.9478\n",
      "Epoch 292: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 58s 227ms/step - loss: 0.1377 - tp: 14992.0000 - fp: 782.0000 - tn: 30942.0000 - fn: 870.0000 - precision: 0.9504 - recall: 0.9452 - auc: 0.9942 - prc: 0.9890 - accuracy: 0.9478 - val_loss: 0.6385 - val_tp: 1668.0000 - val_fp: 312.0000 - val_tn: 3656.0000 - val_fn: 316.0000 - val_precision: 0.8424 - val_recall: 0.8407 - val_auc: 0.9426 - val_prc: 0.8958 - val_accuracy: 0.8417\n",
      "Epoch 293/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1402 - tp: 15008.0000 - fp: 787.0000 - tn: 30937.0000 - fn: 854.0000 - precision: 0.9502 - recall: 0.9462 - auc: 0.9940 - prc: 0.9887 - accuracy: 0.9486\n",
      "Epoch 293: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 159s 634ms/step - loss: 0.1402 - tp: 15008.0000 - fp: 787.0000 - tn: 30937.0000 - fn: 854.0000 - precision: 0.9502 - recall: 0.9462 - auc: 0.9940 - prc: 0.9887 - accuracy: 0.9486 - val_loss: 0.6456 - val_tp: 1650.0000 - val_fp: 327.0000 - val_tn: 3641.0000 - val_fn: 334.0000 - val_precision: 0.8346 - val_recall: 0.8317 - val_auc: 0.9413 - val_prc: 0.8923 - val_accuracy: 0.8337\n",
      "Epoch 294/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1371 - tp: 14988.0000 - fp: 789.0000 - tn: 30935.0000 - fn: 874.0000 - precision: 0.9500 - recall: 0.9449 - auc: 0.9939 - prc: 0.9885 - accuracy: 0.9477\n",
      "Epoch 294: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 126s 494ms/step - loss: 0.1371 - tp: 14988.0000 - fp: 789.0000 - tn: 30935.0000 - fn: 874.0000 - precision: 0.9500 - recall: 0.9449 - auc: 0.9939 - prc: 0.9885 - accuracy: 0.9477 - val_loss: 0.6301 - val_tp: 1651.0000 - val_fp: 322.0000 - val_tn: 3646.0000 - val_fn: 333.0000 - val_precision: 0.8368 - val_recall: 0.8322 - val_auc: 0.9432 - val_prc: 0.8985 - val_accuracy: 0.8342\n",
      "Epoch 295/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1288 - tp: 15050.0000 - fp: 741.0000 - tn: 30983.0000 - fn: 812.0000 - precision: 0.9531 - recall: 0.9488 - auc: 0.9949 - prc: 0.9905 - accuracy: 0.9511\n",
      "Epoch 295: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 225ms/step - loss: 0.1288 - tp: 15050.0000 - fp: 741.0000 - tn: 30983.0000 - fn: 812.0000 - precision: 0.9531 - recall: 0.9488 - auc: 0.9949 - prc: 0.9905 - accuracy: 0.9511 - val_loss: 0.5977 - val_tp: 1661.0000 - val_fp: 310.0000 - val_tn: 3658.0000 - val_fn: 323.0000 - val_precision: 0.8427 - val_recall: 0.8372 - val_auc: 0.9461 - val_prc: 0.9008 - val_accuracy: 0.8392\n",
      "Epoch 296/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1268 - tp: 15100.0000 - fp: 675.0000 - tn: 31049.0000 - fn: 762.0000 - precision: 0.9572 - recall: 0.9520 - auc: 0.9948 - prc: 0.9904 - accuracy: 0.9544\n",
      "Epoch 296: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1268 - tp: 15100.0000 - fp: 675.0000 - tn: 31049.0000 - fn: 762.0000 - precision: 0.9572 - recall: 0.9520 - auc: 0.9948 - prc: 0.9904 - accuracy: 0.9544 - val_loss: 0.6345 - val_tp: 1659.0000 - val_fp: 318.0000 - val_tn: 3650.0000 - val_fn: 325.0000 - val_precision: 0.8392 - val_recall: 0.8362 - val_auc: 0.9439 - val_prc: 0.8982 - val_accuracy: 0.8372\n",
      "Epoch 297/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1268 - tp: 15065.0000 - fp: 714.0000 - tn: 31010.0000 - fn: 797.0000 - precision: 0.9548 - recall: 0.9498 - auc: 0.9949 - prc: 0.9904 - accuracy: 0.9522\n",
      "Epoch 297: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1268 - tp: 15065.0000 - fp: 714.0000 - tn: 31010.0000 - fn: 797.0000 - precision: 0.9548 - recall: 0.9498 - auc: 0.9949 - prc: 0.9904 - accuracy: 0.9522 - val_loss: 0.7216 - val_tp: 1649.0000 - val_fp: 322.0000 - val_tn: 3646.0000 - val_fn: 335.0000 - val_precision: 0.8366 - val_recall: 0.8311 - val_auc: 0.9388 - val_prc: 0.8873 - val_accuracy: 0.8337\n",
      "Epoch 298/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1356 - tp: 14997.0000 - fp: 786.0000 - tn: 30938.0000 - fn: 865.0000 - precision: 0.9502 - recall: 0.9455 - auc: 0.9944 - prc: 0.9895 - accuracy: 0.9482\n",
      "Epoch 298: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 57s 224ms/step - loss: 0.1356 - tp: 14997.0000 - fp: 786.0000 - tn: 30938.0000 - fn: 865.0000 - precision: 0.9502 - recall: 0.9455 - auc: 0.9944 - prc: 0.9895 - accuracy: 0.9482 - val_loss: 0.6410 - val_tp: 1665.0000 - val_fp: 310.0000 - val_tn: 3658.0000 - val_fn: 319.0000 - val_precision: 0.8430 - val_recall: 0.8392 - val_auc: 0.9451 - val_prc: 0.8992 - val_accuracy: 0.8402\n",
      "Epoch 299/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1296 - tp: 15052.0000 - fp: 741.0000 - tn: 30983.0000 - fn: 810.0000 - precision: 0.9531 - recall: 0.9489 - auc: 0.9948 - prc: 0.9903 - accuracy: 0.9511\n",
      "Epoch 299: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 60s 237ms/step - loss: 0.1296 - tp: 15052.0000 - fp: 741.0000 - tn: 30983.0000 - fn: 810.0000 - precision: 0.9531 - recall: 0.9489 - auc: 0.9948 - prc: 0.9903 - accuracy: 0.9511 - val_loss: 0.6560 - val_tp: 1663.0000 - val_fp: 316.0000 - val_tn: 3652.0000 - val_fn: 321.0000 - val_precision: 0.8403 - val_recall: 0.8382 - val_auc: 0.9434 - val_prc: 0.8958 - val_accuracy: 0.8392\n",
      "Epoch 300/300\n",
      "248/248 [==============================] - ETA: 0s - loss: 0.1277 - tp: 15074.0000 - fp: 725.0000 - tn: 30999.0000 - fn: 788.0000 - precision: 0.9541 - recall: 0.9503 - auc: 0.9947 - prc: 0.9900 - accuracy: 0.9521\n",
      "Epoch 300: val_accuracy did not improve from 0.85585\n",
      "248/248 [==============================] - 59s 231ms/step - loss: 0.1277 - tp: 15074.0000 - fp: 725.0000 - tn: 30999.0000 - fn: 788.0000 - precision: 0.9541 - recall: 0.9503 - auc: 0.9947 - prc: 0.9900 - accuracy: 0.9521 - val_loss: 0.6481 - val_tp: 1661.0000 - val_fp: 315.0000 - val_tn: 3653.0000 - val_fn: 323.0000 - val_precision: 0.8406 - val_recall: 0.8372 - val_auc: 0.9441 - val_prc: 0.8974 - val_accuracy: 0.8402\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "class_weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "            class_weight = 'balanced',\n",
    "            classes = np.unique(train_generator1.classes), \n",
    "            y = train_generator1.classes)\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = model_final.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=TRAIN_SAMPLES // (BATCH_SIZE), # number of updates\n",
    "    epochs=EPOCH,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=VALIDATION_SAMPLES // (BATCH_SIZE ),\n",
    "    callbacks=[cp_callback ],\n",
    "    class_weight=class_weights,\n",
    "    workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'auc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1997 images belonging to 3 classes.\n",
      "Found 1997 images belonging to 3 classes.\n",
      "Found 1997 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    " \n",
    " \n",
    "test_generator1 = test_datagen.flow_from_directory(\n",
    "    f'../data/{NAME}/sat/test',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')\n",
    " \n",
    "test_generator2 = test_datagen.flow_from_directory(\n",
    "    f'../data/{NAME}/dem/test',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')\n",
    "test_generator3 = test_datagen.flow_from_directory(\n",
    "    f'../data/{NAME}/road/test',\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    class_mode='categorical')\n",
    "test_generator = JoinedGen(test_generator1, test_generator2, test_generator3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 31s 653ms/step - loss: 0.5792 - tp: 1672.0000 - fp: 305.0000 - tn: 3663.0000 - fn: 312.0000 - precision: 0.8457 - recall: 0.8427 - auc: 0.9492 - prc: 0.9083 - accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5792054533958435,\n",
       " 1672.0,\n",
       " 305.0,\n",
       " 3663.0,\n",
       " 312.0,\n",
       " 0.8457258343696594,\n",
       " 0.8427419066429138,\n",
       " 0.9492025375366211,\n",
       " 0.9083197116851807,\n",
       " 0.84375]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model_final.load_weights(latest)\n",
    "\n",
    "model_final.evaluate(test_generator, steps=VALIDATION_SAMPLES // BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Study\\githubRepo\\road-accident-CNN\\3.Model\\7.MobileNet(3image,3label)_final.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Study/githubRepo/road-accident-CNN/3.Model/7.MobileNet%283image%2C3label%29_final.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_final\u001b[39m.\u001b[39;49msave(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m{\u001b[39;49;00mNAME\u001b[39m}\u001b[39;49;00m\u001b[39m_MobileNet_3imageaaqkj.h5\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\No\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\No\\anaconda3\\lib\\site-packages\\h5py\\_hl\\group.py:148\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    145\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    146\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 148\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[0;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[1;32mc:\\Users\\No\\anaconda3\\lib\\site-packages\\h5py\\_hl\\dataset.py:137\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     sid \u001b[39m=\u001b[39m h5s\u001b[39m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 137\u001b[0m dset_id \u001b[39m=\u001b[39m h5d\u001b[39m.\u001b[39;49mcreate(parent\u001b[39m.\u001b[39;49mid, name, tid, sid, dcpl\u001b[39m=\u001b[39;49mdcpl)\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m (data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    140\u001b[0m     dset_id\u001b[39m.\u001b[39mwrite(h5s\u001b[39m.\u001b[39mALL, h5s\u001b[39m.\u001b[39mALL, data)\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5d.pyx:87\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "model_final.save(f'./{NAME}_MobileNet_3image')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af8e2bc38c47ad2eb2801b8a1df8ba266ffc32d6dc21ae3dca26080e3882f8b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
